version: '3'

services:

  splade-doc:
    image: ghcr.io/huggingface/text-embeddings-inference:cpu-1.4
    command: --model-id naver/efficient-splade-VI-BT-large-doc --revision main --pooling splade
    ports:
      - "4000:80"
    volumes:
      - ./data:/data

  splade-query:
    image: ghcr.io/huggingface/text-embeddings-inference:cpu-1.4
    command: --model-id naver/efficient-splade-VI-BT-large-query --revision main --pooling splade
    ports:
      - "5000:80"
    volumes:
      - ./data:/data

  jina:
    image: ghcr.io/huggingface/text-embeddings-inference:cpu-1.5
    command: --model-id jinaai/jina-embeddings-v2-base-en --revision main
    ports:
      - "6000:80"
    volumes:
      - ./data:/data

  bgem3:
    image: ghcr.io/huggingface/text-embeddings-inference:cpu-1.2
    command: --model-id BAAI/bge-m3 --revision main
    ports:
      - "7000:80"
    volumes:
      - ./data:/data

  reranker:
    image: ghcr.io/huggingface/text-embeddings-inference:cpu-1.8.2
    command: --model-id BAAI/bge-reranker-base --revision main
    ports:
      - "8000:80"
    volumes:
      - ./data:/data
