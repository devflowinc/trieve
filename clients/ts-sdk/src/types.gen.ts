// This file is auto-generated by @hey-api/openapi-ts

export type APIVersion = 'V1' | 'V2';

export type AddChunkToGroupReqPayload = {
    /**
     * Id of the chunk to make a member of the group.
     */
    chunk_id?: (string) | null;
    /**
     * Tracking Id of the chunk to make a member of the group.
     */
    chunk_tracking_id?: (string) | null;
};

/**
 * The default parameters which will be forcibly used when the api key is given on a request. If not provided, the api key will not have default parameters.
 */
export type ApiKeyRequestParams = {
    filters?: ((ChunkFilter) | null);
    highlight_options?: ((HighlightOptions) | null);
    /**
     * Options for handling the response for the llm to return when no results are found
     */
    no_result_message?: (string) | null;
    /**
     * Page size is the number of chunks to fetch. This can be used to fetch more than 10 chunks at a time.
     */
    page_size?: (number) | null;
    /**
     * If true, stop words will be removed. Queries that are entirely stop words will be preserved.
     */
    remove_stop_words?: (boolean) | null;
    /**
     * Set score_threshold to a float to filter out chunks with a score below the threshold.
     */
    score_threshold?: (number) | null;
    search_type?: ((SearchMethod) | null);
    /**
     * Set slim_chunks to true to avoid returning the content and chunk_html of the chunks.
     */
    slim_chunks?: (boolean) | null;
    typo_options?: ((TypoOptions) | null);
    /**
     * If true, quoted and - prefixed words will be parsed from the queries and used as required and negated words respectively.
     */
    use_quote_negated_terms?: (boolean) | null;
};

export type ApiKeyRespBody = {
    created_at: string;
    dataset_ids?: Array<(string)> | null;
    id: string;
    name: string;
    organization_id: string;
    organization_ids?: Array<(string)> | null;
    role: number;
    updated_at: string;
};

export type AuthQuery = {
    /**
     * Code sent via email as a result of successful call to send_invitation
     */
    inv_code?: (string) | null;
    /**
     * ID of organization to authenticate into
     */
    organization_id?: (string) | null;
    /**
     * URL to redirect to after successful login
     */
    redirect_uri?: (string) | null;
};

export type AutocompleteReqPayload = {
    /**
     * Set content_only to true to only returning the chunk_html of the chunks. This is useful for when you want to reduce amount of data over the wire for latency improvement (typically 10-50ms). Default is false.
     */
    content_only?: (boolean) | null;
    /**
     * If specified to true, this will extend the search results to include non-exact prefix matches of the same search_type such that a full page_size of results are returned. Default is false.
     */
    extend_results?: (boolean) | null;
    filters?: ((ChunkFilter) | null);
    highlight_options?: ((HighlightOptions) | null);
    /**
     * Metadata is any metadata you want to associate w/ the event that is created from this request
     */
    metadata?: unknown;
    /**
     * Page size is the number of chunks to fetch. This can be used to fetch more than 10 chunks at a time.
     */
    page_size?: (number) | null;
    query: SearchModalities;
    /**
     * If true, stop words (specified in server/src/stop-words.txt in the git repo) will be removed. Queries that are entirely stop words will be preserved.
     */
    remove_stop_words?: (boolean) | null;
    /**
     * Set score_threshold to a float to filter out chunks with a score below the threshold. This threshold applies before weight and bias modifications. If not specified, this defaults to 0.0.
     */
    score_threshold?: (number) | null;
    scoring_options?: ((ScoringOptions) | null);
    search_type: SearchMethod;
    /**
     * Set slim_chunks to true to avoid returning the content and chunk_html of the chunks. This is useful for when you want to reduce amount of data over the wire for latency improvement (typically 10-50ms). Default is false.
     */
    slim_chunks?: (boolean) | null;
    sort_options?: ((SortOptions) | null);
    typo_options?: ((TypoOptions) | null);
    /**
     * If true, quoted and - prefixed words will be parsed from the queries and used as required and negated words respectively. Default is false.
     */
    use_quote_negated_terms?: (boolean) | null;
    /**
     * User ID is the id of the user who is making the request. This is used to track user interactions with the search results.
     */
    user_id?: (string) | null;
};

export type BatchQueuedChunkResponse = {
    chunk_metadata: Array<ChunkMetadata>;
};

export type BulkDeleteChunkPayload = {
    filter: ChunkFilter;
};

export type ButtonTrigger = {
    mode: string;
    removeTriggers?: (boolean) | null;
    selector: string;
};

export type CTRAnalytics = {
    filter?: ((SearchAnalyticsFilter) | null);
    type: 'search_ctr_metrics';
} | {
    filter?: ((SearchAnalyticsFilter) | null);
    page?: (number) | null;
    type: 'searches_with_clicks';
} | {
    filter?: ((SearchAnalyticsFilter) | null);
    page?: (number) | null;
    type: 'searches_without_clicks';
} | {
    filter?: ((RecommendationAnalyticsFilter) | null);
    type: 'recommendation_ctr_metrics';
} | {
    filter?: ((RecommendationAnalyticsFilter) | null);
    page?: (number) | null;
    type: 'recommendations_with_clicks';
} | {
    filter?: ((RecommendationAnalyticsFilter) | null);
    page?: (number) | null;
    type: 'recommendations_without_clicks';
};

export type type = 'search_ctr_metrics';

export type CTRAnalyticsResponse = SearchCTRMetrics | CTRSearchQueryWithoutClicksResponse | CTRSearchQueryWithClicksResponse | RecommendationCTRMetrics | CTRRecommendationsWithoutClicksResponse | CTRRecommendationsWithClicksResponse;

export type CTRDataRequestBody = {
    /**
     * The ID of chunk that was clicked
     */
    clicked_chunk_id?: (string) | null;
    /**
     * The tracking ID of the chunk that was clicked
     */
    clicked_chunk_tracking_id?: (string) | null;
    ctr_type: CTRType;
    /**
     * Any metadata you want to include with the event i.e. action, user_id, etc.
     */
    metadata?: unknown;
    /**
     * The position of the clicked chunk
     */
    position: number;
    /**
     * The request id for the CTR data
     */
    request_id: string;
};

export type CTRMetricsOverTimeResponse = {
    points: Array<FloatTimePoint>;
    total_ctr: number;
};

export type CTRRecommendationsWithClicksResponse = {
    recommendations: Array<RecommendationsWithClicksCTRResponse>;
};

export type CTRRecommendationsWithoutClicksResponse = {
    recommendations: Array<RecommendationsWithoutClicksCTRResponse>;
};

export type CTRSearchQueryWithClicksResponse = {
    queries: Array<SearchQueriesWithClicksCTRResponse>;
};

export type CTRSearchQueryWithoutClicksResponse = {
    queries: Array<SearchQueriesWithoutClicksCTRResponse>;
};

export type CTRType = 'search' | 'rag' | 'recommendation';

export type ChatMessageProxy = {
    content: string;
    role: RoleProxy;
};

/**
 * ChunkFilter is a JSON object which can be used to filter chunks. This is useful for when you want to filter chunks by arbitrary metadata. Unlike with tag filtering, there is a performance hit for filtering on metadata.
 */
export type ChunkFilter = {
    /**
     * All of these field conditions have to match for the chunk to be included in the result set.
     */
    must?: Array<ConditionType> | null;
    /**
     * None of these field conditions can match for the chunk to be included in the result set.
     */
    must_not?: Array<ConditionType> | null;
    /**
     * Only one of these field conditions has to match for the chunk to be included in the result set.
     */
    should?: Array<ConditionType> | null;
};

export type ChunkGroup = {
    created_at: string;
    dataset_id: string;
    description: string;
    id: string;
    metadata?: unknown;
    name: string;
    tag_set?: Array<((string) | null)> | null;
    tracking_id?: (string) | null;
    updated_at: string;
};

export type ChunkGroupAndFileId = {
    created_at: string;
    dataset_id: string;
    description: string;
    file_id?: (string) | null;
    id: string;
    metadata?: unknown;
    name: string;
    tag_set?: Array<((string) | null)> | null;
    tracking_id?: (string) | null;
    updated_at: string;
};

export type ChunkGroups = Array<ChunkGroup>;

export type ChunkHtmlContentReqPayload = {
    /**
     * Text strings to remove from body when creating chunks for each page
     */
    body_remove_strings?: Array<(string)> | null;
    /**
     * The HTML content to be split into chunks
     */
    chunk_html: string;
    /**
     * Text strings to remove from headings when creating chunks for each page
     */
    heading_remove_strings?: Array<(string)> | null;
};

export type ChunkMetadata = {
    /**
     * HTML content of the chunk, can also be an arbitrary string which is not HTML
     */
    chunk_html?: (string) | null;
    /**
     * Timestamp of the creation of the chunk
     */
    created_at: string;
    /**
     * ID of the dataset which the chunk belongs to
     */
    dataset_id: string;
    /**
     * Unique identifier of the chunk, auto-generated uuid created by Trieve
     */
    id: string;
    /**
     * Image URLs of the chunk, can be any list of strings. Used for image search and RAG.
     */
    image_urls?: Array<((string) | null)> | null;
    /**
     * Link to the chunk, should be a URL
     */
    link?: (string) | null;
    location?: ((GeoInfo) | null);
    /**
     * Metadata of the chunk, can be any JSON object
     */
    metadata?: unknown;
    /**
     * Numeric value of the chunk, can be any float. Can represent the most relevant numeric value of the chunk, such as a price, quantity in stock, rating, etc.
     */
    num_value?: (number) | null;
    /**
     * Tag set of the chunk, can be any list of strings. Used for tag-filtered searches.
     */
    tag_set?: Array<((string) | null)> | null;
    /**
     * Timestamp of the chunk, can be any timestamp. Specified by the user.
     */
    time_stamp?: (string) | null;
    /**
     * Tracking ID of the chunk, can be any string, determined by the user. Tracking ID's are unique identifiers for chunks within a dataset. They are designed to match the unique identifier of the chunk in the user's system.
     */
    tracking_id?: (string) | null;
    /**
     * Timestamp of the last update of the chunk
     */
    updated_at: string;
    /**
     * Weight of the chunk, can be any float. Used as a multiplier on a chunk's relevance score for ranking purposes.
     */
    weight: number;
};

export type ChunkMetadataStringTagSet = {
    chunk_html?: (string) | null;
    created_at: string;
    dataset_id: string;
    id: string;
    image_urls?: Array<((string) | null)> | null;
    link?: (string) | null;
    location?: ((GeoInfo) | null);
    metadata?: unknown;
    num_value?: (number) | null;
    tag_set?: (string) | null;
    time_stamp?: (string) | null;
    tracking_id?: (string) | null;
    updated_at: string;
    weight: number;
};

export type ChunkMetadataTypes = SlimChunkMetadata | ChunkMetadataStringTagSet | ContentChunkMetadata;

export type ChunkMetadataWithPosition = {
    chunk: ChunkMetadata;
    position: number;
};

export type ChunkMetadataWithScore = {
    chunk_html?: (string) | null;
    created_at: string;
    dataset_id: string;
    id: string;
    link?: (string) | null;
    metadata?: unknown;
    score: number;
    tag_set?: (string) | null;
    time_stamp?: (string) | null;
    tracking_id?: (string) | null;
    updated_at: string;
    weight: number;
};

/**
 * Request payload for creating a new chunk
 */
export type ChunkReqPayload = {
    /**
     * HTML content of the chunk. This can also be plaintext. The innerText of the HTML will be used to create the embedding vector. The point of using HTML is for convienience, as some users have applications where users submit HTML content.
     */
    chunk_html?: (string) | null;
    /**
     * Convert HTML to raw text before processing to avoid adding noise to the vector embeddings. By default this is true. If you are using HTML content that you want to be included in the vector embeddings, set this to false.
     */
    convert_html_to_text?: (boolean) | null;
    fulltext_boost?: ((FullTextBoost) | null);
    /**
     * Group ids are the Trieve generated ids of the groups that the chunk should be placed into. This is useful for when you want to create a chunk and add it to a group or multiple groups in one request. Groups with these Trieve generated ids must be created first, it cannot be arbitrarily created through this route.
     */
    group_ids?: Array<(string)> | null;
    /**
     * Group tracking_ids are the user-assigned tracking_ids of the groups that the chunk should be placed into. This is useful for when you want to create a chunk and add it to a group or multiple groups in one request. If a group with the tracking_id does not exist, it will be created.
     */
    group_tracking_ids?: Array<(string)> | null;
    /**
     * High Priority allows you to place this chunk into a priority queue with its own ingestion workers. Can only be used by users with a Custom Pro plan.
     */
    high_priority?: (boolean) | null;
    /**
     * Image urls are a list of urls to images that are associated with the chunk. This is useful for when you want to associate images with a chunk.
     */
    image_urls?: Array<(string)> | null;
    /**
     * Link to the chunk. This can also be any string. Frequently, this is a link to the source of the chunk. The link value will not affect the embedding creation.
     */
    link?: (string) | null;
    location?: ((GeoInfo) | null);
    /**
     * Metadata is a JSON object which can be used to filter chunks. This is useful for when you want to filter chunks by arbitrary metadata. Unlike with tag filtering, there is a performance hit for filtering on metadata.
     */
    metadata?: unknown;
    /**
     * Num value is an arbitrary numerical value that can be used to filter chunks. This is useful for when you want to filter chunks by numerical value. There is no performance hit for filtering on num_value.
     */
    num_value?: (number) | null;
    semantic_boost?: ((SemanticBoost) | null);
    /**
     * If semantic_content is present, it will be used for creating semantic embeddings instead of the innerText `chunk_html`. `chunk_html` will still be the only thing stored and always used for fulltext functionality. `chunk_html` must still be present for the chunk to be created properly.
     */
    semantic_content?: (string) | null;
    /**
     * Split avg is a boolean which tells the server to split the text in the chunk_html into smaller chunks and average their resulting vectors. This is useful for when you want to create a chunk from a large piece of text and want to split it into smaller chunks to create a more fuzzy average dense vector. The sparse vector will be generated normally with no averaging. By default this is false.
     */
    split_avg?: (boolean) | null;
    /**
     * Tag set is a list of tags. This can be used to filter chunks by tag. Unlike with metadata filtering, HNSW indices will exist for each tag such that there is not a performance hit for filtering on them.
     */
    tag_set?: Array<(string)> | null;
    /**
     * Time_stamp should be an ISO 8601 combined date and time without timezone. It is used for time window filtering and recency-biasing search results.
     */
    time_stamp?: (string) | null;
    /**
     * Tracking_id is a string which can be used to identify a chunk. This is useful for when you are coordinating with an external system and want to use the tracking_id to identify the chunk.
     */
    tracking_id?: (string) | null;
    /**
     * Upsert when a chunk with the same tracking_id exists. By default this is false, and chunks will be ignored if another with the same tracking_id exists. If this is true, the chunk will be updated if a chunk with the same tracking_id exists.
     */
    upsert_by_tracking_id?: (boolean) | null;
    /**
     * Weight is a float which can be used to bias search results. This is useful for when you want to bias search results for a chunk. The magnitude only matters relative to other chunks in the chunk's dataset dataset.
     */
    weight?: (number) | null;
};

/**
 * The key in the ChunkReqPayload which you can map a column or field from the CSV or JSONL file to.
 */
export type ChunkReqPayloadFields = 'link' | 'tag_set' | 'num_value' | 'tracking_id' | 'group_tracking_ids' | 'time_stamp' | 'lat' | 'lon' | 'image_urls' | 'weight' | 'boost_phrase';

/**
 * Express a mapping between a column or field in a CSV or JSONL field and a key in the ChunkReqPayload created for each row or object.
 */
export type ChunkReqPayloadMapping = {
    chunk_req_payload_field: ChunkReqPayloadFields;
    /**
     * The column or field in the CSV or JSONL file that you want to map to a key in the ChunkReqPayload
     */
    csv_jsonl_field: string;
};

/**
 * Specify all of the mappings between columns or fields in a CSV or JSONL file and keys in the ChunkReqPayload. Array fields like tag_set, image_urls, and group_tracking_ids can have multiple mappings. Boost phrase can also have multiple mappings which get concatenated. Other fields can only have one mapping and only the last mapping will be used.
 */
export type ChunkReqPayloadMappings = Array<ChunkReqPayloadMapping>;

export type ChunkReturnTypes = ChunkMetadata | ChunkMetadataStringTagSet;

export type ChunkWithPosition = {
    chunk_id: string;
    position: number;
};

export type ChunkedContent = {
    /**
     * The body of the content
     */
    body: string;
    /**
     * The headings of the content in order of when they appear
     */
    headings: Array<(string)>;
};

export type ClickhouseRagTypes = 'chosen_chunks' | 'all_chunks';

export type ClickhouseRecommendationTypes = 'Chunk' | 'Group';

export type ClickhouseSearchTypes = 'search' | 'search_over_groups' | 'autocomplete' | 'rag';

export type CloneTopicReqPayload = {
    /**
     * The name of the topic. If this is not provided, the topic name is the same as the previous topic
     */
    name?: (string) | null;
    /**
     * The owner_id of the topic. This is typically a browser fingerprint or your user's id. It is used to group topics together for a user.
     */
    owner_id: string;
    /**
     * The topic_id to clone from
     */
    topic_id: string;
};

export type ClusterAnalytics = {
    filter?: ((ClusterAnalyticsFilter) | null);
    type: 'cluster_topics';
} | {
    cluster_id: string;
    page?: (number) | null;
    type: 'cluster_queries';
};

export type type2 = 'cluster_topics';

export type ClusterAnalyticsFilter = {
    date_range?: ((DateRange) | null);
};

export type ClusterAnalyticsResponse = SearchClusterResponse | SearchQueryResponse;

export type ComponentAnalytics = {
    filter?: ((ComponentAnalyticsFilter) | null);
    granularity?: ((Granularity) | null);
    type: 'total_unique_users';
} | {
    filter?: ((ComponentAnalyticsFilter) | null);
    page?: (number) | null;
    type: 'top_pages';
} | {
    filter?: ((ComponentAnalyticsFilter) | null);
    page?: (number) | null;
    type: 'top_components';
} | {
    page?: (number) | null;
    type: 'component_names';
};

export type type3 = 'total_unique_users';

export type ComponentAnalyticsFilter = {
    component_name?: (string) | null;
    date_range?: ((DateRange) | null);
};

export type ComponentAnalyticsResponse = TotalUniqueUsersResponse | TopPagesResponse | TopComponentsResponse | ComponentNamesResponse;

export type ComponentNamesResponse = {
    component_names: Array<(string)>;
};

/**
 * Filters can be constructed using either fields on the chunk objects, ids or tracking ids of chunks, and finally ids or tracking ids of groups.
 */
export type ConditionType = FieldCondition | HasChunkIDCondition;

export type ContentChunkMetadata = {
    chunk_html?: (string) | null;
    id: string;
    image_urls?: Array<((string) | null)> | null;
    num_value?: (number) | null;
    time_stamp?: (string) | null;
    tracking_id?: (string) | null;
    weight: number;
};

/**
 * Context options to use for the completion. If not specified, all options will default to false.
 */
export type ContextOptions = {
    /**
     * Include links in the context. If not specified, this defaults to false.
     */
    include_links?: (boolean) | null;
};

export type CountChunkQueryResponseBody = {
    count: number;
};

export type CountChunksReqPayload = {
    filters?: ((ChunkFilter) | null);
    /**
     * Set limit to restrict the maximum number of chunks to count. This is useful for when you want to reduce the latency of the count operation. By default the limit will be the number of chunks in the dataset.
     */
    limit?: (number) | null;
    query: QueryTypes;
    /**
     * Set score_threshold to a float to filter out chunks with a score below the threshold. This threshold applies before weight and bias modifications. If not specified, this defaults to 0.0.
     */
    score_threshold?: (number) | null;
    search_type: CountSearchMethod;
    /**
     * If true, quoted and - prefixed words will be parsed from the queries and used as required and negated words respectively. Default is false.
     */
    use_quote_negated_terms?: (boolean) | null;
};

export type CountSearchMethod = 'fulltext' | 'semantic' | 'bm25';

/**
 * Interval at which specified site should be re-scraped
 */
export type CrawlInterval = 'daily' | 'weekly' | 'monthly';

/**
 * Options for including an openapi spec in the crawl
 */
export type CrawlOpenAPIOptions = {
    /**
     * OpenAPI json schema to be processed alongside the site crawl
     */
    openapi_schema_url: string;
    /**
     * Tag to look for to determine if a page should create an openapi route chunk instead of chunks from heading-split of the HTML
     */
    openapi_tag: string;
};

/**
 * Options for setting up the crawl which will populate the dataset.
 */
export type CrawlOptions = {
    /**
     * Add chunks to the dataset that the crawl is created for, defaults to true
     */
    add_chunks_to_dataset?: (boolean) | null;
    /**
     * Option for allowing the crawl to follow links to external websites.
     */
    allow_external_links?: (boolean) | null;
    /**
     * Text strings to remove from body when creating chunks for each page
     */
    body_remove_strings?: Array<(string)> | null;
    /**
     * Boost titles such that keyword matches in titles are prioritized in search results. Strongly recommended to leave this on. Defaults to true.
     */
    boost_titles?: (boolean) | null;
    /**
     * URL Patterns to exclude from the crawl
     */
    exclude_paths?: Array<(string)> | null;
    /**
     * Specify the HTML tags, classes and ids to exclude from the response.
     */
    exclude_tags?: Array<(string)> | null;
    /**
     * Text strings to remove from headings when creating chunks for each page
     */
    heading_remove_strings?: Array<(string)> | null;
    /**
     * Ignore the website sitemap when crawling, defaults to true.
     */
    ignore_sitemap?: (boolean) | null;
    /**
     * URL Patterns to include in the crawl
     */
    include_paths?: Array<(string)> | null;
    /**
     * Specify the HTML tags, classes and ids to include in the response.
     */
    include_tags?: Array<(string)> | null;
    interval?: ((CrawlInterval) | null);
    /**
     * How many pages to crawl, defaults to 1000
     */
    limit?: (number) | null;
    scrape_options?: ((ScrapeOptions) | null);
    /**
     * The URL to crawl
     */
    site_url?: (string) | null;
    /**
     * Metadata to send back with the webhook call for each successful page scrape
     */
    webhook_metadata?: unknown;
    /**
     * Host to call back on the webhook for each successful page scrape
     */
    webhook_urls?: Array<(string)> | null;
};

export type CrawlRequest = {
    attempt_number: number;
    crawl_options: CrawlOptions;
    crawl_type: CrawlType;
    created_at: string;
    dataset_id: string;
    id: string;
    interval?: (string) | null;
    next_crawl_at?: (string) | null;
    scrape_id: string;
    status: CrawlStatus;
    url: string;
};

/**
 * Options for Crawling Shopify
 */
export type CrawlShopifyOptions = {
    /**
     * This option will ingest all variants as individual chunks and place them in groups by product id. Turning this off will only scrape 1 variant per product. default: true
     */
    group_variants?: (boolean) | null;
    tag_regexes?: Array<(string)> | null;
};

export type CrawlStatus = 'Pending' | {
    Processing: number;
} | 'Completed' | 'Failed';

export type CrawlType = 'firecrawl' | 'openapi' | 'shopify' | 'youtube';

/**
 * Options for Crawling Youtube
 */
export type CrawlYoutubeOptions = {
    [key: string]: unknown;
};

export type CreateApiKeyReqPayload = {
    /**
     * The dataset ids which the api key will have access to. If not provided or empty, the api key will have access to all datasets in the dataset.
     */
    dataset_ids?: Array<(string)> | null;
    default_params?: ((ApiKeyRequestParams) | null);
    /**
     * The expiration date of the api key. If not provided, the api key will not expire. This should be provided in UTC time.
     */
    expires_at?: (string) | null;
    /**
     * The name which will be assigned to the new api key.
     */
    name: string;
    /**
     * The role which will be assigned to the new api key. Either 0 (read), 1 (Admin) or 2 (Owner). The auth'ed user must have a role greater than or equal to the role being assigned.
     */
    role: number;
    /**
     * The routes which the api key will have access to. If not provided or empty, the api key will have access to all routes. Specify the routes as a list of strings. For example, ["GET /api/dataset", "POST /api/dataset"].
     */
    scopes?: Array<(string)> | null;
};

export type CreateApiKeyResponse = {
    /**
     * The api key which was created. This is the value which should be used in the Authorization header.
     */
    api_key: string;
};

export type CreateBatchChunkGroupReqPayload = Array<CreateSingleChunkGroupReqPayload>;

export type CreateBatchChunkReqPayload = Array<ChunkReqPayload>;

export type CreateBatchDataset = {
    /**
     * Name of the dataset.
     */
    dataset_name: string;
    server_configuration?: ((DatasetConfigurationDTO) | null);
    /**
     * Optional tracking ID for the dataset. Can be used to track the dataset in external systems. Must be unique within the organization. Strongly recommended to not use a valid uuid value as that will not work with the TR-Dataset header.
     */
    tracking_id?: (string) | null;
};

export type CreateChunkGroupReqPayloadEnum = CreateSingleChunkGroupReqPayload | CreateBatchChunkGroupReqPayload;

export type CreateChunkGroupResponseEnum = ChunkGroup | ChunkGroups;

export type CreateChunkReqPayloadEnum = ChunkReqPayload | CreateBatchChunkReqPayload;

export type CreateCrawlReqPayload = {
    crawl_options: CrawlOptions;
};

export type CreateDatasetBatchReqPayload = {
    /**
     * List of datasets to create
     */
    datasets: Array<CreateBatchDataset>;
    /**
     * Upsert when a dataset with one of the specified tracking_ids already exists. By default this is false and specified datasets with a tracking_id that already exists in the org will not be ignored. If true, the existing dataset will be updated with the new dataset's details.
     */
    upsert?: (boolean) | null;
};

export type CreateDatasetReqPayload = {
    /**
     * Name of the dataset.
     */
    dataset_name: string;
    server_configuration?: ((DatasetConfigurationDTO) | null);
    /**
     * Optional tracking ID for the dataset. Can be used to track the dataset in external systems. Must be unique within the organization. Strongly recommended to not use a valid uuid value as that will not work with the TR-Dataset header.
     */
    tracking_id?: (string) | null;
};

export type CreateMessageReqPayload = {
    /**
     * The base64 encoded audio input of the user message to attach to the topic and then generate an assistant message in response to.
     */
    audio_input?: (string) | null;
    /**
     * If concat user messages query is set to true, all of the user messages in the topic will be concatenated together and used as the search query. If not specified, this defaults to false. Default is false.
     */
    concat_user_messages_query?: (boolean) | null;
    context_options?: ((ContextOptions) | null);
    filters?: ((ChunkFilter) | null);
    highlight_options?: ((HighlightOptions) | null);
    /**
     * The URL of the image(s) to attach to the message.
     */
    image_urls?: Array<(string)> | null;
    llm_options?: ((LLMOptions) | null);
    /**
     * Metadata is any metadata you want to associate w/ the event that is created from this request
     */
    metadata?: unknown;
    /**
     * The content of the user message to attach to the topic and then generate an assistant message in response to.
     */
    new_message_content?: (string) | null;
    /**
     * No result message for when there are no chunks found above the score threshold.
     */
    no_result_message?: (string) | null;
    /**
     * Only include docs used in the completion. If not specified, this defaults to false.
     */
    only_include_docs_used?: (boolean) | null;
    /**
     * Page size is the number of chunks to fetch during RAG. If 0, then no search will be performed. If specified, this will override the N retrievals to include in the dataset configuration. Default is None.
     */
    page_size?: (number) | null;
    /**
     * If true, stop words (specified in server/src/stop-words.txt in the git repo) will be removed. Queries that are entirely stop words will be preserved.
     */
    remove_stop_words?: (boolean) | null;
    /**
     * Set score_threshold to a float to filter out chunks with a score below the threshold. This threshold applies before weight and bias modifications. If not specified, this defaults to 0.0.
     */
    score_threshold?: (number) | null;
    /**
     * Query is the search query. This can be any string. The search_query will be used to create a dense embedding vector and/or sparse vector which will be used to find the result set. If not specified, will default to the last user message or HyDE if HyDE is enabled in the dataset configuration. Default is None.
     */
    search_query?: (string) | null;
    search_type?: ((SearchMethod) | null);
    sort_options?: ((SortOptions) | null);
    /**
     * The ID of the topic to attach the message to.
     */
    topic_id: string;
    typo_options?: ((TypoOptions) | null);
    /**
     * If use_group_search is set to true, the search will be conducted using the `search_over_groups` api. If not specified, this defaults to false.
     */
    use_group_search?: (boolean) | null;
    /**
     * If true, quoted and - prefixed words will be parsed from the queries and used as required and negated words respectively. Default is false.
     */
    use_quote_negated_terms?: (boolean) | null;
    /**
     * The user_id is the id of the user who is making the request. This is used to track user interactions with the RAG results.
     */
    user_id?: (string) | null;
};

export type CreateOrganizationReqPayload = {
    /**
     * The arbitrary name which will be used to identify the organization. This name must be unique.
     */
    name: string;
};

export type CreatePresignedUrlForCsvJsonResponseBody = {
    file_metadata: File;
    /**
     * Signed URL to upload the file to.
     */
    presigned_put_url: string;
};

export type CreatePresignedUrlForCsvJsonlReqPayload = {
    /**
     * Description is an optional convience field so you do not have to remember what the file contains or is about. It will be included on the group resulting from the file which will hold its chunk.
     */
    description?: (string) | null;
    /**
     * Name of the file being uploaded, including the extension. Will be used to determine CSV or JSONL for processing.
     */
    file_name: string;
    /**
     * Amount to multiplicatevly increase the frequency of the tokens in the boost phrase for each row's chunk by. Applies to fulltext (SPLADE) and keyword (BM25) search.
     */
    fulltext_boost_factor?: (number) | null;
    /**
     * Group tracking id is an optional field which allows you to specify the tracking id of the group that is created from the file. Chunks created will be created with the tracking id of `group_tracking_id|<index of chunk>`
     */
    group_tracking_id?: (string) | null;
    /**
     * Link to the file. This can also be any string. This can be used to filter when searching for the file's resulting chunks. The link value will not affect embedding creation.
     */
    link?: (string) | null;
    mappings?: ((ChunkReqPayloadMappings) | null);
    /**
     * Metadata is a JSON object which can be used to filter chunks. This is useful for when you want to filter chunks by arbitrary metadata. Unlike with tag filtering, there is a performance hit for filtering on metadata. Will be passed down to the file's chunks.
     */
    metadata?: unknown;
    /**
     * Arbitrary float (positive or negative) specifying the multiplicate factor to apply before summing the phrase vector with the chunk_html embedding vector. Applies to semantic (embedding model) search.
     */
    semantic_boost_factor?: (number) | null;
    /**
     * Tag set is a comma separated list of tags which will be passed down to the chunks made from the file. Each tag will be joined with what's creatd per row of the CSV or JSONL file.
     */
    tag_set?: Array<(string)> | null;
    /**
     * Time stamp should be an ISO 8601 combined date and time without timezone. Time_stamp is used for time window filtering and recency-biasing search results. Will be passed down to the file's chunks.
     */
    time_stamp?: (string) | null;
    /**
     * Upsert by tracking_id. If true, chunks will be upserted by tracking_id. If false, chunks with the same tracking_id as another already existing chunk will be ignored. Defaults to true.
     */
    upsert_by_tracking_id?: (boolean) | null;
};

export type CreateSchemaReqPayload = {
    include_images?: (boolean) | null;
    model?: (string) | null;
    prompt: string;
    tag_enum?: Array<(string)> | null;
};

export type CreateSetupCheckoutSessionResPayload = {
    url: string;
};

export type CreateSingleChunkGroupReqPayload = {
    /**
     * Description to assign to the chunk_group. Convenience field for you to avoid having to remember what the group is for.
     */
    description?: (string) | null;
    /**
     * Optional metadata to assign to the chunk_group. This is a JSON object that can store any additional information you want to associate with the chunks inside of the chunk_group.
     */
    metadata?: unknown;
    /**
     * Name to assign to the chunk_group. Does not need to be unique.
     */
    name?: (string) | null;
    /**
     * Optional tags to assign to the chunk_group. This is a list of strings that can be used to categorize the chunks inside the chunk_group.
     */
    tag_set?: Array<(string)> | null;
    /**
     * Optional tracking id to assign to the chunk_group. This is a unique identifier for the chunk_group.
     */
    tracking_id?: (string) | null;
    /**
     * Upsert when a chunk_group with the same tracking_id exists. By default this is false, and the request will fail if a chunk_group with the same tracking_id exists. If this is true, the chunk_group will be updated if a chunk_group with the same tracking_id exists.
     */
    upsert_by_tracking_id?: (boolean) | null;
};

export type CreateSingleChunkReqPayload = ChunkReqPayload;

export type CreateTopicReqPayload = {
    /**
     * The first message which will belong to the topic. The topic name is generated based on this message similar to how it works in the OpenAI chat UX if a name is not explicitly provided on the name request body key.
     */
    first_user_message?: (string) | null;
    /**
     * Metadata is any metadata you want to associate w/ the event that is created from this request
     */
    metadata?: unknown;
    /**
     * The name of the topic. If this is not provided, the topic name is generated from the first_user_message.
     */
    name?: (string) | null;
    /**
     * The owner_id of the topic. This is typically a browser fingerprint or your user's id. It is used to group topics together for a user.
     */
    owner_id: string;
};

export type Dataset = {
    /**
     * Timestamp of the creation of the dataset
     */
    created_at: string;
    /**
     * Flag to indicate if the dataset has been deleted. Deletes are handled async after the flag is set so as to avoid expensive search index compaction.
     */
    deleted: number;
    /**
     * Unique identifier of the dataset, auto-generated uuid created by Trieve
     */
    id: string;
    /**
     * Name of the dataset
     */
    name: string;
    /**
     * Unique identifier of the organization that owns the dataset
     */
    organization_id: string;
    /**
     * Configuration of the dataset for RAG, embeddings, BM25, etc.
     */
    server_configuration: unknown;
    /**
     * Tracking ID of the dataset, can be any string, determined by the user. Tracking ID's are unique identifiers for datasets within an organization. They are designed to match the unique identifier of the dataset in the user's system.
     */
    tracking_id?: (string) | null;
    /**
     * Timestamp of the last update of the dataset
     */
    updated_at: string;
};

export type DatasetAnalytics = {
    /**
     * Average latency of search queries
     */
    avg_latency: number;
    /**
     * 50th percentile latency of search queries
     */
    p50: number;
    /**
     * 95th percentile latency of search queries
     */
    p95: number;
    /**
     * 99th percentile latency of search queries
     */
    p99: number;
    /**
     * Total number of searches with a negative rating
     */
    total_negative_ratings: number;
    /**
     * Total number of searches with a positive rating
     */
    total_positive_ratings: number;
    /**
     * Total number of search queries
     */
    total_queries: number;
};

export type DatasetAndUsage = {
    dataset: DatasetDTO;
    dataset_usage: DatasetUsageCount;
};

/**
 * Lets you specify the configuration for a dataset
 */
export type DatasetConfigurationDTO = {
    /**
     * The average length of the chunks in the index for BM25
     */
    BM25_AVG_LEN?: (number) | null;
    /**
     * The BM25 B parameter
     */
    BM25_B?: (number) | null;
    /**
     * Whether to use BM25
     */
    BM25_ENABLED?: (boolean) | null;
    /**
     * The BM25 K parameter
     */
    BM25_K?: (number) | null;
    /**
     * Whether to disable analytics
     */
    DISABLE_ANALYTICS?: (boolean) | null;
    DISTANCE_METRIC?: ((DistanceMetric) | null);
    /**
     * The base URL for the embedding API
     */
    EMBEDDING_BASE_URL?: (string) | null;
    /**
     * The name of the embedding model to use
     */
    EMBEDDING_MODEL_NAME?: (string) | null;
    /**
     * The prefix to use for the embedding query
     */
    EMBEDDING_QUERY_PREFIX?: (string) | null;
    /**
     * The size of the embeddings
     */
    EMBEDDING_SIZE?: (number) | null;
    /**
     * The frequency penalty to use
     */
    FREQUENCY_PENALTY?: (number) | null;
    /**
     * Whether to use fulltext search
     */
    FULLTEXT_ENABLED?: (boolean) | null;
    /**
     * Whether to only use indexed chunks
     */
    INDEXED_ONLY?: (boolean) | null;
    /**
     * The base URL for the LLM API
     */
    LLM_BASE_URL?: (string) | null;
    /**
     * The default model to use for the LLM
     */
    LLM_DEFAULT_MODEL?: (string) | null;
    /**
     * Whether the dataset is locked to prevent changes or deletion
     */
    LOCKED?: (boolean) | null;
    /**
     * The maximum limit for the number of chunks for counting
     */
    MAX_LIMIT?: (number) | null;
    /**
     * The maximum number of tokens to use in LLM Response
     */
    MAX_TOKENS?: (number) | null;
    /**
     * The prompt to use for converting a message to a query
     */
    MESSAGE_TO_QUERY_PROMPT?: (string) | null;
    /**
     * The number of retrievals to include with the RAG model
     */
    N_RETRIEVALS_TO_INCLUDE?: (number) | null;
    /**
     * Whether to enable pagefind indexing
     */
    PAGEFIND_ENABLED?: (boolean) | null;
    /**
     * The presence penalty to use
     */
    PRESENCE_PENALTY?: (number) | null;
    PUBLIC_DATASET?: ((PublicDatasetOptions) | null);
    /**
     * Whether or not to insert chunks into Postgres
     */
    QDRANT_ONLY?: (boolean) | null;
    /**
     * The prompt to use for the RAG model
     */
    RAG_PROMPT?: (string) | null;
    /**
     * The base URL for the reranker API
     */
    RERANKER_BASE_URL?: (string) | null;
    /**
     * The model name for the Reranker API
     */
    RERANKER_MODEL_NAME?: (string) | null;
    /**
     * Whether to use semantic search
     */
    SEMANTIC_ENABLED?: (boolean) | null;
    /**
     * The stop tokens to use
     */
    STOP_TOKENS?: Array<(string)> | null;
    /**
     * The system prompt to use for the LLM
     */
    SYSTEM_PROMPT?: (string) | null;
    /**
     * The temperature to use
     */
    TEMPERATURE?: (number) | null;
    /**
     * Whether to use the message to query prompt
     */
    USE_MESSAGE_TO_QUERY_PROMPT?: (boolean) | null;
};

export type DatasetDTO = {
    created_at: string;
    id: string;
    name: string;
    organization_id: string;
    tracking_id?: (string) | null;
    updated_at: string;
};

export type DatasetUsageCount = {
    chunk_count: number;
    dataset_id: string;
    id: string;
};

/**
 * Datasets
 */
export type Datasets = Array<Dataset>;

/**
 * DateRange is a JSON object which can be used to filter chunks by a range of dates. This leverages the time_stamp field on chunks in your dataset. You can specify this if you want values in a certain range. You must provide ISO 8601 combined date and time without timezone.
 */
export type DateRange = {
    gt?: (string) | null;
    gte?: (string) | null;
    lt?: (string) | null;
    lte?: (string) | null;
};

export type DeleteTopicData = {
    /**
     * The id of the topic to target.
     */
    topic_id: string;
};

export type DeprecatedSearchOverGroupsResponseBody = {
    corrected_query?: (string) | null;
    group_chunks: Array<GroupScoreChunk>;
    total_chunk_pages: number;
};

export type DistanceMetric = 'euclidean' | 'cosine' | 'manhattan' | 'dot';

export type Document = {
    extract?: (string) | null;
    html?: (string) | null;
    links?: Array<(string)> | null;
    markdown?: (string) | null;
    metadata: Metadata;
    rawHtml?: (string) | null;
    screenshot?: (string) | null;
};

export type EditMessageReqPayload = {
    /**
     * The base64 encoded audio input of the user message to attach to the topic and then generate an assistant message in response to.
     */
    audio_input?: (string) | null;
    /**
     * If concat user messages query is set to true, all of the user messages in the topic will be concatenated together and used as the search query. If not specified, this defaults to false. Default is false.
     */
    concat_user_messages_query?: (boolean) | null;
    context_options?: ((ContextOptions) | null);
    filters?: ((ChunkFilter) | null);
    highlight_options?: ((HighlightOptions) | null);
    /**
     * The URL of the image(s) to attach to the message.
     */
    image_urls?: Array<(string)> | null;
    llm_options?: ((LLMOptions) | null);
    /**
     * The sort order of the message to edit.
     */
    message_sort_order: number;
    /**
     * Metadata is any metadata you want to associate w/ the event that is created from this request
     */
    metadata?: unknown;
    /**
     * The new content of the message to replace the old content with.
     */
    new_message_content?: (string) | null;
    /**
     * No result message for when there are no chunks found above the score threshold.
     */
    no_result_message?: (string) | null;
    /**
     * Only include docs used in the completion. If not specified, this defaults to false.
     */
    only_include_docs_used?: (boolean) | null;
    /**
     * Page size is the number of chunks to fetch during RAG. If 0, then no search will be performed. If specified, this will override the N retrievals to include in the dataset configuration. Default is None.
     */
    page_size?: (number) | null;
    /**
     * If true, stop words (specified in server/src/stop-words.txt in the git repo) will be removed. Queries that are entirely stop words will be preserved.
     */
    remove_stop_words?: (boolean) | null;
    /**
     * Set score_threshold to a float to filter out chunks with a score below the threshold. This threshold applies before weight and bias modifications. If not specified, this defaults to 0.0.
     */
    score_threshold?: (number) | null;
    /**
     * Query is the search query. This can be any string. The search_query will be used to create a dense embedding vector and/or sparse vector which will be used to find the result set. If not specified, will default to the last user message or HyDE if HyDE is enabled in the dataset configuration. Default is None.
     */
    search_query?: (string) | null;
    search_type?: ((SearchMethod) | null);
    sort_options?: ((SortOptions) | null);
    /**
     * The id of the topic to edit the message at the given sort order for.
     */
    topic_id: string;
    typo_options?: ((TypoOptions) | null);
    use_group_search?: (boolean) | null;
    /**
     * If true, quoted and - prefixed words will be parsed from the queries and used as required and negated words respectively. Default is false.
     */
    use_quote_negated_terms?: (boolean) | null;
    /**
     * The user_id is the id of the user who is making the request. This is used to track user interactions with the RAG results.
     */
    user_id?: (string) | null;
};

export type ErrorResponseBody = {
    message: string;
};

/**
 * Filter to apply to the events when querying for them
 */
export type EventAnalyticsFilter = {
    date_range?: ((DateRange) | null);
    event_type?: ((EventTypesFilter) | null);
    /**
     * Filter by conversions
     */
    is_conversion?: (boolean) | null;
    /**
     * Filter by metadata path i.e. path.attribute = \"value\"
     */
    metadata_filter?: (string) | null;
    /**
     * Filter by user ID
     */
    user_id?: (string) | null;
};

/**
 * EventData represents a single analytics event
 */
export type EventData = {
    /**
     * The time the event was created.
     */
    created_at: string;
    /**
     * The unique identifier for the dataset the event is associated with.
     */
    dataset_id: string;
    /**
     * The name of the event, e.g. "Added to Cart", "Purchased", "Viewed Home Page", "Clicked", "Filter Clicked".
     */
    event_name: string;
    /**
     * The type of event, "add_to_cart", "purchase", "view", "click", "filter_clicked".
     */
    event_type: string;
    /**
     * The unique identifier for the event
     */
    id: string;
    /**
     * Whether the event is a conversion event.
     */
    is_conversion?: (boolean) | null;
    /**
     * The items associated with the event. This could be a list of stringified json chunks for search events, or a list of items for add_to_cart, purchase, view, and click events.
     */
    items: Array<(string)>;
    /**
     * Additional metadata associated with the event. This can be custom data that is specific to the event.
     */
    metadata?: unknown;
    /**
     * The unique identifier for the request the event is associated with.
     */
    request_id?: (string) | null;
    /**
     * The type of request the event is associated with.
     */
    request_type?: (string) | null;
    /**
     * The time the event was last updated.
     */
    updated_at: string;
    /**
     * The user identifier associated with the event.
     */
    user_id?: (string) | null;
};

export type EventReturn = {
    event_types: Array<(string)>;
    events: Array<WorkerEvent>;
    page_count: number;
};

export type EventTypeRequest = 'file_uploaded' | 'file_upload_failed' | 'chunks_uploaded' | 'chunk_action_failed' | 'chunk_updated' | 'bulk_chunks_deleted' | 'chunk_update_failed' | 'dataset_delete_failed' | 'qdrant_upload_failed' | 'bulk_chunk_upload_failed' | 'group_chunks_updated' | 'group_chunks_action_failed' | 'crawl_completed' | 'crawl_failed' | 'crawl_started' | 'csv_jsonl_processing_failed' | 'csv_jsonl_processing_checkpoint' | 'csv_jsonl_processing_completed' | 'video_uploaded' | 'pagefind_indexing_started' | 'pagefind_indexing_finished' | 'etl_started' | 'etl_completed' | 'etl_failed';

export type EventTypes = {
    /**
     * The name of the event
     */
    event_name: string;
    event_type: 'view';
    /**
     * The items that were viewed
     */
    items: Array<(string)>;
    /**
     * The location of the event
     */
    location?: (string) | null;
    /**
     * Any other metadata associated with the event
     */
    metadata?: unknown;
    request?: ((RequestInfo) | null);
    /**
     * The user id of the user who viewed the items
     */
    user_id?: (string) | null;
} | {
    /**
     * The name of the event
     */
    event_name: string;
    event_type: 'add_to_cart';
    /**
     * Whether the event is a conversion event
     */
    is_conversion?: (boolean) | null;
    /**
     * The items that were added to the cart
     */
    items: Array<(string)>;
    /**
     * The location of the event
     */
    location?: (string) | null;
    /**
     * Any other metadata associated with the event
     */
    metadata?: unknown;
    request?: ((RequestInfo) | null);
    /**
     * The user id of the user who added the items to the cart
     */
    user_id?: (string) | null;
} | {
    clicked_items?: ((ChunkWithPosition) | null);
    /**
     * The name of the event
     */
    event_name: string;
    event_type: 'click';
    /**
     * Whether the event is a conversion event
     */
    is_conversion?: (boolean) | null;
    /**
     * The location of the event
     */
    location?: (string) | null;
    /**
     * Metadata to include with click event
     */
    metadata?: unknown;
    request?: ((RequestInfo) | null);
    /**
     * The user id of the user who clicked the items
     */
    user_id?: (string) | null;
} | {
    /**
     * The name of the event
     */
    event_name: string;
    event_type: 'purchase';
    /**
     * Whether the event is a conversion event
     */
    is_conversion?: (boolean) | null;
    /**
     * The items that were purchased
     */
    items: Array<(string)>;
    /**
     * The location of the event
     */
    location?: (string) | null;
    /**
     * Any other metadata associated with the event
     */
    metadata?: unknown;
    request?: ((RequestInfo) | null);
    /**
     * The user id of the user who purchased the items
     */
    user_id?: (string) | null;
} | {
    /**
     * The name of the event
     */
    event_name: string;
    event_type: 'filter_clicked';
    /**
     * Whether the event is a conversion event
     */
    is_conversion?: (boolean) | null;
    /**
     * The filter items that were clicked in a hashmap ie. {filter_name: filter_value} where filter_name is filter_type::field_name
     */
    items: {
        [key: string]: (string);
    };
    /**
     * The location of the event
     */
    location?: (string) | null;
    request?: ((RequestInfo) | null);
    /**
     * The user id of the user who clicked the items
     */
    user_id?: (string) | null;
} | {
    event_type: 'search';
    /**
     * Latency of the search
     */
    latency?: (number) | null;
    /**
     * Metadata to provide with each request
     */
    metadata?: unknown;
    /**
     * The search query
     */
    query: string;
    query_rating?: ((SearchQueryRating) | null);
    /**
     * The request params of the search
     */
    request_params?: unknown;
    /**
     * The results of the search
     */
    results?: Array<unknown> | null;
    search_type?: ((ClickhouseSearchTypes) | null);
    /**
     * The top score of the search
     */
    top_score?: (number) | null;
    /**
     * The user id of the user who made the search
     */
    user_id?: (string) | null;
} | {
    /**
     * The detected hallucinations of the RAG event
     */
    detected_hallucinations?: Array<(string)> | null;
    event_type: 'rag';
    /**
     * The hallucination score of the RAG event
     */
    hallucination_score?: (number) | null;
    /**
     * The response from the LLM
     */
    llm_response?: (string) | null;
    /**
     * Metadata to provide with each request
     */
    metadata?: unknown;
    query_rating?: ((SearchQueryRating) | null);
    rag_type?: ((ClickhouseRagTypes) | null);
    /**
     * The results of the RAG event
     */
    results?: Array<unknown> | null;
    /**
     * The search id to associate the RAG event with a search
     */
    search_id?: (string) | null;
    /**
     * The topic id to associate the RAG event with a topic
     */
    topic_id?: (string) | null;
    /**
     * The user id of the user who made the RAG event
     */
    user_id?: (string) | null;
    /**
     * The user message
     */
    user_message: string;
} | {
    event_type: 'recommendation';
    /**
     * Metadata to provide with each request
     */
    metadata?: unknown;
    /**
     * Negative ids used for the recommendation
     */
    negative_ids?: Array<(string)> | null;
    /**
     * Negative tracking ids used for the recommendation
     */
    negative_tracking_ids?: Array<(string)> | null;
    /**
     * Positive ids used for the recommendation
     */
    positive_ids?: Array<(string)> | null;
    /**
     * Positive tracking ids used for the recommendation
     */
    positive_tracking_ids?: Array<(string)> | null;
    recommendation_type?: ((ClickhouseRecommendationTypes) | null);
    /**
     * The request params of the recommendation
     */
    request_params?: unknown;
    /**
     * The results of the Recommendation event
     */
    results?: Array<unknown> | null;
    /**
     * Top score of the recommendation
     */
    top_score?: (number) | null;
    /**
     * The user id of the user who made the recommendation
     */
    user_id?: (string) | null;
};

export type event_type = 'view';

export type EventTypesFilter = 'add_to_cart' | 'purchase' | 'view' | 'click' | 'filter_clicked';

/**
 * FieldCondition is a JSON object which can be used to filter chunks by a field. This is useful for when you want to filter chunks by arbitrary metadata. To access fields inside of the metadata that you provide with the card, prefix the field name with `metadata.`.
 */
export type FieldCondition = {
    /**
     * Boolean is a true false value for a field. This only works for boolean fields. You can specify this if you want values to be true or false.
     */
    boolean?: (boolean) | null;
    date_range?: ((DateRange) | null);
    /**
     * Field is the name of the field to filter on. Commonly used fields are `timestamp`, `link`, `tag_set`, `location`, `num_value`, `group_ids`, and `group_tracking_ids`. The field value will be used to check for an exact substring match on the metadata values for each existing chunk. This is useful for when you want to filter chunks by arbitrary metadata. To access fields inside of the metadata that you provide with the card, prefix the field name with `metadata.`.
     */
    field: string;
    geo_bounding_box?: ((LocationBoundingBox) | null);
    geo_polygon?: ((LocationPolygon) | null);
    geo_radius?: ((LocationRadius) | null);
    /**
     * Match all lets you pass in an array of values that will return results if all of the items match. The match value will be used to check for an exact substring match on the metadata values for each existing chunk. If both match_all and match_any are provided, the match_any condition will be used.
     */
    match_all?: Array<MatchCondition> | null;
    /**
     * Match any lets you pass in an array of values that will return results if any of the items match. The match value will be used to check for an exact substring match on the metadata values for each existing chunk. If both match_all and match_any are provided, the match_any condition will be used.
     */
    match_any?: Array<MatchCondition> | null;
    range?: ((Range) | null);
};

export type File = {
    created_at: string;
    dataset_id: string;
    file_name: string;
    id: string;
    link?: (string) | null;
    metadata?: unknown;
    size: number;
    tag_set?: Array<((string) | null)> | null;
    time_stamp?: (string) | null;
    updated_at: string;
};

export type FileAndGroupId = {
    file: File;
    group_id?: (string) | null;
};

export type FileDTO = {
    created_at: string;
    file_name: string;
    id: string;
    link?: (string) | null;
    metadata?: unknown;
    s3_url: string;
    size: number;
    updated_at: string;
};

export type FileData = {
    file_and_group_ids: Array<FileAndGroupId>;
    total_pages: number;
};

export type FloatRange = {
    gt?: (number) | null;
    gte?: (number) | null;
    lt?: (number) | null;
    lte?: (number) | null;
};

export type FloatTimePoint = {
    point: number;
    time_stamp: string;
};

/**
 * Boost the presence of certain tokens for fulltext (SPLADE) and keyword (BM25) search. I.e. boosting title phrases to priortize title matches or making sure that the listing for AirBNB itself ranks higher than companies who make software for AirBNB hosts by boosting the in-document-frequency of the AirBNB token (AKA word) for its official listing. Conceptually it multiples the in-document-importance second value in the tuples of the SPLADE or BM25 sparse vector of the chunk_html innerText for all tokens present in the boost phrase by the boost factor like so: (token, in-document-importance) -> (token, in-document-importance*boost_factor).
 */
export type FullTextBoost = {
    /**
     * Amount to multiplicatevly increase the frequency of the tokens in the phrase by
     */
    boost_factor: number;
    /**
     * The phrase to boost in the fulltext document frequency index
     */
    phrase: string;
};

export type GenerateOffChunksReqPayload = {
    /**
     * Audio input to be used in the chat. This will be used to generate the audio tokens for the model. The default is None.
     */
    audio_input?: (string) | null;
    /**
     * The ids of the chunks to be retrieved and injected into the context window for RAG.
     */
    chunk_ids: Array<(string)>;
    context_options?: ((ContextOptions) | null);
    /**
     * Frequency penalty is a number between -2.0 and 2.0. Positive values penalize new tokens based on their existing frequency in the text so far, decreasing the model's likelihood to repeat the same line verbatim. Default is 0.7.
     */
    frequency_penalty?: (number) | null;
    /**
     * Set highlight_results to false for a slight latency improvement (1-10ms). If not specified, this defaults to true. This will add `<mark><b>` tags to the chunk_html of the chunks to highlight matching splits.
     */
    highlight_results?: (boolean) | null;
    image_config?: ((ImageConfig) | null);
    /**
     * Image URLs to be used in the chat. These will be used to generate the image tokens for the model. The default is None.
     */
    image_urls?: Array<(string)> | null;
    /**
     * The maximum number of tokens to generate in the chat completion. Default is None.
     */
    max_tokens?: (number) | null;
    /**
     * Metadata is any metadata you want to associate w/ the event that is created from this request
     */
    metadata?: unknown;
    /**
     * Presence penalty is a number between -2.0 and 2.0. Positive values penalize new tokens based on whether they appear in the text so far, increasing the model's likelihood to talk about new topics. Default is 0.7.
     */
    presence_penalty?: (number) | null;
    /**
     * The previous messages to be placed into the chat history. There must be at least one previous message.
     */
    prev_messages: Array<ChatMessageProxy>;
    /**
     * Prompt will be used to tell the model what to generate in the next message in the chat. The default is 'Respond to the previous instruction and include the doc numbers that you used in square brackets at the end of the sentences that you used the docs for:'. You can also specify an empty string to leave the final message alone such that your user's final message can be used as the prompt. See docs.trieve.ai or contact us for more information.
     */
    prompt?: (string) | null;
    /**
     * Stop tokens are up to 4 sequences where the API will stop generating further tokens. Default is None.
     */
    stop_tokens?: Array<(string)> | null;
    /**
     * Whether or not to stream the response. If this is set to true or not included, the response will be a stream. If this is set to false, the response will be a normal JSON response. Default is true.
     */
    stream_response?: (boolean) | null;
    /**
     * What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. Default is 0.5.
     */
    temperature?: (number) | null;
    /**
     * User ID is the id of the user who is making the request. This is used to track user interactions with the RAG results.
     */
    user_id?: (string) | null;
};

/**
 * Location that you want to use as the center of the search.
 */
export type GeoInfo = {
    lat: GeoTypes;
    lon: GeoTypes;
};

/**
 * Location bias lets you rank your results by distance from a location. If not specified, this has no effect. Bias allows you to determine how much of an effect the location of chunks will have on the search results. If not specified, this defaults to 0.0. We recommend setting this to 1.0 for a gentle reranking of the results, >3.0 for a strong reranking of the results.
 */
export type GeoInfoWithBias = {
    /**
     * Bias lets you specify how much of an effect the location of chunks will have on the search results. If not specified, this defaults to 0.0. We recommend setting this to 1.0 for a gentle reranking of the results, >3.0 for a strong reranking of the results.
     */
    bias: number;
    location: GeoInfo;
};

export type GeoTypes = number;

export type GetAllTagsReqPayload = {
    /**
     * Page number to return, 1-indexed. Default is 1.
     */
    page?: (number) | null;
    /**
     * Number of items to return per page. Default is 20.
     */
    page_size?: (number) | null;
};

export type GetAllTagsResponse = {
    /**
     * List of tags with the number of chunks in the dataset with that tag.
     */
    tags: Array<TagsWithCount>;
    /**
     * Total number of unique tags in the dataset.
     */
    total: number;
};

export type GetChunkGroupCountRequest = {
    /**
     * The Id of the group to get the count for, is not required if group_tracking_id is provided.
     */
    group_id?: (string) | null;
    /**
     * The tracking id of the group to get the count for, is not required if group_id is provided.
     */
    group_tracking_id?: (string) | null;
};

export type GetChunkGroupCountResponse = {
    /**
     * The count of chunks in the given group.
     */
    count: number;
    /**
     * The Id of the group to get the count for.
     */
    group_id: string;
};

export type GetChunksData = {
    ids: Array<(string)>;
};

export type GetChunksInGroupResponse = GetChunksInGroupsResponseBody | GroupsBookmarkQueryResult;

export type GetChunksInGroupsResponseBody = {
    chunks: Array<ChunkMetadata>;
    group: ChunkGroupAndFileId;
    total_pages: number;
};

export type GetCrawlRequestsReqPayload = {
    limit?: (number) | null;
    page?: (number) | null;
};

export type GetDatasetsPagination = {
    limit?: (number) | null;
    offset?: (number) | null;
};

export type GetEventsData = {
    /**
     * The types of events to get. Leave undefined to get all events.
     */
    event_types?: Array<EventTypeRequest> | null;
    /**
     * The page number to get. Default is 1.
     */
    page?: (number) | null;
    /**
     * The number of items per page. Default is 10.
     */
    page_size?: (number) | null;
};

export type GetEventsRequestBody = {
    filter?: ((EventAnalyticsFilter) | null);
    /**
     * Page of results to return
     */
    page?: (number) | null;
};

/**
 * Response body for the GetEvents endpoint
 */
export type GetEventsResponseBody = {
    events: Array<EventData>;
};

export type GetGroupsForChunksReqPayload = {
    chunk_ids?: Array<(string)> | null;
    chunk_tracking_ids?: Array<(string)> | null;
};

export type GetPagefindIndexResponse = {
    url: string;
};

/**
 * Request payload for getting the parameters of a tool function
 */
export type GetToolFunctionParamsReqPayload = {
    /**
     * The base64 encoded audio input of the user message to attach to the topic and then generate an assistant message in response to.
     */
    audio_input?: (string) | null;
    /**
     * Image URL to attach to the message to generate the parameters for the tool function.
     */
    image_url?: (string) | null;
    /**
     * Model name to use for the completion. If not specified, this defaults to the dataset's model.
     */
    model?: (string) | null;
    tool_function: ToolFunction;
    /**
     * Text of the user's message to the assistant which will be used to generate the parameters for the tool function.
     */
    user_message_text?: (string) | null;
};

/**
 * Response body for getting the parameters of a tool function
 */
export type GetToolFunctionParamsRespBody = {
    /**
     * Parameters for the tool function.
     */
    parameters?: unknown;
};

export type GetTopDatasetsRequestBody = {
    date_range?: ((DateRange) | null);
    type: TopDatasetsRequestTypes;
};

export type GetTrackingChunksData = {
    tracking_ids: Array<(string)>;
};

export type Granularity = 'minute' | 'second' | 'hour' | 'day' | 'month';

export type GroupData = {
    /**
     * The list of all the groups.
     */
    groups: Array<ChunkGroupAndFileId>;
    /**
     * Parameter for the next cursor offset.
     */
    next_cursor?: (string) | null;
    /**
     * Total number of pages. Pages is groups_count / 10
     */
    total_pages: number;
};

export type GroupScoreChunk = {
    file_id?: (string) | null;
    group_created_at: string;
    group_dataset_id: string;
    group_description?: (string) | null;
    group_id: string;
    group_metadata?: unknown;
    group_name?: (string) | null;
    group_tag_set?: Array<((string) | null)> | null;
    group_tracking_id?: (string) | null;
    group_updated_at: string;
    metadata: Array<ScoreChunkDTO>;
};

export type GroupsBookmarkQueryResult = {
    chunks: Array<ChunkMetadataStringTagSet>;
    group: ChunkGroupAndFileId;
    total_pages: number;
};

export type GroupsForChunk = {
    chunk_uuid: string;
    slim_groups: Array<ChunkGroupAndFileId>;
};

/**
 * HasChunkIDCondition is a JSON object which can be used to filter chunks by their ids or tracking ids. This is useful for when you want to filter chunks by their ids or tracking ids.
 */
export type HasChunkIDCondition = {
    /**
     * Ids of the chunks to apply a match_any condition with. Only chunks with one of these ids will be returned.
     */
    ids?: Array<(string)> | null;
    /**
     * Tracking ids of the chunks to apply a match_any condition with. Only chunks with one of these tracking ids will be returned.
     */
    tracking_ids?: Array<(string)> | null;
};

export type HeadQueries = {
    count: number;
    query: string;
};

export type HeadQueryResponse = {
    queries: Array<HeadQueries>;
};

export type HeroPattern = {
    backgroundColor?: (string) | null;
    foregroundColor?: (string) | null;
    foregroundOpacity?: (number) | null;
    heroPatternName?: (string) | null;
    heroPatternSvg?: (string) | null;
};

/**
 * Highlight Options lets you specify different methods to highlight the chunks in the result set. If not specified, this defaults to the score of the chunks.
 */
export type HighlightOptions = {
    /**
     * Set highlight_delimiters to a list of strings to use as delimiters for highlighting. If not specified, this defaults to ["?", ",", ".", "!"]. These are the characters that will be used to split the chunk_html into splits for highlighting. These are the characters that will be used to split the chunk_html into splits for highlighting.
     */
    highlight_delimiters?: Array<(string)> | null;
    /**
     * Set highlight_max_length to control the maximum number of tokens (typically whitespace separated strings, but sometimes also word stems) which can be present within a single highlight. If not specified, this defaults to 8. This is useful to shorten large splits which may have low scores due to length compared to the query. Set to something very large like 100 to highlight entire splits.
     */
    highlight_max_length?: (number) | null;
    /**
     * Set highlight_max_num to control the maximum number of highlights per chunk. If not specified, this defaults to 3. It may be less than 3 if no snippets score above the highlight_threshold.
     */
    highlight_max_num?: (number) | null;
    /**
     * Set highlight_results to false for a slight latency improvement (1-10ms). If not specified, this defaults to true. This will add `<mark><b>` tags to the chunk_html of the chunks to highlight matching splits and return the highlights on each scored chunk in the response.
     */
    highlight_results?: (boolean) | null;
    highlight_strategy?: ((HighlightStrategy) | null);
    /**
     * Set highlight_threshold to a lower or higher value to adjust the sensitivity of the highlights applied to the chunk html. If not specified, this defaults to 0.8. The range is 0.0 to 1.0.
     */
    highlight_threshold?: (number) | null;
    /**
     * Set highlight_window to a number to control the amount of words that are returned around the matched phrases. If not specified, this defaults to 0. This is useful for when you want to show more context around the matched words. When specified, window/2 whitespace separated words are added before and after each highlight in the response's highlights array. If an extended highlight overlaps with another highlight, the overlapping words are only included once. This parameter can be overriden to respect the highlight_max_length param.
     */
    highlight_window?: (number) | null;
    /**
     * Custom html tag which should appear after highlights. If not specified, this defaults to '</mark></b>'.
     */
    post_tag?: (string) | null;
    /**
     * Custom html tag which should appear before highlights. If not specified, this defaults to '<mark><b>'.
     */
    pre_tag?: (string) | null;
};

export type HighlightStrategy = 'exactmatch' | 'v1';

/**
 * Configuration for sending images to the llm
 */
export type ImageConfig = {
    /**
     * The number of Images to send to the llm per chunk that is fetched more images may slow down llm inference time. default: 5
     */
    images_per_chunk?: (number) | null;
    /**
     * This sends images to the llm if chunk_metadata.image_urls has some value, the call will error if the model is not a vision LLM model. default: false
     */
    use_images?: (boolean) | null;
};

export type IntegerTimePoint = {
    point: number;
    time_stamp: string;
};

export type Invitation = {
    created_at: string;
    email: string;
    id: string;
    organization_id: string;
    role: number;
    updated_at: string;
    used: boolean;
};

export type InvitationData = {
    /**
     * The url of the app that the user will be directed to in order to set their password. Usually admin.trieve.ai, but may differ for local dev or self-hosted setups.
     */
    app_url: string;
    /**
     * The email of the user to invite. Must be a valid email as they will be sent an email to register.
     */
    email: string;
    /**
     * The url that the user will be redirected to after setting their password.
     */
    redirect_uri: string;
    /**
     * The role the user will have in the organization. 0 = User, 1 = Admin, 2 = Owner.
     */
    user_role: number;
};

/**
 * LLM options to use for the completion. If not specified, this defaults to the dataset's LLM options.
 */
export type LLMOptions = {
    /**
     * Completion first decides whether the stream should contain the stream of the completion response or the chunks first. Default is false. Keep in mind that || is used to separate the chunks from the completion response. If || is in the completion then you may want to split on ||{ instead.
     */
    completion_first?: (boolean) | null;
    /**
     * Frequency penalty is a number between -2.0 and 2.0. Positive values penalize new tokens based on their existing frequency in the text so far, decreasing the model's likelihood to repeat the same line verbatim. Default is 0.7.
     */
    frequency_penalty?: (number) | null;
    image_config?: ((ImageConfig) | null);
    /**
     * The maximum number of tokens to generate in the chat completion. Default is None.
     */
    max_tokens?: (number) | null;
    /**
     * Presence penalty is a number between -2.0 and 2.0. Positive values penalize new tokens based on whether they appear in the text so far, increasing the model's likelihood to talk about new topics. Default is 0.7.
     */
    presence_penalty?: (number) | null;
    /**
     * Stop tokens are up to 4 sequences where the API will stop generating further tokens. Default is None.
     */
    stop_tokens?: Array<(string)> | null;
    /**
     * Whether or not to stream the response. If this is set to true or not included, the response will be a stream. If this is set to false, the response will be a normal JSON response. Default is true.
     */
    stream_response?: (boolean) | null;
    /**
     * Optionally, override the system prompt in dataset server settings.
     */
    system_prompt?: (string) | null;
    /**
     * What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. Default is 0.5.
     */
    temperature?: (number) | null;
};

export type LatencyGraphResponse = {
    points: Array<FloatTimePoint>;
};

export type LocationBoundingBox = {
    bottom_right: GeoInfo;
    top_left: GeoInfo;
};

export type LocationPolygon = {
    exterior: Array<GeoInfo>;
    interior?: Array<Array<GeoInfo>> | null;
};

export type LocationRadius = {
    center: GeoInfo;
    radius: number;
};

export type MatchCondition = string | number;

export type Message = {
    completion_tokens?: (number) | null;
    content: string;
    created_at: string;
    dataset_id: string;
    deleted: boolean;
    id: string;
    prompt_tokens?: (number) | null;
    role: string;
    sort_order: number;
    topic_id: string;
    updated_at: string;
};

export type MessagesPerUserResponse = {
    avg_messages_per_user: number;
    points: Array<FloatTimePoint>;
};

export type Metadata = {
    articleSection?: (string) | null;
    articleTag?: (string) | null;
    dcDate?: (string) | null;
    dcDateCreated?: (string) | null;
    dcDescription?: (string) | null;
    dcSubject?: (string) | null;
    dcTermsAudience?: (string) | null;
    dcTermsCreated?: (string) | null;
    dcTermsKeywords?: (string) | null;
    dcTermsSubject?: (string) | null;
    dcTermsType?: (string) | null;
    dcType?: (string) | null;
    description?: (string) | null;
    error?: (string) | null;
    keywords?: (string) | null;
    language?: (string) | null;
    modifiedTime?: (string) | null;
    ogAudio?: (string) | null;
    ogDescription?: (string) | null;
    ogDeterminer?: (string) | null;
    ogImage?: (string) | null;
    ogLocale?: (string) | null;
    ogLocaleAlternate?: Array<(string)> | null;
    ogSiteName?: (string) | null;
    ogTitle?: (string) | null;
    ogUrl?: (string) | null;
    ogVideo?: (string) | null;
    publishedTime?: (string) | null;
    robots?: (string) | null;
    site_map?: ((Sitemap) | null);
    sourceURL?: (string) | null;
    statusCode?: (number) | null;
    title?: (string) | null;
};

/**
 * MMR Options lets you specify different methods to rerank the chunks in the result set using Maximal Marginal Relevance. If not specified, this defaults to the score of the chunks.
 */
export type MmrOptions = {
    /**
     * Set mmr_lambda to a value between 0.0 and 1.0 to control the tradeoff between relevance and diversity. Closer to 1.0 will give more diverse results, closer to 0.0 will give more relevant results. If not specified, this defaults to 0.5.
     */
    mmr_lambda?: (number) | null;
    /**
     * Set use_mmr to true to use the Maximal Marginal Relevance algorithm to rerank the results.
     */
    use_mmr: boolean;
};

/**
 * MultiQuery allows you to construct a dense vector from multiple queries with a weighted sum. This is useful for when you want to emphasize certain features of the query. This only works with Semantic Search and is not compatible with cross encoder re-ranking or highlights.
 */
export type MultiQuery = {
    query: SearchModalities;
    /**
     * Float value which is applies as a multiplier to the query vector when summing.
     */
    weight: number;
};

export type NewChunkMetadataTypes = SlimChunkMetadataWithArrayTagSet | ChunkMetadata | ContentChunkMetadata;

export type OpenGraphMetadata = {
    description?: (string) | null;
    image?: (string) | null;
    title?: (string) | null;
};

export type Organization = {
    /**
     * Timestamp of the creation of the dataset
     */
    created_at: string;
    /**
     * Flag to indicate if the organization has been deleted. Deletes are handled async after the flag is set so as to avoid expensive search index compaction.
     */
    deleted: number;
    /**
     * Unique identifier of the dataset, auto-generated uuid created by Trieve
     */
    id: string;
    /**
     * Name of the organization
     */
    name: string;
    /**
     * Configuration of the organization for the Trieve partner program. Contact partnerships@trieve.ai for more details.
     */
    partner_configuration: unknown;
    /**
     * Flag to indicate whether or not new users may join the organization. Default is true.
     */
    registerable?: (boolean) | null;
    /**
     * Timestamp of the last update of the dataset
     */
    updated_at: string;
};

export type OrganizationUsageCount = {
    chunk_count: number;
    dataset_count: number;
    file_storage: number;
    id: string;
    message_count: number;
    org_id: string;
    user_count: number;
};

export type OrganizationWithSubAndPlan = {
    organization: Organization;
    plan?: ((StripePlan) | null);
    subscription?: ((StripeSubscription) | null);
};

export type PartnerConfiguration = {
    CALENDAR_LINK: string;
    COMPANY_NAME: string;
    COMPANY_URL: string;
    DEMO_DOMAIN: string;
    EMAIL: string;
    FAVICON_URL: string;
    LINKEDIN_LINK: string;
    PHONE: string;
    SLACK_LINK: string;
};

export type Pdf2MdOptions = {
    /**
     * Split headings is an optional field which allows you to specify whether or not to split headings into separate chunks. Default is false.
     */
    split_headings?: (boolean) | null;
    /**
     * Prompt to use for the gpt-4o model. Default is None.
     */
    system_prompt?: (string) | null;
    /**
     * Parameter to use pdf2md_ocr. If true, the file will be converted to markdown using gpt-4o. Default is false.
     */
    use_pdf2md_ocr: boolean;
};

export type PopularFilters = {
    clause: string;
    common_values: {
        [key: string]: (number);
    };
    count: number;
    field: string;
    filter_type: string;
};

export type PopularFiltersResponse = {
    popular_filters: Array<PopularFilters>;
};

export type PublicDatasetOptions = {
    enabled: boolean;
    extra_params?: ((PublicPageParameters) | null);
};

export type PublicPageParameters = {
    allowSwitchingModes?: (boolean) | null;
    analytics?: (boolean) | null;
    apiKey?: (string) | null;
    baseUrl?: (string) | null;
    brandColor?: (string) | null;
    brandFontFamily?: (string) | null;
    brandLogoImgSrcUrl?: (string) | null;
    brandName?: (string) | null;
    buttonTriggers?: Array<ButtonTrigger> | null;
    chat?: (boolean) | null;
    creatorLinkedInUrl?: (string) | null;
    creatorName?: (string) | null;
    currencyPosition?: (string) | null;
    datasetId?: (string) | null;
    debounceMs?: (number) | null;
    defaultAiQuestions?: Array<(string)> | null;
    defaultCurrency?: (string) | null;
    defaultImageQuestion?: (string) | null;
    defaultSearchMode?: (string) | null;
    defaultSearchQueries?: Array<(string)> | null;
    floatingButtonPosition?: (string) | null;
    floatingSearchIconPosition?: (string) | null;
    followupQuestions?: (boolean) | null;
    forBrandName?: (string) | null;
    headingPrefix?: (string) | null;
    heroPattern?: ((HeroPattern) | null);
    hideDrawnText?: (boolean) | null;
    inline?: (boolean) | null;
    inlineHeader?: (string) | null;
    isTestMode?: (boolean) | null;
    navLogoImgSrcUrl?: (string) | null;
    numberOfSuggestions?: (number) | null;
    openGraphMetadata?: ((OpenGraphMetadata) | null);
    openLinksInNewTab?: (boolean) | null;
    placeholder?: (string) | null;
    problemLink?: (string) | null;
    responsive?: (boolean) | null;
    searchOptions?: ((PublicPageSearchOptions) | null);
    showFloatingButton?: (boolean) | null;
    showFloatingInput?: (boolean) | null;
    showFloatingSearchIcon?: (boolean) | null;
    showResultHighlights?: (boolean) | null;
    singleProductOptions?: ((SingleProductOptions) | null);
    suggestedQueries?: (boolean) | null;
    tabMessages?: Array<PublicPageTabMessage> | null;
    tags?: Array<PublicPageTag> | null;
    theme?: ((PublicPageTheme) | null);
    type?: (string) | null;
    useGroupSearch?: (boolean) | null;
    useLocal?: (boolean) | null;
    usePagefind?: (boolean) | null;
    videoLink?: (string) | null;
    videoPosition?: (string) | null;
    zIndex?: (number) | null;
};

export type PublicPageSearchOptions = {
    /**
     * Set content_only to true to only returning the chunk_html of the chunks. This is useful for when you want to reduce amount of data over the wire for latency improvement (typically 10-50ms). Default is false.
     */
    content_only?: (boolean) | null;
    filters?: ((ChunkFilter) | null);
    /**
     * Get total page count for the query accounting for the applied filters. Defaults to false, but can be set to true when the latency penalty is acceptable (typically 50-200ms).
     */
    get_total_pages?: (boolean) | null;
    /**
     * Page of chunks to fetch. Page is 1-indexed.
     */
    page?: (number) | null;
    /**
     * Page size is the number of chunks to fetch. This can be used to fetch more than 10 chunks at a time.
     */
    page_size?: (number) | null;
    /**
     * If true, stop words (specified in server/src/stop-words.txt in the git repo) will be removed. Queries that are entirely stop words will be preserved.
     */
    remove_stop_words?: (boolean) | null;
    /**
     * Set score_threshold to a float to filter out chunks with a score below the threshold for cosine distance metric. For Manhattan Distance, Euclidean Distance, and Dot Product, it will filter out scores above the threshold distance. This threshold applies before weight and bias modifications. If not specified, this defaults to no threshold. A threshold of 0 will default to no threshold.
     */
    score_threshold?: (number) | null;
    scoring_options?: ((ScoringOptions) | null);
    search_type?: ((SearchMethod) | null);
    /**
     * Set slim_chunks to true to avoid returning the content and chunk_html of the chunks. This is useful for when you want to reduce amount of data over the wire for latency improvement (typically 10-50ms). Default is false.
     */
    slim_chunks?: (boolean) | null;
    sort_options?: ((SortOptions) | null);
    typo_options?: ((TypoOptions) | null);
    /**
     * Enables autocomplete on the search modal.
     */
    use_autocomplete?: (boolean) | null;
    /**
     * If true, quoted and - prefixed words will be parsed from the queries and used as required and negated words respectively. Default is false.
     */
    use_quote_negated_terms?: (boolean) | null;
    /**
     * User ID is the id of the user who is making the request. This is used to track user interactions with the search results.
     */
    user_id?: (string) | null;
};

export type PublicPageTabMessage = {
    showComponentCode: boolean;
    tabInnerHtml: string;
    title: string;
};

export type PublicPageTag = {
    description?: (string) | null;
    iconClassName?: (string) | null;
    label?: (string) | null;
    selected?: (boolean) | null;
    tag: string;
};

export type PublicPageTheme = 'light' | 'dark';

export type QdrantChunkMetadata = {
    chunk_html?: (string) | null;
    dataset_id: string;
    group_ids?: Array<(string)> | null;
    image_urls?: Array<(string)> | null;
    link?: (string) | null;
    location?: ((GeoInfo) | null);
    metadata?: unknown;
    num_value?: (number) | null;
    qdrant_point_id: string;
    tag_set?: Array<(string)> | null;
    time_stamp?: (string) | null;
    tracking_id?: (string) | null;
    weight: number;
};

/**
 * Sort by lets you specify a method to sort the results by. If not specified, this defaults to the score of the chunks. If specified, this can be any key in the chunk metadata. This key must be a numeric value within the payload.
 */
export type QdrantSortBy = SortByField | SortBySearchType;

export type QueryCountResponse = {
    total_queries: Array<SearchTypeCount>;
};

export type QueryRatingRange = {
    gt?: (number) | null;
    gte?: (number) | null;
    lt?: (number) | null;
    lte?: (number) | null;
};

/**
 * Query is the search query. This can be any string. The query will be used to create an embedding vector and/or SPLADE vector which will be used to find the result set.  You can either provide one query, or multiple with weights. Multi-query only works with Semantic Search and is not compatible with cross encoder re-ranking or highlights.
 */
export type QueryTypes = SearchModalities | Array<MultiQuery>;

export type RAGAnalytics = {
    filter?: ((RAGAnalyticsFilter) | null);
    has_clicks?: (boolean) | null;
    page?: (number) | null;
    sort_by?: ((RAGSortBy) | null);
    sort_order?: ((SortOrder) | null);
    type: 'rag_queries';
} | {
    filter?: ((RAGAnalyticsFilter) | null);
    type: 'rag_usage';
} | {
    filter?: ((RAGAnalyticsFilter) | null);
    granularity?: ((Granularity) | null);
    type: 'rag_usage_graph';
} | {
    request_id: string;
    type: 'rag_query_details';
} | {
    filter?: ((RAGAnalyticsFilter) | null);
    type: 'rag_query_ratings';
} | {
    filter?: ((TopicAnalyticsFilter) | null);
    has_clicks?: (boolean) | null;
    page?: (number) | null;
    sort_by?: ((RAGSortBy) | null);
    sort_order?: ((SortOrder) | null);
    type: 'topic_queries';
} | {
    topic_id: string;
    type: 'topic_details';
} | {
    filter?: ((TopicAnalyticsFilter) | null);
    granularity?: ((Granularity) | null);
    type: 'topics_over_time';
} | {
    filter?: ((RAGAnalyticsFilter) | null);
    granularity?: ((Granularity) | null);
    type: 'ctr_metrics_over_time';
} | {
    filter?: ((RAGAnalyticsFilter) | null);
    granularity?: ((Granularity) | null);
    type: 'messages_per_user';
};

export type type4 = 'rag_queries';

export type RAGAnalyticsFilter = {
    component_name?: (string) | null;
    date_range?: ((DateRange) | null);
    query?: (string) | null;
    query_rating?: ((QueryRatingRange) | null);
    rag_type?: ((RagTypes) | null);
};

export type RAGAnalyticsResponse = RagQueryResponse | RAGUsageResponse | RAGUsageGraphResponse | RagQueryEvent | RagQueryRatingsResponse | TopicQueriesResponse | TopicDetailsResponse | TopicsOverTimeResponse | CTRMetricsOverTimeResponse | MessagesPerUserResponse;

export type RAGSortBy = 'hallucination_score' | 'top_score' | 'created_at';

export type RAGUsageGraphResponse = {
    points: Array<IntegerTimePoint>;
};

export type RAGUsageResponse = {
    total_queries: number;
};

export type RagQueryEvent = {
    created_at: string;
    dataset_id: string;
    detected_hallucinations: Array<(string)>;
    hallucination_score: number;
    id: string;
    llm_response: string;
    metadata?: unknown;
    query_rating?: ((SearchQueryRating) | null);
    rag_type: ClickhouseRagTypes;
    results: Array<unknown>;
    search_id: string;
    top_score: number;
    topic_id: string;
    user_id: string;
    user_message: string;
};

export type RagQueryRatingsResponse = {
    /**
     * Total number of negative RAG ratings
     */
    total_negative_ratings: number;
    /**
     * Total number of positive RAG ratings
     */
    total_positive_ratings: number;
};

export type RagQueryResponse = {
    queries: Array<RagQueryEvent>;
};

export type RagTypes = 'chosen_chunks' | 'all_chunks';

export type Range = {
    gt?: ((RangeCondition) | null);
    gte?: ((RangeCondition) | null);
    lt?: ((RangeCondition) | null);
    lte?: ((RangeCondition) | null);
};

export type RangeCondition = number;

export type RateQueryRequest = {
    metadata?: unknown;
    note?: (string) | null;
    query_id: string;
    rating: number;
};

export type ReRankOptions = 'semantic' | 'fulltext' | 'bm25' | 'cross_encoder';

export type RecommendChunksRequest = {
    filters?: ((ChunkFilter) | null);
    /**
     * The number of chunks to return. This is the number of chunks which will be returned in the response. The default is 10.
     */
    limit?: (number) | null;
    /**
     * Metadata is any metadata you want to associate w/ the event that is created from this request
     */
    metadata?: unknown;
    /**
     * The ids of the chunks to be used as negative examples for the recommendation. The chunks in this array will be used to filter out similar chunks.
     */
    negative_chunk_ids?: Array<(string)> | null;
    /**
     * The tracking_ids of the chunks to be used as negative examples for the recommendation. The chunks in this array will be used to filter out similar chunks.
     */
    negative_tracking_ids?: Array<(string)> | null;
    /**
     * The ids of the chunks to be used as positive examples for the recommendation. The chunks in this array will be used to find similar chunks.
     */
    positive_chunk_ids?: Array<(string)> | null;
    /**
     * The tracking_ids of the chunks to be used as positive examples for the recommendation. The chunks in this array will be used to find similar chunks.
     */
    positive_tracking_ids?: Array<(string)> | null;
    recommend_type?: ((RecommendType) | null);
    /**
     * Set slim_chunks to true to avoid returning the content and chunk_html of the chunks. This is useful for when you want to reduce amount of data over the wire for latency improvement (typicall 10-50ms). Default is false.
     */
    slim_chunks?: (boolean) | null;
    strategy?: ((RecommendationStrategy) | null);
    /**
     * User ID is the id of the user who is making the request. This is used to track user interactions with the recommendation results.
     */
    user_id?: (string) | null;
};

export type RecommendChunksResponseBody = {
    chunks: Array<ScoreChunk>;
    id: string;
};

export type RecommendGroupsReqPayload = {
    filters?: ((ChunkFilter) | null);
    /**
     * The number of chunks to fetch for each group. This is the number of chunks which will be returned in the response for each group. The default is 3. If this is set to a large number, we recommend setting slim_chunks to true to avoid returning the content and chunk_html of the chunks so as to reduce latency due to content download and serialization.
     */
    group_size?: (number) | null;
    /**
     * The number of groups to return. This is the number of groups which will be returned in the response. The default is 10.
     */
    limit?: (number) | null;
    /**
     * Metadata is any metadata you want to associate w/ the event that is created from this request
     */
    metadata?: unknown;
    /**
     * The ids of the groups to be used as negative examples for the recommendation. The groups in this array will be used to filter out similar groups.
     */
    negative_group_ids?: Array<(string)> | null;
    /**
     * The ids of the groups to be used as negative examples for the recommendation. The groups in this array will be used to filter out similar groups.
     */
    negative_group_tracking_ids?: Array<(string)> | null;
    /**
     * The ids of the groups to be used as positive examples for the recommendation. The groups in this array will be used to find similar groups.
     */
    positive_group_ids?: Array<(string)> | null;
    /**
     * The ids of the groups to be used as positive examples for the recommendation. The groups in this array will be used to find similar groups.
     */
    positive_group_tracking_ids?: Array<(string)> | null;
    recommend_type?: ((RecommendType) | null);
    /**
     * Set slim_chunks to true to avoid returning the content and chunk_html of the chunks. This is useful for when you want to reduce amount of data over the wire for latency improvement (typicall 10-50ms). Default is false.
     */
    slim_chunks?: (boolean) | null;
    strategy?: ((RecommendationStrategy) | null);
    /**
     * The user_id is the id of the user who is making the request. This is used to track user interactions with the rrecommendation results.
     */
    user_id?: (string) | null;
};

export type RecommendGroupsResponse = RecommendGroupsResponseBody | GroupScoreChunk;

export type RecommendGroupsResponseBody = {
    id: string;
    results: Array<SearchOverGroupsResults>;
};

export type RecommendResponseTypes = RecommendChunksResponseBody | V1RecommendChunksResponseBody;

/**
 * The type of recommendation to make. This lets you choose whether to recommend based off of `semantic` or `fulltext` similarity. The default is `semantic`.
 */
export type RecommendType = 'semantic' | 'fulltext' | 'bm25';

export type RecommendationAnalytics = {
    filter?: ((RecommendationAnalyticsFilter) | null);
    page?: (number) | null;
    threshold?: (number) | null;
    type: 'low_confidence_recommendations';
} | {
    filter?: ((RecommendationAnalyticsFilter) | null);
    has_clicks?: (boolean) | null;
    page?: (number) | null;
    sort_by?: ((RecommendationSortBy) | null);
    sort_order?: ((SortOrder) | null);
    type: 'recommendation_queries';
} | {
    request_id: string;
    type: 'query_details';
} | {
    filter?: ((RecommendationAnalyticsFilter) | null);
    granularity?: ((Granularity) | null);
    type: 'recommendation_usage_graph';
} | {
    filter?: ((RecommendationAnalyticsFilter) | null);
    granularity?: ((Granularity) | null);
    type: 'recommendations_per_user';
} | {
    filter?: ((RecommendationAnalyticsFilter) | null);
    granularity?: ((Granularity) | null);
    type: 'recommendations_ctr_rate';
} | {
    filter?: ((RecommendationAnalyticsFilter) | null);
    granularity?: ((Granularity) | null);
    type: 'recommendation_conversion_rate';
};

export type type5 = 'low_confidence_recommendations';

export type RecommendationAnalyticsFilter = {
    component_name?: (string) | null;
    date_range?: ((DateRange) | null);
    recommendation_type?: ((RecommendationType) | null);
    top_score?: ((FloatRange) | null);
};

export type RecommendationAnalyticsResponse = RecommendationsEventResponse | RecommendationEvent | RecommendationUsageGraphResponse | RecommendationsPerUserResponse | RecommendationsCTRRateResponse | RecommendationsConversionRateResponse;

export type RecommendationCTRMetrics = {
    avg_position_of_click: number;
    percent_recommendations_with_clicks: number;
    percent_recommendations_without_clicks: number;
    recommendations_with_clicks: number;
};

export type RecommendationEvent = {
    created_at: string;
    dataset_id: string;
    id: string;
    metadata?: unknown;
    negative_ids: Array<(string)>;
    negative_tracking_ids: Array<(string)>;
    positive_ids: Array<(string)>;
    positive_tracking_ids: Array<(string)>;
    recommendation_type: ClickhouseRecommendationTypes;
    request_params: unknown;
    results: Array<unknown>;
    top_score: number;
    user_id: string;
};

export type RecommendationSortBy = 'created_at' | 'top_score';

/**
 * Strategy to use for recommendations, either "average_vector" or "best_score". The default is "average_vector". The "average_vector" strategy will construct a single average vector from the positive and negative samples then use it to perform a pseudo-search. The "best_score" strategy is more advanced and navigates the HNSW with a heuristic of picking edges where the point is closer to the positive samples than it is the negatives.
 */
export type RecommendationStrategy = 'average_vector' | 'best_score';

export type RecommendationType = 'Chunk' | 'Group';

export type RecommendationUsageGraphResponse = {
    points: Array<IntegerTimePoint>;
    total_requests: number;
};

export type RecommendationsCTRRateResponse = {
    points: Array<FloatTimePoint>;
    total_ctr: number;
};

export type RecommendationsConversionRateResponse = {
    conversion_rate: number;
    points: Array<FloatTimePoint>;
};

export type RecommendationsEventResponse = {
    queries: Array<RecommendationEvent>;
};

export type RecommendationsPerUserResponse = {
    avg_recommendations_per_user: number;
    points: Array<FloatTimePoint>;
};

export type RecommendationsWithClicksCTRResponse = {
    clicked_chunk: ChunkMetadataWithPosition;
    created_at: string;
    negative_ids?: Array<(string)> | null;
    negative_tracking_ids?: Array<(string)> | null;
    positive_ids?: Array<(string)> | null;
    positive_tracking_ids?: Array<(string)> | null;
    request_id: string;
    results: Array<unknown>;
};

export type RecommendationsWithoutClicksCTRResponse = {
    created_at: string;
    negative_ids?: Array<(string)> | null;
    negative_tracking_ids?: Array<(string)> | null;
    positive_ids?: Array<(string)> | null;
    positive_tracking_ids?: Array<(string)> | null;
    request_id: string;
};

export type RegenerateMessageReqPayload = {
    /**
     * If concat user messages query is set to true, all of the user messages in the topic will be concatenated together and used as the search query. If not specified, this defaults to false. Default is false.
     */
    concat_user_messages_query?: (boolean) | null;
    context_options?: ((ContextOptions) | null);
    filters?: ((ChunkFilter) | null);
    highlight_options?: ((HighlightOptions) | null);
    llm_options?: ((LLMOptions) | null);
    /**
     * Metadata is any metadata you want to associate w/ the event that is created from this request
     */
    metadata?: unknown;
    /**
     * No result message for when there are no chunks found above the score threshold.
     */
    no_result_message?: (string) | null;
    /**
     * Only include docs used in the completion. If not specified, this defaults to false.
     */
    only_include_docs_used?: (boolean) | null;
    /**
     * Page size is the number of chunks to fetch during RAG. If 0, then no search will be performed. If specified, this will override the N retrievals to include in the dataset configuration. Default is None.
     */
    page_size?: (number) | null;
    /**
     * If true, stop words (specified in server/src/stop-words.txt in the git repo) will be removed. Queries that are entirely stop words will be preserved.
     */
    remove_stop_words?: (boolean) | null;
    /**
     * Set score_threshold to a float to filter out chunks with a score below the threshold. This threshold applies before weight and bias modifications. If not specified, this defaults to 0.0.
     */
    score_threshold?: (number) | null;
    /**
     * Query is the search query. This can be any string. The search_query will be used to create a dense embedding vector and/or sparse vector which will be used to find the result set. If not specified, will default to the last user message or HyDE if HyDE is enabled in the dataset configuration. Default is None.
     */
    search_query?: (string) | null;
    search_type?: ((SearchMethod) | null);
    sort_options?: ((SortOptions) | null);
    /**
     * The id of the topic to regenerate the last message for.
     */
    topic_id: string;
    typo_options?: ((TypoOptions) | null);
    /**
     * If use_group_search is set to true, the search will be conducted using the `search_over_groups` api. If not specified, this defaults to false.
     */
    use_group_search?: (boolean) | null;
    /**
     * If true, quoted and - prefixed words will be parsed from the queries and used as required and negated words respectively. Default is false.
     */
    use_quote_negated_terms?: (boolean) | null;
    /**
     * The user_id is the id of the user who is making the request. This is used to track user interactions with the RAG results.
     */
    user_id?: (string) | null;
};

export type RemoveChunkFromGroupReqPayload = {
    /**
     * Id of the chunk to remove from the group.
     */
    chunk_id: string;
};

export type RequestInfo = {
    request_id: string;
    request_type: CTRType;
};

export type ReturnQueuedChunk = SingleQueuedChunkResponse | BatchQueuedChunkResponse;

export type RoleProxy = 'system' | 'user' | 'assistant';

export type ScoreChunk = {
    chunk: NewChunkMetadataTypes;
    highlights?: Array<(string)> | null;
    score: number;
};

export type ScoreChunkDTO = {
    highlights?: Array<(string)> | null;
    metadata: Array<ChunkMetadataTypes>;
    score: number;
};

/**
 * Scoring options provides ways to modify the sparse or dense vector created for the query in order to change how potential matches are scored. If not specified, this defaults to no modifications.
 */
export type ScoringOptions = {
    fulltext_boost?: ((FullTextBoost) | null);
    semantic_boost?: ((SemanticBoost) | null);
};

/**
 * Options for including an openapi spec or shopify settigns
 */
export type ScrapeOptions = (CrawlOpenAPIOptions & {
    type: 'openapi';
}) | (CrawlShopifyOptions & {
    type: 'shopify';
}) | (CrawlYoutubeOptions & {
    type: 'youtube';
});

export type type6 = 'openapi';

export type ScrollChunksReqPayload = {
    filters?: ((ChunkFilter) | null);
    /**
     * Offset chunk id is the id of the chunk to start the page from. If not specified, this defaults to the first chunk in the dataset sorted by id ascending.
     */
    offset_chunk_id?: (string) | null;
    /**
     * Page size is the number of chunks to fetch. This can be used to fetch more than 10 chunks at a time.
     */
    page_size?: (number) | null;
    sort_by?: ((SortByField) | null);
};

export type ScrollChunksResponseBody = {
    chunks: Array<ChunkMetadata>;
};

export type SearchAnalytics = {
    filter?: ((SearchAnalyticsFilter) | null);
    granularity?: ((Granularity) | null);
    type: 'latency_graph';
} | {
    filter?: ((SearchAnalyticsFilter) | null);
    granularity?: ((Granularity) | null);
    type: 'search_usage_graph';
} | {
    filter?: ((SearchAnalyticsFilter) | null);
    type: 'search_metrics';
} | {
    filter?: ((SearchAnalyticsFilter) | null);
    page?: (number) | null;
    type: 'head_queries';
} | {
    filter?: ((SearchAnalyticsFilter) | null);
    page?: (number) | null;
    threshold?: (number) | null;
    type: 'low_confidence_queries';
} | {
    filter?: ((SearchAnalyticsFilter) | null);
    page?: (number) | null;
    type: 'no_result_queries';
} | {
    filter?: ((SearchAnalyticsFilter) | null);
    has_clicks?: (boolean) | null;
    page?: (number) | null;
    sort_by?: ((SearchSortBy) | null);
    sort_order?: ((SortOrder) | null);
    type: 'search_queries';
} | {
    filter?: ((SearchAnalyticsFilter) | null);
    type: 'count_queries';
} | {
    request_id: string;
    type: 'query_details';
} | {
    filter?: ((SearchAnalyticsFilter) | null);
    type: 'popular_filters';
} | {
    filter?: ((SearchAnalyticsFilter) | null);
    granularity?: ((Granularity) | null);
    type: 'ctr_metrics_over_time';
} | {
    filter?: ((SearchAnalyticsFilter) | null);
    granularity?: ((Granularity) | null);
    type: 'search_conversion_rate';
} | {
    filter?: ((SearchAnalyticsFilter) | null);
    granularity?: ((Granularity) | null);
    type: 'searches_per_user';
};

export type type7 = 'latency_graph';

export type SearchAnalyticsFilter = {
    component_name?: (string) | null;
    date_range?: ((DateRange) | null);
    query?: (string) | null;
    query_rating?: ((QueryRatingRange) | null);
    search_method?: ((SearchMethod) | null);
    search_type?: ((SearchType) | null);
    top_score?: ((FloatRange) | null);
};

export type SearchAnalyticsResponse = LatencyGraphResponse | SearchUsageGraphResponse | DatasetAnalytics | HeadQueryResponse | SearchQueryResponse | QueryCountResponse | SearchQueryEvent | PopularFiltersResponse | CTRMetricsOverTimeResponse | SearchConversionRateResponse | SearchesPerUserResponse;

export type SearchCTRMetrics = {
    avg_position_of_click: number;
    percent_searches_with_clicks: number;
    percent_searches_without_clicks: number;
    searches_with_clicks: number;
};

export type SearchChunkQueryResponseBody = {
    corrected_query?: (string) | null;
    score_chunks: Array<ScoreChunkDTO>;
    total_chunk_pages: number;
};

export type SearchChunksReqPayload = {
    /**
     * Set content_only to true to only returning the chunk_html of the chunks. This is useful for when you want to reduce amount of data over the wire for latency improvement (typically 10-50ms). Default is false.
     */
    content_only?: (boolean) | null;
    filters?: ((ChunkFilter) | null);
    /**
     * Get total page count for the query accounting for the applied filters. Defaults to false, but can be set to true when the latency penalty is acceptable (typically 50-200ms).
     */
    get_total_pages?: (boolean) | null;
    highlight_options?: ((HighlightOptions) | null);
    /**
     * Metadata is any metadata you want to associate w/ the event that is created from this request
     */
    metadata?: unknown;
    /**
     * Page of chunks to fetch. Page is 1-indexed.
     */
    page?: (number) | null;
    /**
     * Page size is the number of chunks to fetch. This can be used to fetch more than 10 chunks at a time.
     */
    page_size?: (number) | null;
    query: QueryTypes;
    /**
     * If true, stop words (specified in server/src/stop-words.txt in the git repo) will be removed. Queries that are entirely stop words will be preserved.
     */
    remove_stop_words?: (boolean) | null;
    /**
     * Set score_threshold to a float to filter out chunks with a score below the threshold for cosine distance metric. For Manhattan Distance, Euclidean Distance, and Dot Product, it will filter out scores above the threshold distance. This threshold applies before weight and bias modifications. If not specified, this defaults to no threshold. A threshold of 0 will default to no threshold.
     */
    score_threshold?: (number) | null;
    scoring_options?: ((ScoringOptions) | null);
    search_type: SearchMethod;
    /**
     * Set slim_chunks to true to avoid returning the content and chunk_html of the chunks. This is useful for when you want to reduce amount of data over the wire for latency improvement (typically 10-50ms). Default is false.
     */
    slim_chunks?: (boolean) | null;
    sort_options?: ((SortOptions) | null);
    typo_options?: ((TypoOptions) | null);
    /**
     * If true, quoted and - prefixed words will be parsed from the queries and used as required and negated words respectively. Default is false.
     */
    use_quote_negated_terms?: (boolean) | null;
    /**
     * User ID is the id of the user who is making the request. This is used to track user interactions with the search results.
     */
    user_id?: (string) | null;
};

export type SearchClusterResponse = {
    clusters: Array<SearchClusterTopics>;
};

export type SearchClusterTopics = {
    avg_score: number;
    created_at: string;
    dataset_id: string;
    density: number;
    id: string;
    topic: string;
};

export type SearchConversionRateResponse = {
    conversion_rate: number;
    points: Array<FloatTimePoint>;
};

export type SearchGroupResponseTypes = SearchWithinGroupResponseBody | SearchWithinGroupResults;

export type SearchMethod = 'fulltext' | 'semantic' | 'hybrid' | 'bm25';

export type SearchModalities = {
    image_url: string;
    llm_prompt?: (string) | null;
} | string | {
    audio_base64: string;
};

export type SearchOverGroupsReqPayload = {
    filters?: ((ChunkFilter) | null);
    /**
     * Get total page count for the query accounting for the applied filters. Defaults to false, but can be set to true when the latency penalty is acceptable (typically 50-200ms).
     */
    get_total_pages?: (boolean) | null;
    /**
     * Group_size is the number of chunks to fetch for each group. The default is 3. If a group has less than group_size chunks, all chunks will be returned. If this is set to a large number, we recommend setting slim_chunks to true to avoid returning the content and chunk_html of the chunks so as to lower the amount of time required for content download and serialization.
     */
    group_size?: (number) | null;
    highlight_options?: ((HighlightOptions) | null);
    /**
     * Metadata is any metadata you want to associate w/ the event that is created from this request
     */
    metadata?: unknown;
    /**
     * Page of group results to fetch. Page is 1-indexed.
     */
    page?: (number) | null;
    /**
     * Page size is the number of group results to fetch. The default is 10.
     */
    page_size?: (number) | null;
    query: QueryTypes;
    /**
     * If true, stop words (specified in server/src/stop-words.txt in the git repo) will be removed. Queries that are entirely stop words will be
     * preserved.
     */
    remove_stop_words?: (boolean) | null;
    /**
     * Set score_threshold to a float to filter out chunks with a score below the threshold. This threshold applies before weight and bias modifications. If not specified, this defaults to 0.0.
     */
    score_threshold?: (number) | null;
    search_type: SearchMethod;
    /**
     * Set slim_chunks to true to avoid returning the content and chunk_html of the chunks. This is useful for when you want to reduce amount of data over the wire for latency improvement (typicall 10-50ms). Default is false.
     */
    slim_chunks?: (boolean) | null;
    sort_options?: ((SortOptions) | null);
    typo_options?: ((TypoOptions) | null);
    /**
     * If true, quoted and - prefixed words will be parsed from the queries and used as required and negated words respectively. Default is false.
     */
    use_quote_negated_terms?: (boolean) | null;
    /**
     * The user_id is the id of the user who is making the request. This is used to track user interactions with the search results.
     */
    user_id?: (string) | null;
};

export type SearchOverGroupsResponseBody = {
    corrected_query?: (string) | null;
    id: string;
    results: Array<SearchOverGroupsResults>;
    total_pages: number;
};

export type SearchOverGroupsResponseTypes = SearchOverGroupsResponseBody | DeprecatedSearchOverGroupsResponseBody;

export type SearchOverGroupsResults = {
    chunks: Array<ScoreChunk>;
    file_id?: (string) | null;
    group: ChunkGroup;
};

export type SearchQueriesWithClicksCTRResponse = {
    clicked_chunk: ChunkMetadataWithPosition;
    created_at: string;
    query: string;
    request_id: string;
    results: Array<unknown>;
};

export type SearchQueriesWithoutClicksCTRResponse = {
    created_at: string;
    query: string;
    request_id: string;
};

export type SearchQueryEvent = {
    created_at: string;
    dataset_id: string;
    id: string;
    latency: number;
    metadata?: unknown;
    query: string;
    query_rating?: ((SearchQueryRating) | null);
    request_params: unknown;
    results: Array<unknown>;
    search_type: ClickhouseSearchTypes;
    top_score: number;
    user_id: string;
};

export type SearchQueryRating = {
    metadata?: unknown;
    note?: (string) | null;
    rating: number;
};

export type SearchQueryResponse = {
    queries: Array<SearchQueryEvent>;
};

export type SearchResponseBody = {
    chunks: Array<ScoreChunk>;
    corrected_query?: (string) | null;
    id: string;
    total_pages: number;
};

export type SearchResponseTypes = SearchResponseBody | SearchChunkQueryResponseBody;

export type SearchResultType = ScoreChunkDTO | GroupScoreChunk;

export type SearchSortBy = 'created_at' | 'latency' | 'top_score';

export type SearchType = 'search' | 'autocomplete' | 'search_over_groups' | 'search_within_groups';

export type SearchTypeCount = {
    search_count: number;
    search_method: string;
    search_type: string;
};

export type SearchUsageGraphResponse = {
    points: Array<IntegerTimePoint>;
    total_searches: number;
};

export type SearchWithinGroupReqPayload = {
    /**
     * Set content_only to true to only returning the chunk_html of the chunks. This is useful for when you want to reduce amount of data over the wire for latency improvement (typically 10-50ms). Default is false.
     */
    content_only?: (boolean) | null;
    filters?: ((ChunkFilter) | null);
    /**
     * Get total page count for the query accounting for the applied filters. Defaults to false, but can be set to true when the latency penalty is acceptable (typically 50-200ms).
     */
    get_total_pages?: (boolean) | null;
    /**
     * Group specifies the group to search within. Results will only consist of chunks which are bookmarks within the specified group.
     */
    group_id?: (string) | null;
    /**
     * Group_tracking_id specifies the group to search within by tracking id. Results will only consist of chunks which are bookmarks within the specified group. If both group_id and group_tracking_id are provided, group_id will be used.
     */
    group_tracking_id?: (string) | null;
    highlight_options?: ((HighlightOptions) | null);
    /**
     * Metadata is any metadata you want to associate w/ the event that is created from this request
     */
    metadata?: unknown;
    /**
     * The page of chunks to fetch. Page is 1-indexed.
     */
    page?: (number) | null;
    /**
     * The page size is the number of chunks to fetch. This can be used to fetch more than 10 chunks at a time.
     */
    page_size?: (number) | null;
    query: QueryTypes;
    /**
     * If true, stop words (specified in server/src/stop-words.txt in the git repo) will be removed. Queries that are entirely stop words will be preserved.
     */
    remove_stop_words?: (boolean) | null;
    /**
     * Set score_threshold to a float to filter out chunks with a score below the threshold. This threshold applies before weight and bias modifications. If not specified, this defaults to 0.0.
     */
    score_threshold?: (number) | null;
    search_type: SearchMethod;
    /**
     * Set slim_chunks to true to avoid returning the content and chunk_html of the chunks. This is useful for when you want to reduce amount of data over the wire for latency improvement (typicall 10-50ms). Default is false.
     */
    slim_chunks?: (boolean) | null;
    sort_options?: ((SortOptions) | null);
    typo_options?: ((TypoOptions) | null);
    /**
     * If true, quoted and - prefixed words will be parsed from the queries and used as required and negated words respectively. Default is false.
     */
    use_quote_negated_terms?: (boolean) | null;
    /**
     * The user_id is the id of the user who is making the request. This is used to track user interactions with the search results.
     */
    user_id?: (string) | null;
};

export type SearchWithinGroupResponseBody = {
    chunks: Array<ScoreChunk>;
    corrected_query?: (string) | null;
    id: string;
    total_pages: number;
};

export type SearchWithinGroupResults = {
    bookmarks: Array<ScoreChunkDTO>;
    corrected_query?: (string) | null;
    group: ChunkGroupAndFileId;
    total_pages: number;
};

export type SearchesPerUserResponse = {
    avg_searches_per_user: number;
    points: Array<FloatTimePoint>;
};

/**
 * Semantic boosting moves the dense vector of the chunk in the direction of the distance phrase for semantic search. I.e. you can force a cluster by moving every chunk for a PDF closer to its title or push a chunk with a chunk_html of "iphone" 25% closer to the term "flagship" by using the distance phrase "flagship" and a distance factor of 0.25. Conceptually it's drawing a line (euclidean/L2 distance) between the vector for the innerText of the chunk_html and distance_phrase then moving the vector of the chunk_html distance_factor*L2Distance closer to or away from the distance_phrase point along the line between the two points.
 */
export type SemanticBoost = {
    /**
     * Arbitrary float (positive or negative) specifying the multiplicate factor to apply before summing the phrase vector with the chunk_html embedding vector
     */
    distance_factor: number;
    /**
     * Terms to embed in order to create the vector which is weighted summed with the chunk_html embedding vector
     */
    phrase: string;
};

export type SingleProductOptions = {
    groupTrackingId?: (string) | null;
    productDescriptionHtml?: (string) | null;
    productName?: (string) | null;
    productPrimaryImageUrl?: (string) | null;
    productQuestions?: Array<(string)> | null;
    productTrackingId?: (string) | null;
    recSearchQuery?: (string) | null;
};

export type SingleQueuedChunkResponse = {
    chunk_metadata: ChunkMetadata;
};

export type Sitemap = {
    changefreq: string;
};

export type SlimChunkMetadata = {
    created_at: string;
    dataset_id: string;
    id: string;
    image_urls?: Array<((string) | null)> | null;
    link?: (string) | null;
    location?: ((GeoInfo) | null);
    metadata?: unknown;
    num_value?: (number) | null;
    tag_set?: (string) | null;
    time_stamp?: (string) | null;
    tracking_id?: (string) | null;
    updated_at: string;
    weight: number;
};

export type SlimChunkMetadataWithArrayTagSet = {
    created_at: string;
    dataset_id: string;
    id: string;
    image_urls?: Array<((string) | null)> | null;
    link?: (string) | null;
    location?: ((GeoInfo) | null);
    metadata?: unknown;
    num_value?: (number) | null;
    tag_set?: Array<(string)> | null;
    time_stamp?: (string) | null;
    tracking_id?: (string) | null;
    updated_at: string;
    weight: number;
};

export type SlimChunkMetadataWithScore = {
    created_at: string;
    id: string;
    link?: (string) | null;
    metadata?: unknown;
    score: number;
    tag_set?: (string) | null;
    time_stamp?: (string) | null;
    tracking_id?: (string) | null;
    updated_at: string;
    weight: number;
};

export type SlimUser = {
    created_at: string;
    email: string;
    id: string;
    name?: (string) | null;
    orgs: Array<Organization>;
    user_orgs: Array<UserOrganization>;
};

export type SortByField = {
    direction?: ((SortOrder) | null);
    /**
     * Field to sort by. This has to be a numeric field with a Qdrant `Range` index on it. i.e. num_value and timestamp
     */
    field: string;
    /**
     * How many results to pull in before the sort
     */
    prefetch_amount?: (number) | null;
};

export type SortBySearchType = {
    /**
     * How many results to pull in before the rerabj
     */
    prefetch_amount?: (number) | null;
    /**
     * Query to use for prefetching defaults to the search query
     */
    rerank_query?: (string) | null;
    rerank_type: ReRankOptions;
};

/**
 * Sort Options lets you specify different methods to rerank the chunks in the result set. If not specified, this defaults to the score of the chunks.
 */
export type SortOptions = {
    location_bias?: ((GeoInfoWithBias) | null);
    mmr?: ((MmrOptions) | null);
    /**
     * Recency Bias lets you determine how much of an effect the recency of chunks will have on the search results. If not specified, this defaults to 0.0. We recommend setting this to 1.0 for a gentle reranking of the results, >3.0 for a strong reranking of the results.
     */
    recency_bias?: (number) | null;
    sort_by?: ((QdrantSortBy) | null);
    /**
     * Tag weights is a JSON object which can be used to boost the ranking of chunks with certain tags. This is useful for when you want to be able to bias towards chunks with a certain tag on the fly. The keys are the tag names and the values are the weights.
     */
    tag_weights?: {
        [key: string]: (number);
    } | null;
    /**
     * Set use_weights to true to use the weights of the chunks in the result set in order to sort them. If not specified, this defaults to true.
     */
    use_weights?: (boolean) | null;
};

export type SortOrder = 'desc' | 'asc';

export type SplitHtmlResponse = {
    chunks: Array<ChunkedContent>;
};

export type StripeInvoice = {
    created_at: string;
    hosted_invoice_url: string;
    id: string;
    org_id: string;
    status: string;
    stripe_id?: (string) | null;
    total: number;
};

export type StripePlan = {
    amount: number;
    chunk_count: number;
    created_at: string;
    dataset_count: number;
    file_storage: number;
    id: string;
    message_count: number;
    name: string;
    stripe_id: string;
    updated_at: string;
    user_count: number;
    visible: boolean;
};

export type StripeSubscription = {
    created_at: string;
    current_period_end?: (string) | null;
    id: string;
    organization_id: string;
    plan_id: string;
    stripe_id: string;
    updated_at: string;
};

export type SuggestType = 'question' | 'keyword' | 'semantic';

export type SuggestedQueriesReqPayload = {
    /**
     * Context is the context of the query. This can be any string under 15 words and 200 characters. The context will be used to generate the suggested queries. Defaults to None.
     */
    context?: (string) | null;
    filters?: ((ChunkFilter) | null);
    is_followup?: (boolean) | null;
    /**
     * The query to base the generated suggested queries off of using RAG. A hybrid search for 10 chunks from your dataset using this query will be performed and the context of the chunks will be used to generate the suggested queries.
     */
    query?: (string) | null;
    search_type?: ((SearchMethod) | null);
    suggestion_type?: ((SuggestType) | null);
    /**
     * The number of suggested queries to create, defaults to 10
     */
    suggestions_to_create?: (number) | null;
};

export type SuggestedQueriesResponse = {
    queries: Array<(string)>;
};

export type TagsWithCount = {
    /**
     * Number of chunks in the dataset with that tag
     */
    count: number;
    /**
     * Content of the tag
     */
    tag: string;
};

/**
 * Function for a LLM tool call
 */
export type ToolFunction = {
    /**
     * Description of the function.
     */
    description: string;
    /**
     * Name of the function.
     */
    name: string;
    /**
     * Parameters of the function.
     */
    parameters: Array<ToolFunctionParameter>;
};

/**
 * Function parameter for a LLM tool call
 */
export type ToolFunctionParameter = {
    /**
     * The description of the tag.
     */
    description: string;
    /**
     * Name of the parameter.
     */
    name: string;
    parameter_type: ToolFunctionParameterType;
};

/**
 * Type of a given parameter for a LLM tool call
 */
export type ToolFunctionParameterType = 'number' | 'boolean';

export type TopComponents = {
    component_name: string;
    count: number;
};

export type TopComponentsResponse = {
    top_components: Array<TopComponents>;
};

export type TopDatasetsRequestTypes = 'search' | 'rag' | 'recommendation';

export type TopDatasetsResponse = {
    dataset_id: string;
    dataset_tracking_id?: (string) | null;
    total_queries: number;
};

export type TopPages = {
    count: number;
    page: string;
};

export type TopPagesResponse = {
    top_pages: Array<TopPages>;
};

export type Topic = {
    created_at: string;
    dataset_id: string;
    deleted: boolean;
    id: string;
    name: string;
    owner_id: string;
    updated_at: string;
};

export type TopicAnalyticsFilter = {
    component_name?: (string) | null;
    date_range?: ((DateRange) | null);
    hallucination_score?: ((FloatRange) | null);
    query?: (string) | null;
    query_rating?: ((QueryRatingRange) | null);
    rag_type?: ((RagTypes) | null);
    top_score?: ((FloatRange) | null);
};

export type TopicAnalyticsSummary = {
    avg_hallucination_score: number;
    avg_query_rating?: (number) | null;
    avg_top_score: number;
    created_at: string;
    id: string;
    message_count: number;
    name: string;
    owner_id: string;
    topic_id: string;
    updated_at: string;
};

export type TopicDetailsResponse = {
    messages: Array<RagQueryEvent>;
    topic: TopicQuery;
};

export type TopicQueriesResponse = {
    topics: Array<TopicAnalyticsSummary>;
};

export type TopicQuery = {
    created_at: string;
    dataset_id: string;
    id: string;
    metadata?: unknown;
    name: string;
    owner_id: string;
    topic_id: string;
    updated_at: string;
};

export type TopicsOverTimeResponse = {
    points: Array<IntegerTimePoint>;
    total_topics: number;
};

export type TotalUniqueUsersResponse = {
    points: Array<IntegerTimePoint>;
    total_unique_users: number;
};

/**
 * Typo Options lets you specify different methods to correct typos in the query. If not specified, typos will not be corrected.
 */
export type TypoOptions = {
    /**
     * Set correct_typos to true to correct typos in the query. If not specified, this defaults to false.
     */
    correct_typos?: (boolean) | null;
    /**
     * Words that should not be corrected. If not specified, this defaults to an empty list.
     */
    disable_on_word?: Array<(string)> | null;
    one_typo_word_range?: ((TypoRange) | null);
    /**
     * Auto-require non-english words present in the dataset to exist in each results chunk_html text. If not specified, this defaults to true.
     */
    prioritize_domain_specifc_words?: (boolean) | null;
    two_typo_word_range?: ((TypoRange) | null);
};

/**
 * The TypoRange struct is used to specify the range of which the query will be corrected if it has a typo.
 */
export type TypoRange = {
    /**
     * The maximum number of characters that the query will be corrected if it has a typo. If not specified, this defaults to 8.
     */
    max?: (number) | null;
    /**
     * The minimum number of characters that the query will be corrected if it has a typo. If not specified, this defaults to 5.
     */
    min: number;
};

export type UpdateAllOrgDatasetConfigsReqPayload = {
    /**
     * The new configuration for all datasets in the organization. Only the specified keys in the configuration object will be changed per dataset such that you can preserve dataset unique values.
     */
    dataset_config: unknown;
};

export type UpdateChunkByTrackingIdData = {
    /**
     * HTML content of the chunk you want to update. This can also be plaintext. The innerText of the HTML will be used to create the embedding vector. The point of using HTML is for convienience, as some users have applications where users submit HTML content. If no chunk_html is provided, the existing chunk_html will be used.
     */
    chunk_html?: (string) | null;
    /**
     * Convert HTML to raw text before processing to avoid adding noise to the vector embeddings. By default this is true. If you are using HTML content that you want to be included in the vector embeddings, set this to false.
     */
    convert_html_to_text?: (boolean) | null;
    /**
     * Group ids are the ids of the groups that the chunk should be placed into. This is useful for when you want to update a chunk and add it to a group or multiple groups in one request.
     */
    group_ids?: Array<(string)> | null;
    /**
     * Group tracking_ids are the tracking_ids of the groups that the chunk should be placed into. This is useful for when you want to update a chunk and add it to a group or multiple groups in one request.
     */
    group_tracking_ids?: Array<(string)> | null;
    /**
     * Link of the chunk you want to update. This can also be any string. Frequently, this is a link to the source of the chunk. The link value will not affect the embedding creation. If no link is provided, the existing link will be used.
     */
    link?: (string) | null;
    /**
     * The metadata is a JSON object which can be used to filter chunks. This is useful for when you want to filter chunks by arbitrary metadata. Unlike with tag filtering, there is a performance hit for filtering on metadata. If no metadata is provided, the existing metadata will be used.
     */
    metadata?: unknown;
    /**
     * Time_stamp should be an ISO 8601 combined date and time without timezone. It is used for time window filtering and recency-biasing search results. If no time_stamp is provided, the existing time_stamp will be used.
     */
    time_stamp?: (string) | null;
    /**
     * Tracking_id of the chunk you want to update. This is required to match an existing chunk.
     */
    tracking_id: string;
    /**
     * Weight is a float which can be used to bias search results. This is useful for when you want to bias search results for a chunk. The magnitude only matters relative to other chunks in the chunk's dataset dataset. If no weight is provided, the existing weight will be used.
     */
    weight?: (number) | null;
};

export type UpdateChunkGroupReqPayload = {
    /**
     * Description to assign to the chunk_group. Convenience field for you to avoid having to remember what the group is for. If not provided, the description will not be updated.
     */
    description?: (string) | null;
    /**
     * Id of the chunk_group to update.
     */
    group_id?: (string) | null;
    /**
     * Optional metadata to assign to the chunk_group. This is a JSON object that can store any additional information you want to associate with the chunks inside of the chunk_group.
     */
    metadata?: unknown;
    /**
     * Name to assign to the chunk_group. Does not need to be unique. If not provided, the name will not be updated.
     */
    name?: (string) | null;
    /**
     * Optional tags to assign to the chunk_group. This is a list of strings that can be used to categorize the chunks inside the chunk_group.
     */
    tag_set?: Array<(string)> | null;
    /**
     * Tracking Id of the chunk_group to update.
     */
    tracking_id?: (string) | null;
    /**
     * Flag to update the chunks in the group. If true, each chunk in the group will be updated
     * by appending the group's tags to the chunk's tags. Default is false.
     */
    update_chunks?: (boolean) | null;
};

export type UpdateChunkReqPayload = {
    /**
     * HTML content of the chunk you want to update. This can also be plaintext. The innerText of the HTML will be used to create the embedding vector. The point of using HTML is for convienience, as some users have applications where users submit HTML content. If no chunk_html is provided, the existing chunk_html will be used.
     */
    chunk_html?: (string) | null;
    /**
     * Id of the chunk you want to update. You can provide either the chunk_id or the tracking_id. If both are provided, the chunk_id will be used.
     */
    chunk_id?: (string) | null;
    /**
     * Convert HTML to raw text before processing to avoid adding noise to the vector embeddings. By default this is true. If you are using HTML content that you want to be included in the vector embeddings, set this to false.
     */
    convert_html_to_text?: (boolean) | null;
    fulltext_boost?: ((FullTextBoost) | null);
    /**
     * Group ids are the ids of the groups that the chunk should be placed into. This is useful for when you want to update a chunk and add it to a group or multiple groups in one request.
     */
    group_ids?: Array<(string)> | null;
    /**
     * Group tracking_ids are the tracking_ids of the groups that the chunk should be placed into. This is useful for when you want to update a chunk and add it to a group or multiple groups in one request.
     */
    group_tracking_ids?: Array<(string)> | null;
    /**
     * Image urls are a list of urls to images that are associated with the chunk. This is useful for when you want to associate images with a chunk. If no image_urls are provided, the existing image_urls will be used.
     */
    image_urls?: Array<(string)> | null;
    /**
     * Link of the chunk you want to update. This can also be any string. Frequently, this is a link to the source of the chunk. The link value will not affect the embedding creation. If no link is provided, the existing link will be used.
     */
    link?: (string) | null;
    location?: ((GeoInfo) | null);
    /**
     * The metadata is a JSON object which can be used to filter chunks. This is useful for when you want to filter chunks by arbitrary metadata. Unlike with tag filtering, there is a performance hit for filtering on metadata. If no metadata is provided, the existing metadata will be used.
     */
    metadata?: unknown;
    /**
     * Num value is an arbitrary numerical value that can be used to filter chunks. This is useful for when you want to filter chunks by numerical value. If no num_value is provided, the existing num_value will be used.
     */
    num_value?: (number) | null;
    semantic_boost?: ((SemanticBoost) | null);
    /**
     * Tag set is a list of tags. This can be used to filter chunks by tag. Unlike with metadata filtering, HNSW indices will exist for each tag such that there is not a performance hit for filtering on them. If no tag_set is provided, the existing tag_set will be used.
     */
    tag_set?: Array<(string)> | null;
    /**
     * Time_stamp should be an ISO 8601 combined date and time without timezone. It is used for time window filtering and recency-biasing search results. If no time_stamp is provided, the existing time_stamp will be used.
     */
    time_stamp?: (string) | null;
    /**
     * Tracking_id of the chunk you want to update. This is required to match an existing chunk.
     */
    tracking_id?: (string) | null;
    /**
     * Weight is a float which can be used to bias search results. This is useful for when you want to bias search results for a chunk. The magnitude only matters relative to other chunks in the chunk's dataset dataset. If no weight is provided, the existing weight will be used.
     */
    weight?: (number) | null;
};

export type UpdateCrawlReqPayload = {
    /**
     * Crawl ID to update
     */
    crawl_id: string;
    crawl_options: CrawlOptions;
};

export type UpdateDatasetReqPayload = {
    /**
     * The id of the dataset you want to update.
     */
    dataset_id?: (string) | null;
    /**
     * The new name of the dataset. Must be unique within the organization. If not provided, the name will not be updated.
     */
    dataset_name?: (string) | null;
    /**
     * Optional new tracking ID for the dataset. Can be used to track the dataset in external systems. Must be unique within the organization. If not provided, the tracking ID will not be updated. Strongly recommended to not use a valid uuid value as that will not work with the TR-Dataset header.
     */
    new_tracking_id?: (string) | null;
    server_configuration?: ((DatasetConfigurationDTO) | null);
    /**
     * The tracking ID of the dataset you want to update.
     */
    tracking_id?: (string) | null;
};

export type UpdateGroupByTrackingIDReqPayload = {
    /**
     * Description to assign to the chunk_group. Convenience field for you to avoid having to remember what the group is for. If not provided, the description will not be updated.
     */
    description?: (string) | null;
    /**
     * Optional metadata to assign to the chunk_group. This is a JSON object that can store any additional information you want to associate with the chunks inside of the chunk_group.
     */
    metadata?: unknown;
    /**
     * Name to assign to the chunk_group. Does not need to be unique. If not provided, the name will not be updated.
     */
    name?: (string) | null;
    /**
     * Optional tags to assign to the chunk_group. This is a list of strings that can be used to categorize the chunks inside the chunk_group.
     */
    tag_set?: Array<(string)> | null;
    /**
     * Tracking Id of the chunk_group to update.
     */
    tracking_id: string;
};

export type UpdateOrganizationReqPayload = {
    /**
     * The new name of the organization. If not provided, the name will not be updated.
     */
    name?: (string) | null;
    /**
     * New details for the partnership configuration. If not provided, the partnership configuration will not be updated.
     */
    partner_configuration?: unknown;
};

export type UpdateTopicReqPayload = {
    /**
     * The new name of the topic. A name is not generated from this field, it is used as-is.
     */
    name: string;
    /**
     * The id of the topic to target.
     */
    topic_id: string;
};

export type UpdateUserOrgRoleReqPayload = {
    /**
     * Either 0 (user), 1 (admin), or 2 (owner). If not provided, the current role will be used. The auth'ed user must have a role greater than or equal to the role being assigned.
     */
    role: number;
    /**
     * The id of the user to update, if not provided, the auth'ed user will be updated. If provided, the role of the auth'ed user or api key must be an admin (1) or owner (2) of the organization.
     */
    user_id?: (string) | null;
};

export type UploadFileReqPayload = {
    /**
     * Base64 encoded file.
     */
    base64_file: string;
    /**
     * Create chunks is a boolean which determines whether or not to create chunks from the file. If false, you can manually chunk the file and send the chunks to the create_chunk endpoint with the file_id to associate chunks with the file. Meant mostly for advanced users.
     */
    create_chunks?: (boolean) | null;
    /**
     * Description is an optional convience field so you do not have to remember what the file contains or is about. It will be included on the group resulting from the file which will hold its chunk.
     */
    description?: (string) | null;
    /**
     * Name of the file being uploaded, including the extension.
     */
    file_name: string;
    /**
     * Group tracking id is an optional field which allows you to specify the tracking id of the group that is created from the file. Chunks created will be created with the tracking id of `group_tracking_id|<index of chunk>`
     */
    group_tracking_id?: (string) | null;
    /**
     * Link to the file. This can also be any string. This can be used to filter when searching for the file's resulting chunks. The link value will not affect embedding creation.
     */
    link?: (string) | null;
    /**
     * Metadata is a JSON object which can be used to filter chunks. This is useful for when you want to filter chunks by arbitrary metadata. Unlike with tag filtering, there is a performance hit for filtering on metadata. Will be passed down to the file's chunks.
     */
    metadata?: unknown;
    pdf2md_options?: ((Pdf2MdOptions) | null);
    /**
     * Rebalance chunks is an optional field which allows you to specify whether or not to rebalance the chunks created from the file. If not specified, the default true is used. If true, Trieve will evenly distribute remainder splits across chunks such that 66 splits with a `target_splits_per_chunk` of 20 will result in 3 chunks with 22 splits each.
     */
    rebalance_chunks?: (boolean) | null;
    /**
     * Split average will automatically split your file into multiple chunks and average all of the resulting vectors into a single output chunk. Default is false. Explicitly enabling this will cause each file to only produce a single chunk.
     */
    split_avg?: (boolean) | null;
    /**
     * Split delimiters is an optional field which allows you to specify the delimiters to use when splitting the file before chunking the text. If not specified, the default [.!?\n] are used to split into sentences. However, you may want to use spaces or other delimiters.
     */
    split_delimiters?: Array<(string)> | null;
    /**
     * Tag set is a comma separated list of tags which will be passed down to the chunks made from the file. Tags are used to filter chunks when searching. HNSW indices are created for each tag such that there is no performance loss when filtering on them.
     */
    tag_set?: Array<(string)> | null;
    /**
     * Target splits per chunk. This is an optional field which allows you to specify the number of splits you want per chunk. If not specified, the default 20 is used. However, you may want to use a different number.
     */
    target_splits_per_chunk?: (number) | null;
    /**
     * Time stamp should be an ISO 8601 combined date and time without timezone. Time_stamp is used for time window filtering and recency-biasing search results. Will be passed down to the file's chunks.
     */
    time_stamp?: (string) | null;
};

export type UploadFileResponseBody = {
    file_metadata: File;
};

export type UploadHtmlPageReqPayload = {
    data: Document;
    metadata: unknown;
    scrapeId: string;
};

export type UserApiKey = {
    api_key_hash?: (string) | null;
    blake3_hash?: (string) | null;
    created_at: string;
    dataset_ids?: Array<((string) | null)> | null;
    expires_at?: (string) | null;
    id: string;
    name: string;
    organization_ids?: Array<((string) | null)> | null;
    params?: unknown;
    role: number;
    scopes?: Array<((string) | null)> | null;
    updated_at: string;
    user_id: string;
};

export type UserOrganization = {
    created_at: string;
    id: string;
    organization_id: string;
    role: number;
    updated_at: string;
    user_id: string;
};

export type V1RecommendChunksResponseBody = Array<ChunkMetadataWithScore>;

export type WorkerEvent = {
    created_at: string;
    dataset_id: string;
    event_data: string;
    event_type: string;
    id: string;
};

export type SendCtrDataData = {
    /**
     * JSON request payload to send CTR data
     */
    requestBody: CTRDataRequestBody;
    /**
     * The dataset id or tracking_id to use for the request. We assume you intend to use an id if the value is a valid uuid.
     */
    trDataset: string;
};

export type SendCtrDataResponse = (void);

export type SendEventDataData = {
    /**
     * JSON request payload to send event data
     */
    requestBody: EventTypes;
    /**
     * The dataset id or tracking_id to use for the request. We assume you intend to use an id if the value is a valid uuid.
     */
    trDataset: string;
};

export type SendEventDataResponse = (void);

export type GetAllEventsData = {
    /**
     * JSON request payload to filter the events
     */
    requestBody: GetEventsRequestBody;
};

export type GetAllEventsResponse = (GetEventsResponseBody);

export type GetComponentAnalyticsData = {
    /**
     * JSON request payload to filter the graph
     */
    requestBody: ComponentAnalytics;
    /**
     * The dataset id or tracking_id to use for the request. We assume you intend to use an id if the value is a valid uuid.
     */
    trDataset: string;
};

export type GetComponentAnalyticsResponse = (ComponentAnalyticsResponse);

export type GetCtrAnalyticsData = {
    /**
     * JSON request payload to filter the graph
     */
    requestBody: CTRAnalytics;
    /**
     * The dataset id or tracking_id to use for the request. We assume you intend to use an id if the value is a valid uuid.
     */
    trDataset: string;
};

export type GetCtrAnalyticsResponse = (CTRAnalyticsResponse);

export type GetEventByIdData = {
    /**
     * The event id to use for the request
     */
    eventId: string;
    /**
     * The dataset id or tracking_id to use for the request. We assume you intend to use an id if the value is a valid uuid.
     */
    trDataset: string;
};

export type GetEventByIdResponse = (EventData);

export type GetRagAnalyticsData = {
    /**
     * JSON request payload to filter the graph
     */
    requestBody: RAGAnalytics;
    /**
     * The dataset id or tracking_id to use for the request. We assume you intend to use an id if the value is a valid uuid.
     */
    trDataset: string;
};

export type GetRagAnalyticsResponse = (RAGAnalyticsResponse);

export type SetRagQueryRatingData = {
    /**
     * JSON request payload to rate a RAG query
     */
    requestBody: RateQueryRequest;
    /**
     * The dataset id or tracking_id to use for the request. We assume you intend to use an id if the value is a valid uuid.
     */
    trDataset: string;
};

export type SetRagQueryRatingResponse = (void);

export type GetRecommendationAnalyticsData = {
    /**
     * JSON request payload to filter the graph
     */
    requestBody: RecommendationAnalytics;
    /**
     * The dataset id or tracking_id to use for the request. We assume you intend to use an id if the value is a valid uuid.
     */
    trDataset: string;
};

export type GetRecommendationAnalyticsResponse = (RecommendationAnalyticsResponse);

export type GetSearchAnalyticsData = {
    /**
     * JSON request payload to filter the graph
     */
    requestBody: SearchAnalytics;
    /**
     * The dataset id or tracking_id to use for the request. We assume you intend to use an id if the value is a valid uuid.
     */
    trDataset: string;
};

export type GetSearchAnalyticsResponse = (SearchAnalyticsResponse);

export type SetSearchQueryRatingData = {
    /**
     * JSON request payload to rate a search query
     */
    requestBody: RateQueryRequest;
    /**
     * The dataset id or tracking_id to use for the request. We assume you intend to use an id if the value is a valid uuid.
     */
    trDataset: string;
};

export type SetSearchQueryRatingResponse = (void);

export type GetClusterAnalyticsData = {
    /**
     * JSON request payload to filter the graph
     */
    requestBody: ClusterAnalytics;
    /**
     * The dataset id or tracking_id to use for the request. We assume you intend to use an id if the value is a valid uuid.
     */
    trDataset: string;
};

export type GetClusterAnalyticsResponse = (ClusterAnalyticsResponse);

export type GetTopDatasetsData = {
    /**
     * JSON request payload to filter the top datasets
     */
    requestBody: GetTopDatasetsRequestBody;
    /**
     * The organization id to use for the request
     */
    trOrganization: string;
};

export type GetTopDatasetsResponse = (Array<TopDatasetsResponse>);

export type LoginData = {
    /**
     * Code sent via email as a result of successful call to send_invitation
     */
    invCode?: (string) | null;
    /**
     * ID of organization to authenticate into
     */
    organizationId?: (string) | null;
    /**
     * URL to redirect to after successful login
     */
    redirectUri?: (string) | null;
};

export type LogoutResponse = (void);

export type CallbackResponse = (SlimUser);

export type GetMeResponse = (SlimUser);

export type CreateChunkData = {
    /**
     * JSON request payload to create a new chunk (chunk)
     */
    requestBody: CreateChunkReqPayloadEnum;
    /**
     * The dataset id or tracking_id to use for the request. We assume you intend to use an id if the value is a valid uuid.
     */
    trDataset: string;
};

export type CreateChunkResponse = (ReturnQueuedChunk);

export type UpdateChunkData = {
    /**
     * JSON request payload to update a chunk (chunk)
     */
    requestBody: UpdateChunkReqPayload;
    /**
     * The dataset id or tracking_id to use for the request. We assume you intend to use an id if the value is a valid uuid.
     */
    trDataset: string;
};

export type UpdateChunkResponse = (void);

export type BulkDeleteChunkData = {
    /**
     * JSON request payload to speicy a filter to bulk delete chunks
     */
    requestBody: BulkDeleteChunkPayload;
    /**
     * The dataset id or tracking_id to use for the request. We assume you intend to use an id if the value is a valid uuid.
     */
    trDataset: string;
};

export type BulkDeleteChunkResponse = (void);

export type AutocompleteData = {
    /**
     * JSON request payload to semantically search for chunks (chunks)
     */
    requestBody: AutocompleteReqPayload;
    /**
     * The dataset id or tracking_id to use for the request. We assume you intend to use an id if the value is a valid uuid.
     */
    trDataset: string;
    /**
     * The API version to use for this request. Defaults to V2 for orgs created after July 12, 2024 and V1 otherwise.
     */
    xApiVersion?: ((APIVersion) | null);
};

export type AutocompleteResponse = (SearchResponseTypes);

export type CountChunksData = {
    /**
     * JSON request payload to count chunks for a search query
     */
    requestBody: CountChunksReqPayload;
    /**
     * The dataset id or tracking_id to use for the request. We assume you intend to use an id if the value is a valid uuid.
     */
    trDataset: string;
};

export type CountChunksResponse = (CountChunkQueryResponseBody);

export type GenerateOffChunksData = {
    /**
     * JSON request payload to perform RAG on some chunks (chunks)
     */
    requestBody: GenerateOffChunksReqPayload;
    /**
     * The dataset id or tracking_id to use for the request. We assume you intend to use an id if the value is a valid uuid.
     */
    trDataset: string;
};

export type GenerateOffChunksResponse = (string);

export type GetRecommendedChunksData = {
    /**
     * JSON request payload to get recommendations of chunks similar to the chunks in the request
     */
    requestBody: RecommendChunksRequest;
    /**
     * The dataset id or tracking_id to use for the request. We assume you intend to use an id if the value is a valid uuid.
     */
    trDataset: string;
    /**
     * The API version to use for this request. Defaults to V2 for orgs created after July 12, 2024 and V1 otherwise.
     */
    xApiVersion?: ((APIVersion) | null);
};

export type GetRecommendedChunksResponse = (RecommendResponseTypes);

export type SearchChunksData = {
    /**
     * JSON request payload to semantically search for chunks (chunks)
     */
    requestBody: SearchChunksReqPayload;
    /**
     * The dataset id or tracking_id to use for the request. We assume you intend to use an id if the value is a valid uuid.
     */
    trDataset: string;
    /**
     * The API version to use for this request. Defaults to V2 for orgs created after July 12, 2024 and V1 otherwise.
     */
    xApiVersion?: ((APIVersion) | null);
};

export type SearchChunksResponse = (SearchResponseTypes);

export type SplitHtmlContentData = {
    /**
     * JSON request payload to perform RAG on some chunks (chunks)
     */
    requestBody: ChunkHtmlContentReqPayload;
};

export type SplitHtmlContentResponse = (SplitHtmlResponse);

export type GetSuggestedQueriesData = {
    /**
     * JSON request payload to get alternative suggested queries
     */
    requestBody: SuggestedQueriesReqPayload;
    /**
     * The dataset id or tracking_id to use for the request. We assume you intend to use an id if the value is a valid uuid.
     */
    trDataset: string;
};

export type GetSuggestedQueriesResponse = (SuggestedQueriesResponse);

export type UpdateChunkByTrackingIdData2 = {
    /**
     * JSON request payload to update a chunk by tracking_id (chunks)
     */
    requestBody: UpdateChunkByTrackingIdData;
    /**
     * The dataset id or tracking_id to use for the request. We assume you intend to use an id if the value is a valid uuid.
     */
    trDataset: string;
};

export type UpdateChunkByTrackingIdResponse = (void);

export type GetChunkByTrackingIdData = {
    /**
     * tracking_id of the chunk you want to fetch
     */
    trackingId: string;
    /**
     * The dataset id or tracking_id to use for the request. We assume you intend to use an id if the value is a valid uuid.
     */
    trDataset: string;
    /**
     * The API version to use for this request. Defaults to V2 for orgs created after July 12, 2024 and V1 otherwise.
     */
    xApiVersion?: ((APIVersion) | null);
};

export type GetChunkByTrackingIdResponse = (ChunkReturnTypes);

export type DeleteChunkByTrackingIdData = {
    /**
     * tracking_id of the chunk you want to delete
     */
    trackingId: string;
    /**
     * The dataset id or tracking_id to use for the request. We assume you intend to use an id if the value is a valid uuid.
     */
    trDataset: string;
};

export type DeleteChunkByTrackingIdResponse = (void);

export type GetChunkByIdData = {
    /**
     * Id of the chunk you want to fetch.
     */
    chunkId: string;
    /**
     * The dataset id or tracking_id to use for the request. We assume you intend to use an id if the value is a valid uuid.
     */
    trDataset: string;
    /**
     * The API version to use for this request. Defaults to V2 for orgs created after July 12, 2024 and V1 otherwise.
     */
    xApiVersion?: ((APIVersion) | null);
};

export type GetChunkByIdResponse = (ChunkReturnTypes);

export type DeleteChunkData = {
    /**
     * Id of the chunk you want to fetch.
     */
    chunkId: string;
    /**
     * The dataset id or tracking_id to use for the request. We assume you intend to use an id if the value is a valid uuid.
     */
    trDataset: string;
};

export type DeleteChunkResponse = (void);

export type CreateChunkGroupData = {
    /**
     * JSON request payload to cretea a chunk_group(s)
     */
    requestBody: CreateChunkGroupReqPayloadEnum;
    /**
     * The dataset id or tracking_id to use for the request. We assume you intend to use an id if the value is a valid uuid.
     */
    trDataset: string;
};

export type CreateChunkGroupResponse = (CreateChunkGroupResponseEnum);

export type UpdateChunkGroupData = {
    /**
     * JSON request payload to update a chunkGroup
     */
    requestBody: UpdateChunkGroupReqPayload;
    /**
     * The dataset id or tracking_id to use for the request. We assume you intend to use an id if the value is a valid uuid.
     */
    trDataset: string;
};

export type UpdateChunkGroupResponse = (void);

export type AddChunkToGroupData = {
    /**
     * Id of the group to add the chunk to as a bookmark
     */
    groupId: string;
    /**
     * JSON request payload to add a chunk to a group (bookmark it)
     */
    requestBody: AddChunkToGroupReqPayload;
    /**
     * The dataset id or tracking_id to use for the request. We assume you intend to use an id if the value is a valid uuid.
     */
    trDataset: string;
};

export type AddChunkToGroupResponse = (void);

export type RemoveChunkFromGroupData = {
    /**
     * Id of the chunk you want to remove from the group
     */
    chunkId?: (string) | null;
    /**
     * Id of the group you want to remove the chunk from.
     */
    groupId: string;
    /**
     * JSON request payload to remove a chunk from a group
     */
    requestBody?: ((RemoveChunkFromGroupReqPayload) | null);
    /**
     * The dataset id or tracking_id to use for the request. We assume you intend to use an id if the value is a valid uuid.
     */
    trDataset: string;
};

export type RemoveChunkFromGroupResponse = (void);

export type GetGroupsForChunksData = {
    /**
     * JSON request payload to get the groups that a chunk is in
     */
    requestBody: GetGroupsForChunksReqPayload;
    /**
     * The dataset id or tracking_id to use for the request. We assume you intend to use an id if the value is a valid uuid.
     */
    trDataset: string;
};

export type GetGroupsForChunksResponse = (Array<GroupsForChunk>);

export type CountGroupChunksData = {
    /**
     * JSON request payload to add a chunk to a group (bookmark it)
     */
    requestBody: GetChunkGroupCountRequest;
    /**
     * The dataset id or tracking_id to use for the request. We assume you intend to use an id if the value is a valid uuid.
     */
    trDataset: string;
};

export type CountGroupChunksResponse = (GetChunkGroupCountResponse);

export type SearchOverGroupsData = {
    /**
     * JSON request payload to semantically search over groups
     */
    requestBody: SearchOverGroupsReqPayload;
    /**
     * The dataset id or tracking_id to use for the request. We assume you intend to use an id if the value is a valid uuid.
     */
    trDataset: string;
    /**
     * The API version to use for this request. Defaults to V2 for orgs created after July 12, 2024 and V1 otherwise.
     */
    xApiVersion?: ((APIVersion) | null);
};

export type SearchOverGroupsResponse = (SearchOverGroupsResponseTypes);

export type GetRecommendedGroupsData = {
    /**
     * JSON request payload to get recommendations of chunks similar to the chunks in the request
     */
    requestBody: RecommendGroupsReqPayload;
    /**
     * The dataset id or tracking_id to use for the request. We assume you intend to use an id if the value is a valid uuid.
     */
    trDataset: string;
    /**
     * The API version to use for this request. Defaults to V2 for orgs created after July 12, 2024 and V1 otherwise.
     */
    xApiVersion?: ((APIVersion) | null);
};

export type GetRecommendedGroupsResponse = (RecommendGroupsResponse);

export type SearchWithinGroupData = {
    /**
     * JSON request payload to semantically search a group
     */
    requestBody: SearchWithinGroupReqPayload;
    /**
     * The dataset id or tracking_id to use for the request. We assume you intend to use an id if the value is a valid uuid.
     */
    trDataset: string;
    /**
     * The API version to use for this request. Defaults to V2 for orgs created after July 12, 2024 and V1 otherwise.
     */
    xApiVersion?: ((APIVersion) | null);
};

export type SearchWithinGroupResponse = (SearchGroupResponseTypes);

export type GetChunksInGroupByTrackingIdData = {
    /**
     * The id of the group to get the chunks from
     */
    groupTrackingId: string;
    /**
     * The page of chunks to get from the group
     */
    page: number;
    /**
     * The dataset id or tracking_id to use for the request. We assume you intend to use an id if the value is a valid uuid.
     */
    trDataset: string;
    /**
     * The version of the API to use for the request
     */
    xApiVersion?: ((APIVersion) | null);
};

export type GetChunksInGroupByTrackingIdResponse = (GetChunksInGroupResponse);

export type GetGroupByTrackingIdData = {
    /**
     * The tracking id of the group to fetch.
     */
    trackingId: string;
    /**
     * The dataset id or tracking_id to use for the request. We assume you intend to use an id if the value is a valid uuid.
     */
    trDataset: string;
};

export type GetGroupByTrackingIdResponse = (ChunkGroupAndFileId);

export type AddChunkToGroupByTrackingIdData = {
    /**
     * JSON request payload to add a chunk to a group via tracking_id
     */
    requestBody: AddChunkToGroupReqPayload;
    /**
     * Tracking id of the group to add the chunk to as a bookmark
     */
    trackingId: string;
    /**
     * The dataset id or tracking_id to use for the request. We assume you intend to use an id if the value is a valid uuid.
     */
    trDataset: string;
};

export type AddChunkToGroupByTrackingIdResponse = (void);

export type DeleteGroupByTrackingIdData = {
    /**
     * Delete the chunks within the group
     */
    deleteChunks: boolean;
    /**
     * Tracking id of the chunk_group to delete
     */
    trackingId: string;
    /**
     * The dataset id or tracking_id to use for the request. We assume you intend to use an id if the value is a valid uuid.
     */
    trDataset: string;
};

export type DeleteGroupByTrackingIdResponse = (void);

export type GetChunkGroupData = {
    /**
     * Id of the group you want to fetch.
     */
    groupId: string;
    /**
     * The dataset id or tracking_id to use for the request. We assume you intend to use an id if the value is a valid uuid.
     */
    trDataset: string;
};

export type GetChunkGroupResponse = (ChunkGroupAndFileId);

export type DeleteChunkGroupData = {
    /**
     * Delete the chunks within the group
     */
    deleteChunks: boolean;
    /**
     * Id of the group you want to fetch.
     */
    groupId: string;
    /**
     * The dataset id or tracking_id to use for the request. We assume you intend to use an id if the value is a valid uuid.
     */
    trDataset: string;
};

export type DeleteChunkGroupResponse = (void);

export type GetChunksInGroupData = {
    /**
     * Id of the group you want to fetch.
     */
    groupId: string;
    /**
     * The page of chunks to get from the group
     */
    page: (number) | null;
    /**
     * The dataset id or tracking_id to use for the request. We assume you intend to use an id if the value is a valid uuid.
     */
    trDataset: string;
    /**
     * The version of the API to use for the request
     */
    xApiVersion?: ((APIVersion) | null);
};

export type GetChunksInGroupResponse2 = (GetChunksInGroupResponse);

export type GetChunksByIdsData = {
    /**
     * JSON request payload to get the chunks in the request
     */
    requestBody: GetChunksData;
    /**
     * The dataset id or tracking_id to use for the request. We assume you intend to use an id if the value is a valid uuid.
     */
    trDataset: string;
    /**
     * The API version to use for this request. Defaults to V2 for orgs created after July 12, 2024 and V1 otherwise.
     */
    xApiVersion?: ((APIVersion) | null);
};

export type GetChunksByIdsResponse = (Array<ChunkReturnTypes>);

export type ScrollDatasetChunksData = {
    /**
     * JSON request payload to scroll through chunks (chunks)
     */
    requestBody: ScrollChunksReqPayload;
    /**
     * The dataset id or tracking_id to use for the request. We assume you intend to use an id if the value is a valid uuid.
     */
    trDataset: string;
};

export type ScrollDatasetChunksResponse = (ScrollChunksResponseBody);

export type GetChunksByTrackingIdsData = {
    /**
     * JSON request payload to get the chunks in the request
     */
    requestBody: GetTrackingChunksData;
    /**
     * The dataset id or tracking_id to use for the request. We assume you intend to use an id if the value is a valid uuid.
     */
    trDataset: string;
    /**
     * The API version to use for this request. Defaults to V2 for orgs created after July 12, 2024 and V1 otherwise.
     */
    xApiVersion?: ((APIVersion) | null);
};

export type GetChunksByTrackingIdsResponse = (Array<ChunkReturnTypes>);

export type GetCrawlRequestsForDatasetData = {
    /**
     * The number of items to retrieve per page
     */
    limit?: (number) | null;
    /**
     * The page number to retrieve
     */
    page?: (number) | null;
    /**
     * The dataset id to use for the request
     */
    trDataset: string;
};

export type GetCrawlRequestsForDatasetResponse = (Array<CrawlRequest>);

export type CreateCrawlData = {
    /**
     * JSON request payload to create a new crawl
     */
    requestBody: CreateCrawlReqPayload;
    /**
     * The dataset id to use for the request
     */
    trDataset: string;
};

export type CreateCrawlResponse = (CrawlRequest);

export type UpdateCrawlRequestData = {
    /**
     * JSON request payload to update a crawl
     */
    requestBody: UpdateCrawlReqPayload;
    /**
     * The dataset id to use for the request
     */
    trDataset: string;
};

export type UpdateCrawlRequestResponse = (CrawlRequest);

export type DeleteCrawlRequestData = {
    /**
     * The id of the crawl to delete
     */
    crawlId: string;
    /**
     * The dataset id to use for the request
     */
    trDataset: string;
};

export type DeleteCrawlRequestResponse = (void);

export type CreateDatasetData = {
    /**
     * JSON request payload to create a new dataset
     */
    requestBody: CreateDatasetReqPayload;
    /**
     * The organization id to use for the request
     */
    trOrganization: string;
};

export type CreateDatasetResponse = (Dataset);

export type UpdateDatasetData = {
    /**
     * JSON request payload to update a dataset
     */
    requestBody: UpdateDatasetReqPayload;
    /**
     * The organization id to use for the request
     */
    trOrganization: string;
};

export type UpdateDatasetResponse = (Dataset);

export type BatchCreateDatasetsData = {
    /**
     * JSON request payload to bulk create datasets
     */
    requestBody: CreateDatasetBatchReqPayload;
    /**
     * The organization id to use for the request
     */
    trOrganization: string;
};

export type BatchCreateDatasetsResponse = (Datasets);

export type ClearDatasetData = {
    /**
     * The id of the dataset you want to clear.
     */
    datasetId: string;
    /**
     * The dataset id or tracking_id to use for the request. We assume you intend to use an id if the value is a valid uuid.
     */
    trDataset: string;
};

export type ClearDatasetResponse = (void);

export type GetEventsData2 = {
    /**
     * JSON request payload to get events for a dataset
     */
    requestBody: GetEventsData;
    /**
     * The dataset id or tracking_id to use for the request. We assume you intend to use an id if the value is a valid uuid.
     */
    trDataset: string;
};

export type GetEventsResponse = (EventReturn);

export type GetDatasetFilesHandlerData = {
    /**
     * The id of the dataset to fetch files for.
     */
    datasetId: string;
    /**
     * The page number of files you wish to fetch. Each page contains at most 10 files.
     */
    page: number;
    /**
     * The dataset id or tracking_id to use for the request. We assume you intend to use an id if the value is a valid uuid.
     */
    trDataset: string;
};

export type GetDatasetFilesHandlerResponse = (FileData);

export type GetAllTagsData = {
    /**
     * JSON request payload to get items with the tag in the request
     */
    requestBody: GetAllTagsReqPayload;
    /**
     * The dataset id or tracking_id to use for the request. We assume you intend to use an id if the value is a valid uuid.
     */
    trDataset: string;
};

export type GetAllTagsResponse2 = (GetAllTagsResponse);

export type GetGroupsForDatasetData = {
    /**
     * The cursor offset for .Requires `use_cursor` = True. Defaults to `00000000-00000000-00000000-00000000`
     */
    cursor?: (string) | null;
    /**
     * The id of the dataset to fetch groups for.
     */
    datasetId: string;
    /**
     * The page of groups to fetch. Page is 1-indexed. Only used if `use_cursor` = `false`.
     */
    page: (number) | null;
    /**
     * The dataset id or tracking_id to use for the request. We assume you intend to use an id if the value is a valid uuid.
     */
    trDataset: string;
    /**
     * Flag to enable `cursor` mode, this runs faster for large scroll operations. Defaults to false
     */
    useCursor?: (boolean) | null;
};

export type GetGroupsForDatasetResponse = (GroupData);

export type GetDatasetsFromOrganizationData = {
    /**
     * The number of records to return
     */
    limit?: (number) | null;
    /**
     * The number of records to skip
     */
    offset?: (number) | null;
    /**
     * id of the organization you want to retrieve datasets for
     */
    organizationId: string;
    /**
     * The organization id to use for the request
     */
    trOrganization: string;
};

export type GetDatasetsFromOrganizationResponse = (Array<DatasetAndUsage>);

export type GetPagefindIndexForDatasetData = {
    /**
     * The dataset id or tracking_id to use for the request. We assume you intend to use an id if the value is a valid uuid.
     */
    trDataset: string;
};

export type GetPagefindIndexForDatasetResponse = (GetPagefindIndexResponse);

export type CreatePagefindIndexForDatasetData = {
    /**
     * The dataset id or tracking_id to use for the request. We assume you intend to use an id if the value is a valid uuid.
     */
    trDataset: string;
};

export type CreatePagefindIndexForDatasetResponse = (void);

export type GetDatasetByTrackingIdData = {
    /**
     * The tracking id of the dataset you want to retrieve.
     */
    trackingId: string;
    /**
     * The organization id to use for the request
     */
    trOrganization: string;
};

export type GetDatasetByTrackingIdResponse = (Dataset);

export type DeleteDatasetByTrackingIdData = {
    /**
     * The tracking id of the dataset you want to delete.
     */
    trackingId: string;
    /**
     * The dataset id or tracking_id to use for the request. We assume you intend to use an id if the value is a valid uuid.
     */
    trDataset: string;
};

export type DeleteDatasetByTrackingIdResponse = (void);

export type GetUsageByDatasetIdData = {
    /**
     * The id of the dataset you want to retrieve usage for.
     */
    datasetId: string;
    /**
     * The dataset id or tracking_id to use for the request. We assume you intend to use an id if the value is a valid uuid.
     */
    trDataset: string;
};

export type GetUsageByDatasetIdResponse = (DatasetUsageCount);

export type GetDatasetData = {
    /**
     * The id of the dataset you want to retrieve.
     */
    datasetId: string;
    /**
     * The dataset id or tracking_id to use for the request. We assume you intend to use an id if the value is a valid uuid.
     */
    trDataset: string;
};

export type GetDatasetResponse = (Dataset);

export type DeleteDatasetData = {
    /**
     * The id of the dataset you want to delete.
     */
    datasetId: string;
    /**
     * The dataset id or tracking_id to use for the request. We assume you intend to use an id if the value is a valid uuid.
     */
    trDataset: string;
};

export type DeleteDatasetResponse = (void);

export type CreateEtlJobData = {
    /**
     * JSON request payload to create a new ETL Job
     */
    requestBody: CreateSchemaReqPayload;
    /**
     * The dataset id to use for the request
     */
    trDataset: string;
};

export type CreateEtlJobResponse = (void);

export type UploadFileHandlerData = {
    /**
     * JSON request payload to upload a file
     */
    requestBody: UploadFileReqPayload;
    /**
     * The dataset id or tracking_id to use for the request. We assume you intend to use an id if the value is a valid uuid.
     */
    trDataset: string;
};

export type UploadFileHandlerResponse = (UploadFileResponseBody);

export type CreatePresignedUrlForCsvJsonlData = {
    /**
     * JSON request payload to upload a CSV or JSONL file
     */
    requestBody: CreatePresignedUrlForCsvJsonlReqPayload;
    /**
     * The dataset id or tracking_id to use for the request. We assume you intend to use an id if the value is a valid uuid.
     */
    trDataset: string;
};

export type CreatePresignedUrlForCsvJsonlResponse = (CreatePresignedUrlForCsvJsonResponseBody);

export type UploadHtmlPageData = {
    /**
     * JSON request payload to upload a file
     */
    requestBody: UploadHtmlPageReqPayload;
};

export type UploadHtmlPageResponse = (void);

export type GetFileHandlerData = {
    /**
     * Optional field to override the presigned url's Content-Type header
     */
    contentType?: (string) | null;
    /**
     * The id of the file to fetch
     */
    fileId: string;
    /**
     * The dataset id or tracking_id to use for the request. We assume you intend to use an id if the value is a valid uuid.
     */
    trDataset: string;
};

export type GetFileHandlerResponse = (FileDTO);

export type DeleteFileHandlerData = {
    /**
     * Delete the chunks within the group
     */
    deleteChunks: boolean;
    /**
     * The id of the file to delete
     */
    fileId: string;
    /**
     * The dataset id or tracking_id to use for the request. We assume you intend to use an id if the value is a valid uuid.
     */
    trDataset: string;
};

export type DeleteFileHandlerResponse = (void);

export type HealthCheckResponse = (unknown);

export type PostInvitationData = {
    /**
     * JSON request payload to send an invitation
     */
    requestBody: InvitationData;
    /**
     * The organization id to use for the request
     */
    trOrganization: string;
};

export type PostInvitationResponse = (void);

export type DeleteInvitationData = {
    /**
     * The id of the invitation to delete
     */
    invitationId: string;
    /**
     * The organization id to use for the request
     */
    trOrganization: string;
};

export type DeleteInvitationResponse = (void);

export type GetInvitationsData = {
    /**
     * The organization id to get invitations for
     */
    organizationId: string;
    /**
     * The organization id to use for the request
     */
    trOrganization: string;
};

export type GetInvitationsResponse = (Array<Invitation>);

export type CreateMessageData = {
    /**
     * JSON request payload to create a message completion
     */
    requestBody: CreateMessageReqPayload;
    /**
     * The dataset id or tracking_id to use for the request. We assume you intend to use an id if the value is a valid uuid.
     */
    trDataset: string;
};

export type CreateMessageResponse = (string);

export type EditMessageData = {
    /**
     * JSON request payload to edit a message and get a new stream
     */
    requestBody: EditMessageReqPayload;
    /**
     * The dataset id or tracking_id to use for the request. We assume you intend to use an id if the value is a valid uuid.
     */
    trDataset: string;
};

export type EditMessageResponse = (string);

export type RegenerateMessageData = {
    /**
     * JSON request payload to delete an agent message then regenerate it in a strem
     */
    requestBody: RegenerateMessageReqPayload;
    /**
     * The dataset id or tracking_id to use for the request. We assume you intend to use an id if the value is a valid uuid.
     */
    trDataset: string;
};

export type RegenerateMessageResponse = (string);

export type RegenerateMessagePatchData = {
    /**
     * JSON request payload to delete an agent message then regenerate it in a strem
     */
    requestBody: RegenerateMessageReqPayload;
    /**
     * The dataset id or tracking_id to use for the request. We assume you intend to use an id if the value is a valid uuid.
     */
    trDataset: string;
};

export type RegenerateMessagePatchResponse = (string);

export type GetToolFunctionParamsData = {
    /**
     * JSON request payload to get the parameters for a tool function
     */
    requestBody: GetToolFunctionParamsReqPayload;
    /**
     * The dataset id or tracking_id to use for the request. We assume you intend to use an id if the value is a valid uuid.
     */
    trDataset: string;
};

export type GetToolFunctionParamsResponse = (GetToolFunctionParamsRespBody);

export type GetMessageByIdData = {
    /**
     * The ID of the message to get.
     */
    messageId: string;
    /**
     * The dataset id or tracking_id to use for the request. We assume you intend to use an id if the value is a valid uuid.
     */
    trDataset: string;
};

export type GetMessageByIdResponse = (Message);

export type GetAllTopicMessagesData = {
    /**
     * The ID of the topic to get messages for.
     */
    messagesTopicId: string;
    /**
     * The dataset id or tracking_id to use for the request. We assume you intend to use an id if the value is a valid uuid.
     */
    trDataset: string;
};

export type GetAllTopicMessagesResponse = (Array<Message>);

export type CreateOrganizationData = {
    /**
     * The organization data that you want to create
     */
    requestBody: CreateOrganizationReqPayload;
};

export type CreateOrganizationResponse = (Organization);

export type UpdateOrganizationData = {
    /**
     * The organization data that you want to update
     */
    requestBody: UpdateOrganizationReqPayload;
    /**
     * The organization id to use for the request
     */
    trOrganization: string;
};

export type UpdateOrganizationResponse = (Organization);

export type GetOrganizationApiKeysData = {
    /**
     * The organization id to use for the request.
     */
    trOrganization: string;
};

export type GetOrganizationApiKeysResponse = (Array<ApiKeyRespBody>);

export type CreateOrganizationApiKeyData = {
    /**
     * JSON request payload to create a new organization api key
     */
    requestBody: CreateApiKeyReqPayload;
    /**
     * The organization id to use for the request.
     */
    trOrganization: string;
};

export type CreateOrganizationApiKeyResponse = (CreateApiKeyResponse);

export type DeleteOrganizationApiKeyData = {
    /**
     * The id of the api key to delete
     */
    apiKeyId: string;
    /**
     * The organization id to use for the request.
     */
    trOrganization: string;
};

export type DeleteOrganizationApiKeyResponse = (void);

export type UpdateAllOrgDatasetConfigsData = {
    /**
     * The organization data that you want to create
     */
    requestBody: UpdateAllOrgDatasetConfigsReqPayload;
    /**
     * The organization id to use for the request
     */
    trOrganization: string;
};

export type UpdateAllOrgDatasetConfigsResponse = (void);

export type GetOrganizationUsageData = {
    /**
     * The id of the organization you want to fetch the usage of.
     */
    organizationId: string;
    /**
     * The organization id to use for the request
     */
    trOrganization: string;
};

export type GetOrganizationUsageResponse = (OrganizationUsageCount);

export type GetOrganizationUsersData = {
    /**
     * The id of the organization you want to fetch the users of.
     */
    organizationId: string;
    /**
     * The organization id to use for the request
     */
    trOrganization: string;
};

export type GetOrganizationUsersResponse = (Array<SlimUser>);

export type GetOrganizationData = {
    /**
     * The id of the organization you want to fetch.
     */
    organizationId: string;
    /**
     * The organization id to use for the request
     */
    trOrganization: string;
};

export type GetOrganizationResponse = (OrganizationWithSubAndPlan);

export type DeleteOrganizationData = {
    /**
     * The id of the organization you want to fetch.
     */
    organizationId: string;
    /**
     * The organization id to use for the request
     */
    trOrganization: string;
};

export type DeleteOrganizationResponse = (void);

export type PublicPageData = {
    /**
     * The id or tracking_id of the dataset you want to get the demo page for.
     */
    datasetId: string;
};

export type PublicPageResponse = (unknown);

export type CreateSetupCheckoutSessionData = {
    /**
     * The id of the organization to create setup checkout session for.
     */
    organizationId: string;
};

export type CreateSetupCheckoutSessionResponse = (CreateSetupCheckoutSessionResPayload);

export type GetAllInvoicesData = {
    /**
     * The id of the organization to get invoices for.
     */
    organizationId: string;
};

export type GetAllInvoicesResponse = (Array<StripeInvoice>);

export type DirectToPaymentLinkData = {
    /**
     * id of the organization you want to subscribe to the plan
     */
    organizationId: string;
    /**
     * id of the plan you want to subscribe to
     */
    planId: string;
};

export type GetAllPlansResponse = (Array<StripePlan>);

export type CancelSubscriptionData = {
    /**
     * id of the subscription you want to cancel
     */
    subscriptionId: string;
    /**
     * The organization id to use for the request
     */
    trOrganization: string;
};

export type CancelSubscriptionResponse = (unknown);

export type UpdateSubscriptionPlanData = {
    /**
     * id of the plan you want to subscribe to
     */
    planId: string;
    /**
     * id of the subscription you want to update
     */
    subscriptionId: string;
    /**
     * The organization id to use for the request
     */
    trOrganization: string;
};

export type UpdateSubscriptionPlanResponse = (unknown);

export type CreateTopicData = {
    /**
     * JSON request payload to create chat topic
     */
    requestBody: CreateTopicReqPayload;
    /**
     * The dataset id or tracking_id to use for the request. We assume you intend to use an id if the value is a valid uuid.
     */
    trDataset: string;
};

export type CreateTopicResponse = (Topic);

export type UpdateTopicData = {
    /**
     * JSON request payload to update a chat topic
     */
    requestBody: UpdateTopicReqPayload;
    /**
     * The dataset id or tracking_id to use for the request. We assume you intend to use an id if the value is a valid uuid.
     */
    trDataset: string;
};

export type UpdateTopicResponse = (void);

export type CloneTopicData = {
    /**
     * JSON request payload to create chat topic
     */
    requestBody: CloneTopicReqPayload;
    /**
     * The dataset id or tracking_id to use for the request. We assume you intend to use an id if the value is a valid uuid.
     */
    trDataset: string;
};

export type CloneTopicResponse = (Topic);

export type GetAllTopicsForOwnerIdData = {
    /**
     * The owner_id to get topics of; A common approach is to use a browser fingerprint or your user's id
     */
    ownerId: string;
    /**
     * The dataset id or tracking_id to use for the request. We assume you intend to use an id if the value is a valid uuid.
     */
    trDataset: string;
};

export type GetAllTopicsForOwnerIdResponse = (Array<Topic>);

export type DeleteTopicData2 = {
    /**
     * The id of the topic you want to delete.
     */
    topicId: string;
    /**
     * The dataset id or tracking_id to use for the request. We assume you intend to use an id if the value is a valid uuid.
     */
    trDataset: string;
};

export type DeleteTopicResponse = (void);

export type UpdateUserData = {
    /**
     * JSON request payload to update user information for the auth'ed user
     */
    requestBody: UpdateUserOrgRoleReqPayload;
    /**
     * The organization id to use for the request
     */
    trOrganization: string;
};

export type UpdateUserResponse = (void);

export type GetUserApiKeysResponse = (Array<ApiKeyRespBody>);

export type DeleteUserApiKeyData = {
    /**
     * The id of the api key to delete
     */
    apiKeyId: string;
};

export type DeleteUserApiKeyResponse = (void);

export type GetMetricsResponse = (string);

export type $OpenApiTs = {
    '/api/analytics/ctr': {
        put: {
            req: SendCtrDataData;
            res: {
                /**
                 * The CTR data was successfully sent
                 */
                204: void;
                /**
                 * Service error relating to sending CTR data
                 */
                400: ErrorResponseBody;
            };
        };
    };
    '/api/analytics/events': {
        put: {
            req: SendEventDataData;
            res: {
                /**
                 * The event data was successfully sent
                 */
                204: void;
                /**
                 * Service error relating to sending event data
                 */
                400: ErrorResponseBody;
            };
        };
    };
    '/api/analytics/events/all': {
        post: {
            req: GetAllEventsData;
            res: {
                /**
                 * The events for the request
                 */
                200: GetEventsResponseBody;
                /**
                 * Service error relating to getting events
                 */
                400: ErrorResponseBody;
            };
        };
    };
    '/api/analytics/events/component': {
        post: {
            req: GetComponentAnalyticsData;
            res: {
                /**
                 * The component analytics for the dataset
                 */
                200: ComponentAnalyticsResponse;
                /**
                 * Service error relating to getting component analytics
                 */
                400: ErrorResponseBody;
            };
        };
    };
    '/api/analytics/events/ctr': {
        post: {
            req: GetCtrAnalyticsData;
            res: {
                /**
                 * The CTR analytics for the dataset
                 */
                200: CTRAnalyticsResponse;
                /**
                 * Service error relating to getting CTR analytics
                 */
                400: ErrorResponseBody;
            };
        };
    };
    '/api/analytics/events/{event_id}': {
        get: {
            req: GetEventByIdData;
            res: {
                /**
                 * The event for the request
                 */
                200: EventData;
                /**
                 * Service error relating to getting an event
                 */
                400: ErrorResponseBody;
            };
        };
    };
    '/api/analytics/rag': {
        post: {
            req: GetRagAnalyticsData;
            res: {
                /**
                 * The RAG analytics for the dataset
                 */
                200: RAGAnalyticsResponse;
                /**
                 * Service error relating to getting RAG analytics
                 */
                400: ErrorResponseBody;
            };
        };
        put: {
            req: SetRagQueryRatingData;
            res: {
                /**
                 * The RAG query was successfully rated
                 */
                204: void;
                /**
                 * Service error relating to rating a RAG query
                 */
                400: ErrorResponseBody;
            };
        };
    };
    '/api/analytics/recommendations': {
        post: {
            req: GetRecommendationAnalyticsData;
            res: {
                /**
                 * The recommendation analytics for the dataset
                 */
                200: RecommendationAnalyticsResponse;
                /**
                 * Service error relating to getting recommendation analytics
                 */
                400: ErrorResponseBody;
            };
        };
    };
    '/api/analytics/search': {
        post: {
            req: GetSearchAnalyticsData;
            res: {
                /**
                 * The search analytics for the dataset
                 */
                200: SearchAnalyticsResponse;
                /**
                 * Service error relating to getting search analytics
                 */
                400: ErrorResponseBody;
            };
        };
        put: {
            req: SetSearchQueryRatingData;
            res: {
                /**
                 * The search query was successfully rated
                 */
                204: void;
                /**
                 * Service error relating to rating a search query
                 */
                400: ErrorResponseBody;
            };
        };
    };
    '/api/analytics/search/cluster': {
        post: {
            req: GetClusterAnalyticsData;
            res: {
                /**
                 * The cluster analytics for the dataset
                 */
                200: ClusterAnalyticsResponse;
                /**
                 * Service error relating to getting cluster analytics
                 */
                400: ErrorResponseBody;
            };
        };
    };
    '/api/analytics/top': {
        post: {
            req: GetTopDatasetsData;
            res: {
                /**
                 * The top datasets for the request
                 */
                200: Array<TopDatasetsResponse>;
                /**
                 * Service error relating to getting top datasets
                 */
                400: ErrorResponseBody;
            };
        };
    };
    '/api/auth': {
        get: {
            req: LoginData;
            res: {
                /**
                 * Response that redirects to OAuth provider through a Location header to be handled by browser.
                 */
                303: unknown;
                /**
                 * OAuth error likely with OIDC provider.
                 */
                400: ErrorResponseBody;
            };
        };
        delete: {
            res: {
                /**
                 * Confirmation that your current auth token has been invalidated. This does not invalidate your API key.
                 */
                204: void;
            };
        };
    };
    '/api/auth/callback': {
        get: {
            res: {
                /**
                 * Response that returns with set-cookie header
                 */
                200: SlimUser;
                /**
                 * Email or password empty or incorrect
                 */
                400: ErrorResponseBody;
            };
        };
    };
    '/api/auth/me': {
        get: {
            res: {
                /**
                 * The user corresponding to your current auth credentials
                 */
                200: SlimUser;
                /**
                 * Error message indicitating you are not currently signed in
                 */
                400: ErrorResponseBody;
            };
        };
    };
    '/api/chunk': {
        post: {
            req: CreateChunkData;
            res: {
                /**
                 * JSON response payload containing the created chunk
                 */
                200: ReturnQueuedChunk;
                /**
                 * Error typically due to deserialization issues
                 */
                400: ErrorResponseBody;
                /**
                 * Error when more than 120 chunks are provided in bulk
                 */
                413: ErrorResponseBody;
                /**
                 * Error when upgrade is needed to process more chunks
                 */
                426: ErrorResponseBody;
            };
        };
        put: {
            req: UpdateChunkData;
            res: {
                /**
                 * No content Ok response indicating the chunk was updated as requested
                 */
                204: void;
                /**
                 * Service error relating to to updating chunk, likely due to conflicting tracking_id
                 */
                400: ErrorResponseBody;
            };
        };
        delete: {
            req: BulkDeleteChunkData;
            res: {
                /**
                 * Confirmation that the chunk with the id specified was deleted
                 */
                204: void;
                /**
                 * Service error relating to finding a chunk by tracking_id
                 */
                400: ErrorResponseBody;
            };
        };
    };
    '/api/chunk/autocomplete': {
        post: {
            req: AutocompleteData;
            res: {
                /**
                 * Chunks with embedding vectors which are similar to those in the request body
                 */
                200: SearchResponseTypes;
                /**
                 * Service error relating to searching
                 */
                400: ErrorResponseBody;
            };
        };
    };
    '/api/chunk/count': {
        post: {
            req: CountChunksData;
            res: {
                /**
                 * Number of chunks satisfying the query
                 */
                200: CountChunkQueryResponseBody;
                /**
                 * Failed to count chunks
                 */
                404: ErrorResponseBody;
            };
        };
    };
    '/api/chunk/generate': {
        post: {
            req: GenerateOffChunksData;
            res: {
                /**
                 * This will be a JSON response of a string containing the LLM's generated inference. Response if not streaming.
                 */
                200: string;
                /**
                 * Service error relating to to updating chunk, likely due to conflicting tracking_id
                 */
                400: ErrorResponseBody;
            };
        };
    };
    '/api/chunk/recommend': {
        post: {
            req: GetRecommendedChunksData;
            res: {
                /**
                 * Chunks with embedding vectors which are similar to positives and dissimilar to negatives
                 */
                200: RecommendResponseTypes;
                /**
                 * Service error relating to to getting similar chunks
                 */
                400: ErrorResponseBody;
            };
        };
    };
    '/api/chunk/search': {
        post: {
            req: SearchChunksData;
            res: {
                /**
                 * Chunks with embedding vectors which are similar to those in the request body
                 */
                200: SearchResponseTypes;
                /**
                 * Service error relating to searching
                 */
                400: ErrorResponseBody;
            };
        };
    };
    '/api/chunk/split': {
        post: {
            req: SplitHtmlContentData;
            res: {
                /**
                 * This will be a JSON response of the chunks split from the HTML content with the headings and body
                 */
                200: SplitHtmlResponse;
                /**
                 * Payload too large, if the HTML contnet is greater than 256Kb
                 */
                413: ErrorResponseBody;
            };
        };
    };
    '/api/chunk/suggestions': {
        post: {
            req: GetSuggestedQueriesData;
            res: {
                /**
                 * A JSON object containing a list of alternative suggested queries
                 */
                200: SuggestedQueriesResponse;
                /**
                 * Service error relating to to updating chunk, likely due to conflicting tracking_id
                 */
                400: ErrorResponseBody;
            };
        };
    };
    '/api/chunk/tracking_id/update': {
        put: {
            req: UpdateChunkByTrackingIdData2;
            res: {
                /**
                 * Confirmation that the chunk has been updated as per your request
                 */
                204: void;
                /**
                 * Service error relating to to updating chunk
                 */
                400: ErrorResponseBody;
            };
        };
    };
    '/api/chunk/tracking_id/{tracking_id}': {
        get: {
            req: GetChunkByTrackingIdData;
            res: {
                /**
                 * chunk with the tracking_id that you were searching for
                 */
                200: ChunkReturnTypes;
                /**
                 * Service error relating to fidning a chunk by tracking_id
                 */
                400: ErrorResponseBody;
                /**
                 * Chunk not found
                 */
                404: ErrorResponseBody;
            };
        };
        delete: {
            req: DeleteChunkByTrackingIdData;
            res: {
                /**
                 * Confirmation that the chunk with the tracking_id specified was deleted
                 */
                204: void;
                /**
                 * Service error relating to finding a chunk by tracking_id
                 */
                400: ErrorResponseBody;
            };
        };
    };
    '/api/chunk/{chunk_id}': {
        get: {
            req: GetChunkByIdData;
            res: {
                /**
                 * chunk with the id that you were searching for
                 */
                200: ChunkReturnTypes;
                /**
                 * Service error relating to fidning a chunk by tracking_id
                 */
                400: ErrorResponseBody;
                /**
                 * Chunk not found
                 */
                404: ErrorResponseBody;
            };
        };
        delete: {
            req: DeleteChunkData;
            res: {
                /**
                 * Confirmation that the chunk with the id specified was deleted
                 */
                204: void;
                /**
                 * Service error relating to finding a chunk by tracking_id
                 */
                400: ErrorResponseBody;
            };
        };
    };
    '/api/chunk_group': {
        post: {
            req: CreateChunkGroupData;
            res: {
                /**
                 * Returns the created chunk_group if a single chunk_group was specified or an array of all chunk_groups which were created
                 */
                200: CreateChunkGroupResponseEnum;
                /**
                 * Service error relating to creating the chunk_group(s)
                 */
                400: ErrorResponseBody;
                /**
                 * Service error indicating more 1000 chunk groups are trying to be created at once
                 */
                413: ErrorResponseBody;
            };
        };
        put: {
            req: UpdateChunkGroupData;
            res: {
                /**
                 * Confirmation that the chunkGroup was updated
                 */
                204: void;
                /**
                 * Service error relating to updating the chunkGroup
                 */
                400: ErrorResponseBody;
            };
        };
    };
    '/api/chunk_group/chunk/{group_id}': {
        post: {
            req: AddChunkToGroupData;
            res: {
                /**
                 * Confirmation that the chunk was added to the group (bookmark'ed).
                 */
                204: void;
                /**
                 * Service error relating to getting the groups that the chunk is in.
                 */
                400: ErrorResponseBody;
            };
        };
        delete: {
            req: RemoveChunkFromGroupData;
            res: {
                /**
                 * Confirmation that the chunk was removed to the group
                 */
                204: void;
                /**
                 * Service error relating to removing the chunk from the group
                 */
                400: ErrorResponseBody;
            };
        };
    };
    '/api/chunk_group/chunks': {
        post: {
            req: GetGroupsForChunksData;
            res: {
                /**
                 * JSON body representing the groups that the chunk is in
                 */
                200: Array<GroupsForChunk>;
                /**
                 * Service error relating to getting the groups that the chunk is in
                 */
                400: ErrorResponseBody;
            };
        };
    };
    '/api/chunk_group/count': {
        post: {
            req: CountGroupChunksData;
            res: {
                /**
                 * JSON body representing the group with the count
                 */
                200: GetChunkGroupCountResponse;
                /**
                 * Service error relating to getting the group with the given tracking id
                 */
                400: ErrorResponseBody;
                /**
                 * Group not found
                 */
                404: ErrorResponseBody;
            };
        };
    };
    '/api/chunk_group/group_oriented_search': {
        post: {
            req: SearchOverGroupsData;
            res: {
                /**
                 * Group chunks which are similar to the embedding vector of the search query
                 */
                200: SearchOverGroupsResponseTypes;
                /**
                 * Service error relating to searching over groups
                 */
                400: ErrorResponseBody;
            };
        };
    };
    '/api/chunk_group/recommend': {
        post: {
            req: GetRecommendedGroupsData;
            res: {
                /**
                 * JSON body representing the groups which are similar to the positive groups and dissimilar to the negative ones
                 */
                200: RecommendGroupsResponse;
                /**
                 * Service error relating to to getting similar chunks
                 */
                400: ErrorResponseBody;
            };
        };
    };
    '/api/chunk_group/search': {
        post: {
            req: SearchWithinGroupData;
            res: {
                /**
                 * Group chunks which are similar to the embedding vector of the search query
                 */
                200: SearchGroupResponseTypes;
                /**
                 * Service error relating to getting the groups that the chunk is in
                 */
                400: ErrorResponseBody;
            };
        };
    };
    '/api/chunk_group/tracking_id/{group_tracking_id}/{page}': {
        get: {
            req: GetChunksInGroupByTrackingIdData;
            res: {
                /**
                 * Chunks present within the specified group
                 */
                200: GetChunksInGroupResponse;
                /**
                 * Service error relating to getting the groups that the chunk is in
                 */
                400: ErrorResponseBody;
                /**
                 * Group not found
                 */
                404: ErrorResponseBody;
            };
        };
    };
    '/api/chunk_group/tracking_id/{tracking_id}': {
        get: {
            req: GetGroupByTrackingIdData;
            res: {
                /**
                 * JSON body representing the group with the given tracking id
                 */
                200: ChunkGroupAndFileId;
                /**
                 * Service error relating to getting the group with the given tracking id
                 */
                400: ErrorResponseBody;
                /**
                 * Group not found
                 */
                404: ErrorResponseBody;
            };
        };
        post: {
            req: AddChunkToGroupByTrackingIdData;
            res: {
                /**
                 * Confirmation that the chunk was added to the group
                 */
                204: void;
                /**
                 * Service error related to adding the chunk group by tracking_id
                 */
                400: ErrorResponseBody;
            };
        };
        delete: {
            req: DeleteGroupByTrackingIdData;
            res: {
                /**
                 * Confirmation that the chunkGroup was deleted
                 */
                204: void;
                /**
                 * Service error relating to deleting the chunkGroup
                 */
                400: ErrorResponseBody;
            };
        };
    };
    '/api/chunk_group/{group_id}': {
        get: {
            req: GetChunkGroupData;
            res: {
                /**
                 * JSON body representing the group with the given tracking id
                 */
                200: ChunkGroupAndFileId;
                /**
                 * Service error relating to getting the group with the given tracking id
                 */
                400: ErrorResponseBody;
                /**
                 * Group not found
                 */
                404: ErrorResponseBody;
            };
        };
        delete: {
            req: DeleteChunkGroupData;
            res: {
                /**
                 * Confirmation that the chunkGroup was deleted
                 */
                204: void;
                /**
                 * Service error relating to deleting the chunkGroup
                 */
                400: ErrorResponseBody;
            };
        };
    };
    '/api/chunk_group/{group_id}/{page}': {
        get: {
            req: GetChunksInGroupData;
            res: {
                /**
                 * Chunks present within the specified group
                 */
                200: GetChunksInGroupResponse;
                /**
                 * Service error relating to getting the groups that the chunk is in
                 */
                400: ErrorResponseBody;
                /**
                 * Group not found
                 */
                404: ErrorResponseBody;
            };
        };
    };
    '/api/chunks': {
        post: {
            req: GetChunksByIdsData;
            res: {
                /**
                 * chunks with the id that you were searching for
                 */
                200: Array<ChunkReturnTypes>;
                /**
                 * Service error relating to fidning a chunk by tracking_id
                 */
                400: ErrorResponseBody;
                /**
                 * Any one of the specified chunks not found
                 */
                404: ErrorResponseBody;
            };
        };
    };
    '/api/chunks/scroll': {
        post: {
            req: ScrollDatasetChunksData;
            res: {
                /**
                 * Number of chunks equivalent to page_size starting from offset_chunk_id
                 */
                200: ScrollChunksResponseBody;
                /**
                 * Service error relating to scrolling chunks
                 */
                400: ErrorResponseBody;
            };
        };
    };
    '/api/chunks/tracking': {
        post: {
            req: GetChunksByTrackingIdsData;
            res: {
                /**
                 * Chunks with one the ids which were specified
                 */
                200: Array<ChunkReturnTypes>;
                /**
                 * Service error relating to finding a chunk by tracking_id
                 */
                400: ErrorResponseBody;
            };
        };
    };
    '/api/crawl': {
        get: {
            req: GetCrawlRequestsForDatasetData;
            res: {
                /**
                 * Crawl requests retrieved successfully
                 */
                200: Array<CrawlRequest>;
                /**
                 * Service error relating to retrieving the crawl requests
                 */
                400: ErrorResponseBody;
            };
        };
        post: {
            req: CreateCrawlData;
            res: {
                /**
                 * Crawl created successfully
                 */
                200: CrawlRequest;
                /**
                 * Service error relating to creating the dataset
                 */
                400: ErrorResponseBody;
            };
        };
        put: {
            req: UpdateCrawlRequestData;
            res: {
                /**
                 * Crawl updated successfully
                 */
                200: CrawlRequest;
                /**
                 * Service error relating to updating the dataset
                 */
                400: ErrorResponseBody;
            };
        };
    };
    '/api/crawl/{crawl_id}': {
        delete: {
            req: DeleteCrawlRequestData;
            res: {
                /**
                 * Crawl deleted successfully
                 */
                204: void;
                /**
                 * Service error relating to deleting the dataset
                 */
                400: ErrorResponseBody;
            };
        };
    };
    '/api/dataset': {
        post: {
            req: CreateDatasetData;
            res: {
                /**
                 * Dataset created successfully
                 */
                200: Dataset;
                /**
                 * Service error relating to creating the dataset
                 */
                400: ErrorResponseBody;
            };
        };
        put: {
            req: UpdateDatasetData;
            res: {
                /**
                 * Dataset updated successfully
                 */
                200: Dataset;
                /**
                 * Service error relating to updating the dataset
                 */
                400: ErrorResponseBody;
                /**
                 * Dataset not found
                 */
                404: ErrorResponseBody;
            };
        };
    };
    '/api/dataset/batch_create_datasets': {
        post: {
            req: BatchCreateDatasetsData;
            res: {
                /**
                 * Page of tags requested with all tags and the number of chunks in the dataset with that tag plus the total number of unique tags for the whole datset
                 */
                200: Datasets;
                /**
                 * Service error relating to finding items by tag
                 */
                400: ErrorResponseBody;
            };
        };
    };
    '/api/dataset/clear/{dataset_id}': {
        put: {
            req: ClearDatasetData;
            res: {
                /**
                 * Dataset cleared successfully
                 */
                204: void;
                /**
                 * Service error relating to deleting the dataset
                 */
                400: ErrorResponseBody;
                /**
                 * Dataset not found
                 */
                404: ErrorResponseBody;
            };
        };
    };
    '/api/dataset/events': {
        post: {
            req: GetEventsData2;
            res: {
                /**
                 * Events for the dataset
                 */
                200: EventReturn;
                /**
                 * Service error relating to getting events for the dataset
                 */
                400: ErrorResponseBody;
            };
        };
    };
    '/api/dataset/files/{dataset_id}/{page}': {
        get: {
            req: GetDatasetFilesHandlerData;
            res: {
                /**
                 * JSON body representing the files in the current dataset
                 */
                200: FileData;
                /**
                 * Service error relating to getting the files in the current datase
                 */
                400: ErrorResponseBody;
            };
        };
    };
    '/api/dataset/get_all_tags': {
        post: {
            req: GetAllTagsData;
            res: {
                /**
                 * Page of tags requested with all tags and the number of chunks in the dataset with that tag plus the total number of unique tags for the whole datset
                 */
                200: GetAllTagsResponse;
                /**
                 * Service error relating to finding items by tag
                 */
                400: ErrorResponseBody;
            };
        };
    };
    '/api/dataset/groups/{dataset_id}/{page}': {
        get: {
            req: GetGroupsForDatasetData;
            res: {
                /**
                 * JSON body representing the groups created by the given dataset
                 */
                200: GroupData;
                /**
                 * Service error relating to getting the groups created by the given dataset
                 */
                400: ErrorResponseBody;
            };
        };
    };
    '/api/dataset/organization/{organization_id}': {
        get: {
            req: GetDatasetsFromOrganizationData;
            res: {
                /**
                 * Datasets retrieved successfully
                 */
                200: Array<DatasetAndUsage>;
                /**
                 * Service error relating to retrieving the dataset
                 */
                400: ErrorResponseBody;
                /**
                 * Could not find organization
                 */
                404: ErrorResponseBody;
            };
        };
    };
    '/api/dataset/pagefind': {
        get: {
            req: GetPagefindIndexForDatasetData;
            res: {
                /**
                 * Dataset indexed successfully
                 */
                200: GetPagefindIndexResponse;
                /**
                 * Service error relating to creating the index
                 */
                400: ErrorResponseBody;
            };
        };
        put: {
            req: CreatePagefindIndexForDatasetData;
            res: {
                /**
                 * Dataset indexed successfully
                 */
                204: void;
                /**
                 * Service error relating to creating the index
                 */
                400: ErrorResponseBody;
            };
        };
    };
    '/api/dataset/tracking_id/{tracking_id}': {
        get: {
            req: GetDatasetByTrackingIdData;
            res: {
                /**
                 * Dataset retrieved successfully
                 */
                200: Dataset;
                /**
                 * Service error relating to retrieving the dataset
                 */
                400: ErrorResponseBody;
                /**
                 * Dataset not found
                 */
                404: ErrorResponseBody;
            };
        };
        delete: {
            req: DeleteDatasetByTrackingIdData;
            res: {
                /**
                 * Dataset deleted successfully
                 */
                204: void;
                /**
                 * Service error relating to deleting the dataset
                 */
                400: ErrorResponseBody;
                /**
                 * Dataset not found
                 */
                404: ErrorResponseBody;
            };
        };
    };
    '/api/dataset/usage/{dataset_id}': {
        get: {
            req: GetUsageByDatasetIdData;
            res: {
                /**
                 * Dataset usage retrieved successfully
                 */
                200: DatasetUsageCount;
                /**
                 * Service error relating to retrieving the dataset usage
                 */
                400: ErrorResponseBody;
                /**
                 * Dataset not found
                 */
                404: ErrorResponseBody;
            };
        };
    };
    '/api/dataset/{dataset_id}': {
        get: {
            req: GetDatasetData;
            res: {
                /**
                 * Dataset retrieved successfully
                 */
                200: Dataset;
                /**
                 * Service error relating to retrieving the dataset
                 */
                400: ErrorResponseBody;
                /**
                 * Dataset not found
                 */
                404: ErrorResponseBody;
            };
        };
        delete: {
            req: DeleteDatasetData;
            res: {
                /**
                 * Dataset deleted successfully
                 */
                204: void;
                /**
                 * Service error relating to deleting the dataset
                 */
                400: ErrorResponseBody;
                /**
                 * Dataset not found
                 */
                404: ErrorResponseBody;
            };
        };
    };
    '/api/etl/create_job': {
        post: {
            req: CreateEtlJobData;
            res: {
                /**
                 * ETL Job created successfully
                 */
                204: void;
                /**
                 * Service error relating to creating the dataset
                 */
                400: ErrorResponseBody;
            };
        };
    };
    '/api/file': {
        post: {
            req: UploadFileHandlerData;
            res: {
                /**
                 * Confirmation that the file is uploading
                 */
                200: UploadFileResponseBody;
                /**
                 * Service error relating to uploading the file
                 */
                400: ErrorResponseBody;
            };
        };
    };
    '/api/file/csv_or_jsonl': {
        post: {
            req: CreatePresignedUrlForCsvJsonlData;
            res: {
                /**
                 * File object information and signed put URL
                 */
                200: CreatePresignedUrlForCsvJsonResponseBody;
                /**
                 * Service error relating to uploading the file
                 */
                400: ErrorResponseBody;
            };
        };
    };
    '/api/file/html_page': {
        post: {
            req: UploadHtmlPageData;
            res: {
                /**
                 * Confirmation that html is being processed
                 */
                204: void;
                /**
                 * Service error relating to processing the file
                 */
                400: ErrorResponseBody;
            };
        };
    };
    '/api/file/{file_id}': {
        get: {
            req: GetFileHandlerData;
            res: {
                /**
                 * The file's information and s3_url where the original file can be downloaded
                 */
                200: FileDTO;
                /**
                 * Service error relating to finding the file
                 */
                400: ErrorResponseBody;
                /**
                 * File not found
                 */
                404: ErrorResponseBody;
            };
        };
        delete: {
            req: DeleteFileHandlerData;
            res: {
                /**
                 * Confirmation that the file has been deleted
                 */
                204: void;
                /**
                 * Service error relating to finding or deleting the file
                 */
                400: ErrorResponseBody;
            };
        };
    };
    '/api/health': {
        get: {
            res: {
                /**
                 * Confirmation that the service is healthy and can make embedding vectors
                 */
                200: unknown;
                /**
                 * Service error relating to making an embedding or overall service health
                 */
                400: ErrorResponseBody;
            };
        };
    };
    '/api/invitation': {
        post: {
            req: PostInvitationData;
            res: {
                /**
                 * Ok response. Indicates that invitation email was sent correctly.
                 */
                204: void;
                /**
                 * Invalid email or some other error
                 */
                400: ErrorResponseBody;
            };
        };
    };
    '/api/invitation/{invitation_id}': {
        delete: {
            req: DeleteInvitationData;
            res: {
                /**
                 * Ok response. Indicates that invitation was deleted.
                 */
                204: void;
                /**
                 * Service error relating to deleting invitation
                 */
                400: ErrorResponseBody;
            };
        };
    };
    '/api/invitations/{organization_id}': {
        get: {
            req: GetInvitationsData;
            res: {
                /**
                 * Invitations for the dataset
                 */
                200: Array<Invitation>;
                /**
                 * Service error relating to getting invitations for the dataset
                 */
                400: ErrorResponseBody;
            };
        };
    };
    '/api/message': {
        post: {
            req: CreateMessageData;
            res: {
                /**
                 * This will be a JSON response of a string containing the LLM's generated inference. Response if not streaming.
                 */
                200: string;
                /**
                 * Service error relating to getting a chat completion
                 */
                400: ErrorResponseBody;
            };
        };
        put: {
            req: EditMessageData;
            res: {
                /**
                 * This will be a HTTP stream, check the chat or search UI for an example how to process this
                 */
                200: string;
                /**
                 * Service error relating to getting a chat completion
                 */
                400: ErrorResponseBody;
            };
        };
        delete: {
            req: RegenerateMessageData;
            res: {
                /**
                 * This will be a JSON response of a string containing the LLM's generated inference. Response if not streaming.
                 */
                200: string;
                /**
                 * Service error relating to getting a chat completion
                 */
                400: ErrorResponseBody;
            };
        };
        patch: {
            req: RegenerateMessagePatchData;
            res: {
                /**
                 * This will be a JSON response of a string containing the LLM's generated inference. Response if not streaming.
                 */
                200: string;
                /**
                 * Service error relating to getting a chat completion
                 */
                400: ErrorResponseBody;
            };
        };
    };
    '/api/message/get_tool_function_params': {
        post: {
            req: GetToolFunctionParamsData;
            res: {
                /**
                 * A JSON object containing the parameters for the tool function
                 */
                200: GetToolFunctionParamsRespBody;
                /**
                 * Service error relating to to updating chunk, likely due to conflicting tracking_id
                 */
                400: ErrorResponseBody;
            };
        };
    };
    '/api/message/{message_id}': {
        get: {
            req: GetMessageByIdData;
            res: {
                /**
                 * Message with the given ID
                 */
                200: Message;
                /**
                 * Service error relating to getting the message
                 */
                400: ErrorResponseBody;
            };
        };
    };
    '/api/messages/{messages_topic_id}': {
        get: {
            req: GetAllTopicMessagesData;
            res: {
                /**
                 * All messages relating to the topic with the given ID
                 */
                200: Array<Message>;
                /**
                 * Service error relating to getting the messages
                 */
                400: ErrorResponseBody;
            };
        };
    };
    '/api/organization': {
        post: {
            req: CreateOrganizationData;
            res: {
                /**
                 * Created organization object
                 */
                200: Organization;
                /**
                 * Service error relating to creating the organization
                 */
                400: ErrorResponseBody;
            };
        };
        put: {
            req: UpdateOrganizationData;
            res: {
                /**
                 * Updated organization object
                 */
                200: Organization;
                /**
                 * Service error relating to updating the organization
                 */
                400: ErrorResponseBody;
            };
        };
    };
    '/api/organization/api_key': {
        get: {
            req: GetOrganizationApiKeysData;
            res: {
                /**
                 * JSON body representing the api_key for the organization
                 */
                200: Array<ApiKeyRespBody>;
                /**
                 * Service error relating to creating api_key for the organization
                 */
                400: ErrorResponseBody;
            };
        };
        post: {
            req: CreateOrganizationApiKeyData;
            res: {
                /**
                 * JSON body representing the api_key for the organization
                 */
                200: CreateApiKeyResponse;
                /**
                 * Service error relating to creating api_key for the organization
                 */
                400: ErrorResponseBody;
            };
        };
    };
    '/api/organization/api_key/{api_key_id}': {
        delete: {
            req: DeleteOrganizationApiKeyData;
            res: {
                /**
                 * Confirmation that the api key was deleted
                 */
                204: void;
                /**
                 * Service error relating to creating api_key for the organization
                 */
                400: ErrorResponseBody;
            };
        };
    };
    '/api/organization/update_dataset_configs': {
        post: {
            req: UpdateAllOrgDatasetConfigsData;
            res: {
                /**
                 * Confirmation that the dataset ServerConfigurations were updated successfully
                 */
                204: void;
                /**
                 * Service error relating to updating the dataset ServerConfigurations
                 */
                400: ErrorResponseBody;
            };
        };
    };
    '/api/organization/usage/{organization_id}': {
        get: {
            req: GetOrganizationUsageData;
            res: {
                /**
                 * The current usage of the specified organization
                 */
                200: OrganizationUsageCount;
                /**
                 * Service error relating to finding the organization's usage by id
                 */
                400: ErrorResponseBody;
            };
        };
    };
    '/api/organization/users/{organization_id}': {
        get: {
            req: GetOrganizationUsersData;
            res: {
                /**
                 * Array of users who belong to the specified by organization
                 */
                200: Array<SlimUser>;
                /**
                 * Service error relating to finding the organization's users by id
                 */
                400: ErrorResponseBody;
            };
        };
    };
    '/api/organization/{organization_id}': {
        get: {
            req: GetOrganizationData;
            res: {
                /**
                 * Organization with the id that was requested
                 */
                200: OrganizationWithSubAndPlan;
                /**
                 * Service error relating to finding the organization by id
                 */
                400: ErrorResponseBody;
                /**
                 * Organization not found
                 */
                404: ErrorResponseBody;
            };
        };
        delete: {
            req: DeleteOrganizationData;
            res: {
                /**
                 * Confirmation that the organization was deleted
                 */
                204: void;
                /**
                 * Service error relating to deleting the organization by id
                 */
                400: ErrorResponseBody;
            };
        };
    };
    '/api/public_page/{dataset_id}': {
        get: {
            req: PublicPageData;
            res: {
                /**
                 * Public Page associated to the dataset
                 */
                200: unknown;
                /**
                 * Service error relating to loading the public page
                 */
                400: ErrorResponseBody;
                /**
                 * Dataset not found
                 */
                404: ErrorResponseBody;
            };
        };
    };
    '/api/stripe/checkout/setup/{organization_id}': {
        post: {
            req: CreateSetupCheckoutSessionData;
            res: {
                /**
                 * Checkout session (setup) response
                 */
                200: CreateSetupCheckoutSessionResPayload;
                /**
                 * Service error relating to creating setup checkout session
                 */
                400: ErrorResponseBody;
            };
        };
    };
    '/api/stripe/invoices/{organization_id}': {
        get: {
            req: GetAllInvoicesData;
            res: {
                /**
                 * List of all invoices
                 */
                200: Array<StripeInvoice>;
                /**
                 * Service error relating to getting all invoices
                 */
                400: ErrorResponseBody;
            };
        };
    };
    '/api/stripe/payment_link/{plan_id}/{organization_id}': {
        get: {
            req: DirectToPaymentLinkData;
            res: {
                /**
                 * SeeOther response redirecting user to stripe checkout page
                 */
                303: unknown;
                /**
                 * Service error relating to creating a URL for a stripe checkout page
                 */
                400: ErrorResponseBody;
            };
        };
    };
    '/api/stripe/plans': {
        get: {
            res: {
                /**
                 * List of all plans
                 */
                200: Array<StripePlan>;
                /**
                 * Service error relating to getting all plans
                 */
                400: ErrorResponseBody;
            };
        };
    };
    '/api/stripe/subscription/{subscription_id}': {
        delete: {
            req: CancelSubscriptionData;
            res: {
                /**
                 * Confirmation that the subscription was cancelled
                 */
                200: unknown;
                /**
                 * Service error relating to creating a URL for a stripe checkout page
                 */
                400: ErrorResponseBody;
            };
        };
    };
    '/api/stripe/subscription_plan/{subscription_id}/{plan_id}': {
        patch: {
            req: UpdateSubscriptionPlanData;
            res: {
                /**
                 * Confirmation that the subscription was updated to the new plan
                 */
                200: unknown;
                /**
                 * Service error relating to updating the subscription to the new plan
                 */
                400: ErrorResponseBody;
            };
        };
    };
    '/api/topic': {
        post: {
            req: CreateTopicData;
            res: {
                /**
                 * The JSON response payload containing the created topic
                 */
                200: Topic;
                /**
                 * Topic name empty or a service error
                 */
                400: ErrorResponseBody;
            };
        };
        put: {
            req: UpdateTopicData;
            res: {
                /**
                 * Confirmation that the topic was updated
                 */
                204: void;
                /**
                 * Service error relating to topic update
                 */
                400: ErrorResponseBody;
            };
        };
    };
    '/api/topic/clone': {
        post: {
            req: CloneTopicData;
            res: {
                /**
                 * The JSON response payload containing the created topic
                 */
                200: Topic;
                /**
                 * Topic name empty or a service error
                 */
                400: ErrorResponseBody;
            };
        };
    };
    '/api/topic/owner/{owner_id}': {
        get: {
            req: GetAllTopicsForOwnerIdData;
            res: {
                /**
                 * All topics belonging to a given owner_id
                 */
                200: Array<Topic>;
                /**
                 * Service error relating to getting topics for the owner_id
                 */
                400: ErrorResponseBody;
            };
        };
    };
    '/api/topic/{topic_id}': {
        delete: {
            req: DeleteTopicData2;
            res: {
                /**
                 * Confirmation that the topic was deleted
                 */
                204: void;
                /**
                 * Service error relating to topic deletion
                 */
                400: ErrorResponseBody;
            };
        };
    };
    '/api/user': {
        put: {
            req: UpdateUserData;
            res: {
                /**
                 * Confirmation that the user's role was updated
                 */
                204: void;
                /**
                 * Service error relating to updating the user
                 */
                400: ErrorResponseBody;
            };
        };
    };
    '/api/user/api_key': {
        get: {
            res: {
                /**
                 * JSON body representing the api_key for the user
                 */
                200: Array<ApiKeyRespBody>;
                /**
                 * Service error relating to creating api_key for the user
                 */
                400: ErrorResponseBody;
            };
        };
    };
    '/api/user/api_key/{api_key_id}': {
        delete: {
            req: DeleteUserApiKeyData;
            res: {
                /**
                 * Confirmation that the api key was deleted
                 */
                204: void;
                /**
                 * Service error relating to creating api_key for the user
                 */
                400: ErrorResponseBody;
            };
        };
    };
    '/metrics': {
        post: {
            res: {
                /**
                 * Prometheus metrics for the server
                 */
                200: string;
                /**
                 * Internal Server Error
                 */
                500: ErrorResponseBody;
            };
        };
    };
};